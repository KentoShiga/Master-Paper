{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import ConvexHull\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyVHR as vhr\n",
    "from pyVHR.extraction.sig_processing import SignalProcessing\n",
    "from pyVHR.plot.visualize import *\n",
    "from pyVHR.BVP import *\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# 修正: scikit-image 0.18.3用のインポート\n",
    "from skimage.feature import local_binary_pattern\n",
    "# graycomatrixとgraycopropsは古いバージョンでは別の場所にあります\n",
    "try:\n",
    "    from skimage.feature import greycomatrix as graycomatrix, greycoprops as graycoprops\n",
    "except ImportError:\n",
    "    # 別の方法を試す\n",
    "    from skimage.feature import texture\n",
    "    # または関数を使わない場合はコメントアウト\n",
    "    graycomatrix = None\n",
    "    graycoprops = None\n",
    "    print(\"警告: graycomatrix/graycopropsをインポートできませんでした\")\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from scipy.ndimage import laplace\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力とする動画と動画のファイル名を取得\n",
    "root_dir = \"experimentData\\\\\"\n",
    "data_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "movie_paths = []\n",
    "movie_names = []\n",
    "true_value_csv_array = []\n",
    "true_value_rri_csv_array = []\n",
    "print(\"動画ディレクトリ:\", data_dirs)\n",
    "\n",
    "for i in range(len(data_dirs)):\n",
    "    data_dir = data_dirs[i]\n",
    "\n",
    "    # 動画ファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.avi')]\n",
    "    movie_paths.extend(movie_files)\n",
    "\n",
    "    movie_name = os.path.basename(data_dir)\n",
    "    movie_names.append(movie_name)\n",
    "\n",
    "    # ppgファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    true_value_csv_array = [f.replace('.avi', '.csv') for f in movie_paths if f.endswith('.avi')]\n",
    "    true_value_rri_csv_array.append(os.path.join(data_dir, 'RRI_Simple_' + movie_name + '.csv'))\n",
    "\n",
    "\n",
    "f_1_ffi = 0.0399  # LFのはじめ\n",
    "f_2 = 0.151  # LFの終わり、HFのはじめ\n",
    "f_3 = 0.401  # HFの終わり\n",
    "\n",
    "# start_index = 6\n",
    "# end_index = len(movie_paths)\n",
    "\n",
    "# data_dirs = data_dirs[start_index:end_index]\n",
    "# movie_paths = movie_paths[start_index:end_index]\n",
    "# movie_names = movie_names[start_index:end_index]\n",
    "# true_value_csv_array = true_value_csv_array[start_index:end_index]\n",
    "# true_value_rri_csv_array = true_value_rri_csv_array[start_index:end_index]\n",
    "\n",
    "print(f\"data_dirs: {data_dirs}\")\n",
    "print(f\"movie_paths: {movie_paths}\")\n",
    "print(f\"movie_names: {movie_names}\")\n",
    "print(f\"true_value_csv_array: {true_value_csv_array}\")\n",
    "print(f\"true_value_rri_csv_array: {true_value_rri_csv_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc238cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR  = \"ExploreParamPCA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785aef43",
   "metadata": {},
   "source": [
    "### 肌領域を1フレーム目から検出し、フレームごとにRGBを抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3b416",
   "metadata": {},
   "source": [
    "抽出指標\n",
    "- RGB\n",
    "- HSV\n",
    "- Lightness\n",
    "- LBP\n",
    "  - エントロピー\n",
    "  - 分散\n",
    "  - 歪度\n",
    "  - 尖度\n",
    "  - χ²距離\n",
    "  - Uniform比率\n",
    "- オプティカルフロー(2フレーム目から)\n",
    "  - 平均動き量\n",
    "  - 動き量の標準偏差\n",
    "  - 1ピクセル/5ピクセル/10ピクセル動いたピクセルの割合\n",
    "- SSIM(2フレーム目から)\n",
    "- PSNR(2フレーム目から)\n",
    "- Canny\n",
    "- GLCM\n",
    "  - 等方性テクスチャ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16143ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lbp_features(gray_roi, radius=1, n_points=8):\n",
    "    \"\"\"LBP特徴量を計算\"\"\"\n",
    "    # LBP計算\n",
    "    lbp = local_binary_pattern(gray_roi, n_points, radius, method='uniform')\n",
    "    \n",
    "    # ヒストグラム作成(uniform patternsは0〜n_points+1、non-uniformはn_points+2)\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    # エントロピー\n",
    "    lbp_entropy = entropy(hist + 1e-10)  # ゼロ除算防止\n",
    "    \n",
    "    # 分散\n",
    "    lbp_variance = np.var(lbp)\n",
    "    \n",
    "    # 歪度\n",
    "    lbp_skewness = skew(lbp.ravel())\n",
    "    \n",
    "    # 尖度\n",
    "    lbp_kurtosis_val = kurtosis(lbp.ravel())\n",
    "    \n",
    "    # χ²距離(一様分布との比較)\n",
    "    uniform_hist = np.ones(n_bins) / n_bins\n",
    "    chi2_distance = np.sum((hist - uniform_hist) ** 2 / (uniform_hist + 1e-10))\n",
    "    \n",
    "    # Uniform比率(uniform patternsの割合)\n",
    "    uniform_patterns = lbp <= n_points\n",
    "    uniform_ratio = np.sum(uniform_patterns) / lbp.size\n",
    "    \n",
    "    return {\n",
    "        'lbp_entropy': lbp_entropy,\n",
    "        'lbp_variance': lbp_variance,\n",
    "        'lbp_skewness': lbp_skewness,\n",
    "        'lbp_kurtosis': lbp_kurtosis_val,\n",
    "        'lbp_chi2_distance': chi2_distance,\n",
    "        'lbp_uniform_ratio': uniform_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c368f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optical_flow_features(prev_gray, curr_gray, mask):\n",
    "    \"\"\"オプティカルフロー特徴量を計算\"\"\"\n",
    "    # Farneback法でオプティカルフロー計算\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prev_gray, curr_gray, None,\n",
    "        pyr_scale=0.5, levels=3, winsize=15,\n",
    "        iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "    )\n",
    "    \n",
    "    # マスク領域のフローのみ抽出\n",
    "    flow_roi = flow[mask > 0]\n",
    "    \n",
    "    # 動き量(magnitude)を計算\n",
    "    magnitude = np.sqrt(flow_roi[:, 0]**2 + flow_roi[:, 1]**2)\n",
    "    \n",
    "    # 平均動き量\n",
    "    mean_motion = np.mean(magnitude)\n",
    "    \n",
    "    # 動き量の標準偏差\n",
    "    std_motion = np.std(magnitude)\n",
    "    \n",
    "    # しきい値を超えたピクセルの割合\n",
    "    ratio_1px = np.sum(magnitude > 1) / len(magnitude)\n",
    "    ratio_5px = np.sum(magnitude > 5) / len(magnitude)\n",
    "    ratio_10px = np.sum(magnitude > 10) / len(magnitude)\n",
    "    \n",
    "    return {\n",
    "        'flow_mean_motion': mean_motion,\n",
    "        'flow_std_motion': std_motion,\n",
    "        'flow_ratio_1px': ratio_1px,\n",
    "        'flow_ratio_5px': ratio_5px,\n",
    "        'flow_ratio_10px': ratio_10px\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim_psnr(prev_gray, curr_gray, mask):\n",
    "    \"\"\"SSIMとPSNRを計算\"\"\"    \n",
    "    # マスク領域の外接矩形を取得\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    \n",
    "    # ROI領域のみ切り出し\n",
    "    prev_roi = prev_gray[y:y+h, x:x+w]\n",
    "    curr_roi = curr_gray[y:y+h, x:x+w]\n",
    "    mask_roi = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    # マスクを適用\n",
    "    prev_roi_masked = np.where(mask_roi > 0, prev_roi, 0)\n",
    "    curr_roi_masked = np.where(mask_roi > 0, curr_roi, 0)\n",
    "    \n",
    "    # SSIM計算\n",
    "    ssim_value, _ = ssim(prev_roi_masked, curr_roi_masked, full=True)\n",
    "    \n",
    "    # PSNR計算\n",
    "    mse = np.mean((prev_roi_masked.astype(float) - curr_roi_masked.astype(float)) ** 2)\n",
    "    if mse == 0:\n",
    "        psnr_value = 100  # 完全一致の場合\n",
    "    else:\n",
    "        psnr_value = 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "    \n",
    "    return {\n",
    "        'ssim': ssim_value,\n",
    "        'psnr': psnr_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad330e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_glcm_features(gray_roi):\n",
    "    \"\"\"GLCM特徴量を計算\"\"\"\n",
    "    # GLCMの計算(4方向の平均を取る)\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    # 256階調を64階調に削減(計算高速化)\n",
    "    gray_roi_reduced = (gray_roi // 4).astype(np.uint8)\n",
    "    \n",
    "    glcm = graycomatrix(\n",
    "        gray_roi_reduced, \n",
    "        distances=distances, \n",
    "        angles=angles, \n",
    "        levels=64,\n",
    "        symmetric=True, \n",
    "        normed=True\n",
    "    )\n",
    "    \n",
    "    # 等方性テクスチャ(各方向のコントラストの標準偏差の逆数)\n",
    "    contrast_values = []\n",
    "    for i in range(len(angles)):\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, i]\n",
    "        contrast_values.append(contrast)\n",
    "    \n",
    "    # 等方性スコア(方向間の差が小さいほど等方的)\n",
    "    isotropy = 1.0 / (np.std(contrast_values) + 1e-10)\n",
    "    \n",
    "    return {\n",
    "        'glcm_isotropy': isotropy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34847453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_canny_features(gray_roi):\n",
    "    \"\"\"Cannyエッジ特徴量を計算\"\"\"\n",
    "    # Cannyエッジ検出\n",
    "    edges = cv2.Canny(gray_roi, 100, 200)\n",
    "    \n",
    "    # エッジピクセルの割合\n",
    "    edge_ratio = np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    return {\n",
    "        'canny_edge_ratio': edge_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skin_angle(r_signal, g_signal, b_signal):\n",
    "    \"\"\"\n",
    "    皮膚色角度を計算（標準肌色調ベクトルとの角度）\n",
    "    \n",
    "    Args:\n",
    "        r_signal: (N,) 赤チャンネル信号\n",
    "        g_signal: (N,) 緑チャンネル信号\n",
    "        b_signal: (N,) 青チャンネル信号\n",
    "    \n",
    "    Returns:\n",
    "        angle: float 標準肌色調ベクトル [0.7682, 0.5121, 0.3841] との角度（度）\n",
    "    \"\"\"\n",
    "    eps = 1e-9  # ゼロ除算対策\n",
    "    \n",
    "    # RGB統計量（時間平均）\n",
    "    r_mean = np.mean(r_signal)\n",
    "    g_mean = np.mean(g_signal)\n",
    "    b_mean = np.mean(b_signal)\n",
    "    \n",
    "    # RGB正規化（単位ベクトル化）\n",
    "    norm = np.sqrt(r_mean**2 + g_mean**2 + b_mean**2)\n",
    "    \n",
    "    # ゼロ除算チェック\n",
    "    if norm < eps:\n",
    "        print(\"警告: RGB平均値がほぼゼロです。角度を計算できません。\")\n",
    "        return np.nan\n",
    "    \n",
    "    skin_vector = np.array([r_mean, g_mean, b_mean]) / norm\n",
    "    \n",
    "    # 標準化肌ベクトル [0.7682, 0.5121, 0.3841]との角度計算\n",
    "    reference_vector = np.array([0.7682, 0.5121, 0.3841])\n",
    "    \n",
    "    # コサイン類似度（範囲を[-1, 1]にクリップ）\n",
    "    cosine_similarity = np.dot(skin_vector, reference_vector)\n",
    "    cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)\n",
    "    \n",
    "    # 角度計算（度数法）\n",
    "    angle = np.degrees(np.arccos(cosine_similarity))\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcdd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_roi(frame, roi_info):\n",
    "    \"\"\"\n",
    "    ROIを可視化する関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    frame : np.ndarray\n",
    "        元の画像フレーム\n",
    "    roi_info : dict\n",
    "        extract_rgb_with_fixed_roi()が返すROI情報\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    vis_frame : np.ndarray\n",
    "        ROIを描画した画像\n",
    "    \"\"\"\n",
    "    vis_frame = frame.copy()\n",
    "    \n",
    "    # マスク領域を半透明で表示\n",
    "    mask_colored = cv2.cvtColor(roi_info['mask'], cv2.COLOR_GRAY2BGR)\n",
    "    mask_colored[:, :, 1] = roi_info['mask']  # 緑チャンネル\n",
    "    vis_frame = cv2.addWeighted(vis_frame, 0.7, mask_colored, 0.3, 0)\n",
    "    \n",
    "    # 凸包の輪郭を描画\n",
    "    cv2.polylines(vis_frame, [roi_info['hull_points']], \n",
    "                  True, (0, 255, 0), 2)\n",
    "    \n",
    "    # ランドマークを描画（オプション）\n",
    "    for pt in roi_info['landmarks']:\n",
    "        cv2.circle(vis_frame, tuple(pt), 1, (255, 0, 0), -1)\n",
    "    \n",
    "    return vis_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メイン処理\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"処理中: {dataName}\")\n",
    "    print(f\"保存先: {save_dir}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 動画情報取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    print(f\"動画情報: {total_frames}フレーム, {fps:.2f}fps, {duration:.2f}秒\")\n",
    "\n",
    "    # 1フレーム目でROI検出\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        print(f\"エラー: 動画の読み込みに失敗しました: {inputMoviePath}\")\n",
    "        continue\n",
    "    \n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "        results_mp = face_mesh.process(frame_rgb)\n",
    "        \n",
    "        if not results_mp.multi_face_landmarks:\n",
    "            cap.release()\n",
    "            print(f\"エラー: 顔が検出できませんでした: {inputMoviePath}\")\n",
    "            continue\n",
    "        \n",
    "        landmarks = results_mp.multi_face_landmarks[0]\n",
    "        h, w = first_frame.shape[:2]\n",
    "        \n",
    "        ldmks = np.array([[int(l.x * w), int(l.y * h)] \n",
    "                        for l in landmarks.landmark])\n",
    "        \n",
    "        hull = ConvexHull(ldmks)\n",
    "        hull_points = ldmks[hull.vertices]\n",
    "        \n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        cv2.fillConvexPoly(mask, hull_points, 255)\n",
    "\n",
    "        roi_info = {\n",
    "            'mask': mask,\n",
    "            'hull_points': hull_points,\n",
    "            'landmarks': ldmks\n",
    "        }\n",
    "\n",
    "        vis_frame = visualize_roi(first_frame, roi_info)\n",
    "        roi_vis_path = os.path.join(save_dir, \"roi_visualization.jpg\")\n",
    "        cv2.imwrite(roi_vis_path, vis_frame)\n",
    "        print(f\"ROI可視化画像を保存: {roi_vis_path}\")\n",
    "        print(f\"1フレーム目でROI検出完了: {len(hull_points)}個の凸包頂点\")\n",
    "\n",
    "    # 全フレームでRGB信号抽出\n",
    "    print(\"全フレームで特徴量抽出中...\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_count = 0\n",
    "\n",
    "    # 結果を格納する辞書\n",
    "    results = {\n",
    "        'frame_number': [], 'timestamp': [], 'contrast': [],\n",
    "        'r_mean': [], 'g_mean': [], 'b_mean': [],\n",
    "        'r_std': [], 'g_std': [], 'b_std': [],\n",
    "        'h_mean': [], 's_mean': [], 'v_mean': [],\n",
    "        'h_std': [], 's_std': [], 'v_std': [],\n",
    "        'l_mean': [],\n",
    "        # LBP特徴量\n",
    "        'lbp_entropy': [], 'lbp_variance': [], 'lbp_skewness': [],\n",
    "        'lbp_kurtosis': [], 'lbp_chi2_distance': [], 'lbp_uniform_ratio': [],\n",
    "        # オプティカルフロー\n",
    "        'flow_mean_motion': [], 'flow_std_motion': [],\n",
    "        'flow_ratio_1px': [], 'flow_ratio_5px': [], 'flow_ratio_10px': [],\n",
    "        # SSIM & PSNR\n",
    "        'ssim': [], 'psnr': [],\n",
    "        # Canny\n",
    "        'canny_edge_ratio': [],\n",
    "        # GLCM\n",
    "        'glcm_isotropy': [],\n",
    "        # 皮膚色角度\n",
    "        'angle': []\n",
    "    }\n",
    "\n",
    "    gray_first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        timestamp = frame_count / fps\n",
    "        \n",
    "        # BGRをRGBに変換\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # マスク領域のピクセルを抽出\n",
    "        valid_pixels = frame_rgb[mask > 0]\n",
    "        \n",
    "        if len(valid_pixels) > 0:\n",
    "            # RGB統計量\n",
    "            r_mean = np.mean(valid_pixels[:, 0])\n",
    "            g_mean = np.mean(valid_pixels[:, 1])\n",
    "            b_mean = np.mean(valid_pixels[:, 2])\n",
    "            \n",
    "            r_std = np.std(valid_pixels[:, 0])\n",
    "            g_std = np.std(valid_pixels[:, 1])\n",
    "            b_std = np.std(valid_pixels[:, 2])\n",
    "            \n",
    "            # HSV統計量\n",
    "            roi_bgr = frame[mask > 0]\n",
    "            roi_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[mask > 0]\n",
    "            \n",
    "            h_mean = np.mean(roi_hsv[:, 0])\n",
    "            s_mean = np.mean(roi_hsv[:, 1])\n",
    "            v_mean = np.mean(roi_hsv[:, 2])\n",
    "            \n",
    "            h_std = np.std(roi_hsv[:, 0])\n",
    "            s_std = np.std(roi_hsv[:, 1])\n",
    "            v_std = np.std(roi_hsv[:, 2])\n",
    "            \n",
    "            contrast = np.std(roi_bgr)\n",
    "            lightness = v_mean\n",
    "            \n",
    "            # グレースケールROIを取得\n",
    "            gray_roi = gray[mask > 0].reshape(-1)\n",
    "            x, y, w_roi, h_roi = cv2.boundingRect(mask)\n",
    "            gray_roi_2d = gray[y:y+h_roi, x:x+w_roi]\n",
    "            mask_roi_2d = mask[y:y+h_roi, x:x+w_roi]\n",
    "            gray_roi_2d_masked = np.where(mask_roi_2d > 0, gray_roi_2d, 0)\n",
    "            \n",
    "            # LBP特徴量\n",
    "            lbp_features = calculate_lbp_features(gray_roi_2d_masked)\n",
    "            \n",
    "            # Canny特徴量\n",
    "            canny_features = calculate_canny_features(gray_roi_2d_masked)\n",
    "            \n",
    "            # GLCM特徴量\n",
    "            glcm_features = calculate_glcm_features(gray_roi_2d_masked)\n",
    "\n",
    "            # 皮膚色角度\n",
    "            angle = calculate_skin_angle(\n",
    "                r_signal=np.array([r_mean]),\n",
    "                g_signal=np.array([g_mean]),\n",
    "                b_signal=np.array([b_mean]),\n",
    "            )\n",
    "            \n",
    "            # オプティカルフロー・SSIM・PSNR(最初のフレームとの比較)\n",
    "            if gray_first_frame is not None:\n",
    "                flow_features = calculate_optical_flow_features(gray_first_frame, gray, mask)\n",
    "                ssim_psnr_features = calculate_ssim_psnr(gray_first_frame, gray, mask)\n",
    "            else:\n",
    "                flow_features = {\n",
    "                    'flow_mean_motion': np.nan, 'flow_std_motion': np.nan,\n",
    "                    'flow_ratio_1px': np.nan, 'flow_ratio_5px': np.nan, \n",
    "                    'flow_ratio_10px': np.nan\n",
    "                }\n",
    "                ssim_psnr_features = {'ssim': np.nan, 'psnr': np.nan}\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"ROI内に有効なピクセルが存在しません\")\n",
    "\n",
    "        # 結果を保存\n",
    "        results['frame_number'].append(frame_count)\n",
    "        results['timestamp'].append(timestamp)\n",
    "        results['contrast'].append(contrast)\n",
    "        results['r_mean'].append(r_mean)\n",
    "        results['g_mean'].append(g_mean)\n",
    "        results['b_mean'].append(b_mean)\n",
    "        results['r_std'].append(r_std)\n",
    "        results['g_std'].append(g_std)\n",
    "        results['b_std'].append(b_std)\n",
    "        results['h_mean'].append(h_mean)\n",
    "        results['s_mean'].append(s_mean)\n",
    "        results['v_mean'].append(v_mean)\n",
    "        results['h_std'].append(h_std)\n",
    "        results['s_std'].append(s_std)\n",
    "        results['v_std'].append(v_std)\n",
    "        results['l_mean'].append(lightness)\n",
    "        \n",
    "        # LBP\n",
    "        results['lbp_entropy'].append(lbp_features['lbp_entropy'])\n",
    "        results['lbp_variance'].append(lbp_features['lbp_variance'])\n",
    "        results['lbp_skewness'].append(lbp_features['lbp_skewness'])\n",
    "        results['lbp_kurtosis'].append(lbp_features['lbp_kurtosis'])\n",
    "        results['lbp_chi2_distance'].append(lbp_features['lbp_chi2_distance'])\n",
    "        results['lbp_uniform_ratio'].append(lbp_features['lbp_uniform_ratio'])\n",
    "        \n",
    "        # オプティカルフロー\n",
    "        results['flow_mean_motion'].append(flow_features['flow_mean_motion'])\n",
    "        results['flow_std_motion'].append(flow_features['flow_std_motion'])\n",
    "        results['flow_ratio_1px'].append(flow_features['flow_ratio_1px'])\n",
    "        results['flow_ratio_5px'].append(flow_features['flow_ratio_5px'])\n",
    "        results['flow_ratio_10px'].append(flow_features['flow_ratio_10px'])\n",
    "        \n",
    "        # SSIM & PSNR\n",
    "        results['ssim'].append(ssim_psnr_features['ssim'])\n",
    "        results['psnr'].append(ssim_psnr_features['psnr'])\n",
    "        \n",
    "        # Canny\n",
    "        results['canny_edge_ratio'].append(canny_features['canny_edge_ratio'])\n",
    "        \n",
    "        # GLCM\n",
    "        results['glcm_isotropy'].append(glcm_features['glcm_isotropy'])\n",
    "\n",
    "        # 皮膚色角度\n",
    "        results['angle'].append(angle)\n",
    "        \n",
    "        # 前フレームを保存\n",
    "        prev_frame = frame.copy()\n",
    "        prev_gray = gray.copy()\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"  処理中: {frame_count}/{total_frames} フレーム ({frame_count/total_frames*100:.1f}%)\")\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"特徴量抽出完了: {frame_count}フレーム処理\")\n",
    "\n",
    "    # DataFrameに変換して保存\n",
    "    signals_df = pd.DataFrame(results)\n",
    "\n",
    "    save_path = os.path.join(save_dir, \"extracted_signals.csv\")\n",
    "    signals_df.to_csv(save_path, index=False)\n",
    "    print(f\"抽出した信号を保存: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0494c0b",
   "metadata": {},
   "source": [
    "### windowごとに抽出信号を分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894c726",
   "metadata": {},
   "source": [
    "抽出指標\n",
    "- ウェーブレット変換\n",
    "  - グレースケール画像のウェーブレット変換のHHサブバンドのエネルギー\n",
    "- FFT\n",
    "  - グレースケール画像\n",
    "    - 高周波エネルギー比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_full_string(arr):\n",
    "    \"\"\"NumPy配列を省略なしの文字列に変換\"\"\"\n",
    "    if isinstance(arr, str):\n",
    "        return arr\n",
    "    elif isinstance(arr, (np.ndarray, list)):\n",
    "        # NumPy配列またはリストを完全な文字列に変換\n",
    "        arr_np = np.array(arr)\n",
    "        return np.array2string(arr_np, threshold=np.inf, max_line_width=np.inf, separator=' ')\n",
    "    else:\n",
    "        return str(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrideSegmentCalculator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_sizes: List[float] = [2, 3, 4, 5],\n",
    "        strides: List[float] = [0.1, 0.5, 1, 1.5, 2],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_sizes : List[float]\n",
    "            窓幅（秒）のリスト\n",
    "        strides : List[float]\n",
    "            移動秒数のリスト\n",
    "        \"\"\"\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "    def calculate_overlap(self, window_size: float, stride: float) -> float:\n",
    "        \"\"\"\n",
    "        窓幅と移動秒数からオーバーラップ率を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            オーバーラップ率（%）\n",
    "        \"\"\"\n",
    "        if stride >= window_size:\n",
    "            return 0\n",
    "        overlap = (window_size - stride) / window_size * 100\n",
    "        return round(overlap, 2)\n",
    "\n",
    "    def calculate_segments(\n",
    "        self, window_size: float, stride: float, total_frames: int, fps: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        フレーム数から解析区間を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple[int, int]]\n",
    "            各区間の(開始フレーム, 終了フレーム)のリスト\n",
    "        \"\"\"\n",
    "        frames_per_window = round(window_size * fps)\n",
    "        frames_per_stride = round(stride * fps)\n",
    "\n",
    "        segments = []\n",
    "        start_frame = 0\n",
    "\n",
    "        while start_frame + frames_per_window <= total_frames:\n",
    "            segments.append((start_frame, start_frame + frames_per_window))\n",
    "            start_frame += frames_per_stride\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def create_analysis_dataframe(self, total_frames: int, fps: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        全ての窓幅と移動秒数の組み合わせに対してDataFrameを生成\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            各条件でのセグメント情報を含むDataFrame\n",
    "            columns: window_size, stride, overlap, segment_number, frame_start, frame_end\n",
    "        \"\"\"\n",
    "        data_dict = {\n",
    "            \"window_size\": [],\n",
    "            \"stride\": [],\n",
    "            \"overlap\": [],\n",
    "            \"segment_number\": [],\n",
    "            \"frame_start\": [],\n",
    "            \"frame_end\": [],\n",
    "        }\n",
    "\n",
    "        for window_size in self.window_sizes:\n",
    "            for stride in self.strides:\n",
    "                overlap = self.calculate_overlap(window_size, stride)\n",
    "                segments = self.calculate_segments(\n",
    "                    window_size, stride, total_frames, fps\n",
    "                )\n",
    "\n",
    "                for i, (start_frame, end_frame) in enumerate(segments):\n",
    "                    data_dict[\"window_size\"].append(window_size)\n",
    "                    data_dict[\"stride\"].append(stride)\n",
    "                    data_dict[\"overlap\"].append(overlap)\n",
    "                    data_dict[\"segment_number\"].append(i)\n",
    "                    data_dict[\"frame_start\"].append(start_frame)\n",
    "                    data_dict[\"frame_end\"].append(end_frame)\n",
    "\n",
    "        return pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "class PulseAnalysisDataStrides:\n",
    "    def __init__(self, window_sizes, strides):\n",
    "        # 窓枠とストライドの値を定義\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "        # accuracyのみを格納するDataFrameを初期化\n",
    "        self.results = pd.DataFrame(\n",
    "            index=pd.Index(self.window_sizes, name=\"window_size\"),\n",
    "            columns=pd.Index(self.strides, name=\"strides\"),\n",
    "        )\n",
    "\n",
    "    def add_accuracy(self, window_size: float, strides: int, accuracy: float):\n",
    "        \"\"\"\n",
    "        精度データを追加する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        strides : int\n",
    "            ストライド（s）\n",
    "        accuracy : float\n",
    "            精度値\n",
    "        \"\"\"\n",
    "        self.results.loc[window_size, strides] = accuracy\n",
    "\n",
    "    def _create_heatmap_dataframe(self):\n",
    "        \"\"\"\n",
    "        ヒートマップ用のDataFrameを作成する内部メソッド\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            ヒートマップ用に整形されたDataFrame\n",
    "        \"\"\"\n",
    "        data = {\"stride\": self.strides}\n",
    "        for window_size in self.window_sizes:\n",
    "            data[window_size] = [\n",
    "                self.results.loc[window_size, stride] for stride in self.strides\n",
    "            ]\n",
    "        df = pd.DataFrame(data).set_index(\"stride\").T\n",
    "        return df\n",
    "\n",
    "    def save_heatmap(\n",
    "        self,\n",
    "        title: str,\n",
    "        save_path: str,\n",
    "        figsize: tuple = (10, 8),\n",
    "        cmap: str = \"YlGnBu\",\n",
    "        colorbar_label: str = \"MAE\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        cmap : str, optional\n",
    "            カラーマップ (default: 'YlGnBu')\n",
    "        colorbar_label : str, optional\n",
    "            カラーバーのラベル (default: 'MAE')\n",
    "        \"\"\"\n",
    "        df = self._create_heatmap_dataframe()\n",
    "\n",
    "        # ヒートマップを作成\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(\n",
    "            df, annot=True, fmt=\".4f\", cmap=cmap, cbar_kws={\"label\": colorbar_label}\n",
    "        )\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.xlabel(\"Stride [s]\")\n",
    "        plt.ylabel(\"Window Size [s]\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def save_heatmap_std(self, title: str, save_path: str, figsize: tuple = (10, 8)):\n",
    "        \"\"\"\n",
    "        標準偏差のヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        \"\"\"\n",
    "        self.save_heatmap(\n",
    "            title,\n",
    "            save_path,\n",
    "            figsize,\n",
    "            cmap=\"Reds\",\n",
    "            colorbar_label=\"Standard Deviation\",\n",
    "        )\n",
    "\n",
    "def find_closest_ground_truth_rri_and_time(\n",
    "    rPPG_peak_time, trueValueRRITimeArray, trueValueRRIArray\n",
    "):\n",
    "    \"\"\"\n",
    "    与えられたrPPGpeakTimeと最も近い時間のtrueValueRRIと時間を返す\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rPPG_peak_time : float\n",
    "        rPPGのピーク時間\n",
    "    trueValueRRITimeArray : array-like\n",
    "        真値RRIの時間配列\n",
    "    trueValueRRIArray : array-like\n",
    "        真値RRIの値配列\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        最も近い時間の真値RRI時間\n",
    "        最も近い時間の真値RRI値\n",
    "    \"\"\"\n",
    "    # 時間差の絶対値を計算\n",
    "    time_differences = np.abs(trueValueRRITimeArray - rPPG_peak_time)\n",
    "\n",
    "    # 最小の時間差のインデックスを取得\n",
    "    closest_index = np.argmin(time_differences)\n",
    "\n",
    "    # 対応する時間とRRI値を返す\n",
    "    return trueValueRRITimeArray[closest_index], trueValueRRIArray[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZES = [2, 4, 6, 8, 10]\n",
    "STRIDES = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc66cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wavelet_hh_energy(gray_frames):\n",
    "    \"\"\"\n",
    "    ウェーブレット変換のHHサブバンド(高周波-高周波)のエネルギーを計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gray_frames : list of np.ndarray\n",
    "        グレースケール画像のリスト\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hh_energies : np.ndarray\n",
    "        各フレームのHHサブバンドエネルギー\n",
    "    mean_hh_energy : float\n",
    "        窓内の平均HHエネルギー\n",
    "    std_hh_energy : float\n",
    "        窓内のHHエネルギーの標準偏差\n",
    "    \"\"\"\n",
    "    hh_energies = []\n",
    "    \n",
    "    for gray_frame in gray_frames:\n",
    "        # 2次元ウェーブレット変換(Haar wavelet)\n",
    "        coeffs = pywt.dwt2(gray_frame, 'haar')\n",
    "        cA, (cH, cV, cD) = coeffs\n",
    "        \n",
    "        # HH(cD: diagonal detail)のエネルギーを計算\n",
    "        hh_energy = np.sum(cD ** 2)\n",
    "        hh_energies.append(hh_energy)\n",
    "    \n",
    "    hh_energies = np.array(hh_energies)\n",
    "    \n",
    "    return {\n",
    "        'hh_energies': hh_energies,\n",
    "        'mean_hh_energy': np.mean(hh_energies),\n",
    "        'std_hh_energy': np.std(hh_energies),\n",
    "        'max_hh_energy': np.max(hh_energies),\n",
    "        'min_hh_energy': np.min(hh_energies)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fft_high_freq_ratio(gray_frames, threshold_ratio=0.5):\n",
    "    \"\"\"\n",
    "    グレースケール画像のFFT高周波エネルギー比を計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gray_frames : list of np.ndarray\n",
    "        グレースケール画像のリスト\n",
    "    threshold_ratio : float\n",
    "        高周波の閾値(0.5なら周波数の上位50%を高周波とみなす)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    high_freq_ratios : np.ndarray\n",
    "        各フレームの高周波エネルギー比\n",
    "    mean_high_freq_ratio : float\n",
    "        窓内の平均高周波エネルギー比\n",
    "    \"\"\"\n",
    "    high_freq_ratios = []\n",
    "    \n",
    "    for gray_frame in gray_frames:\n",
    "        # 2D FFT\n",
    "        f_transform = np.fft.fft2(gray_frame)\n",
    "        f_shift = np.fft.fftshift(f_transform)\n",
    "        \n",
    "        # パワースペクトル\n",
    "        magnitude_spectrum = np.abs(f_shift) ** 2\n",
    "        \n",
    "        # 画像中心からの距離を計算\n",
    "        rows, cols = gray_frame.shape\n",
    "        crow, ccol = rows // 2, cols // 2\n",
    "        \n",
    "        # 距離マップを作成\n",
    "        y, x = np.ogrid[:rows, :cols]\n",
    "        distance_from_center = np.sqrt((x - ccol)**2 + (y - crow)**2)\n",
    "        \n",
    "        # 最大距離\n",
    "        max_distance = np.sqrt(crow**2 + ccol**2)\n",
    "        \n",
    "        # 高周波領域のマスク(中心から遠い部分)\n",
    "        high_freq_mask = distance_from_center > (max_distance * threshold_ratio)\n",
    "        \n",
    "        # 高周波エネルギーと全エネルギー\n",
    "        high_freq_energy = np.sum(magnitude_spectrum[high_freq_mask])\n",
    "        total_energy = np.sum(magnitude_spectrum)\n",
    "        \n",
    "        # 高周波エネルギー比\n",
    "        high_freq_ratio = high_freq_energy / (total_energy + 1e-10)\n",
    "        high_freq_ratios.append(high_freq_ratio)\n",
    "    \n",
    "    high_freq_ratios = np.array(high_freq_ratios)\n",
    "    \n",
    "    return {\n",
    "        'high_freq_ratios': high_freq_ratios,\n",
    "        'mean_high_freq_ratio': np.mean(high_freq_ratios),\n",
    "        'std_high_freq_ratio': np.std(high_freq_ratios),\n",
    "        'max_high_freq_ratio': np.max(high_freq_ratios),\n",
    "        'min_high_freq_ratio': np.min(high_freq_ratios)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_temporal_frequency_features(signal, fps):\n",
    "    \"\"\"\n",
    "    時系列信号の周波数特徴を計算(1次元FFT)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : np.ndarray\n",
    "        時系列信号(例: RGB平均値の時系列)\n",
    "    fps : float\n",
    "        サンプリングレート\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    frequency_features : dict\n",
    "        周波数特徴量\n",
    "    \"\"\"\n",
    "    if len(signal) < 2:\n",
    "        return {\n",
    "            'dominant_freq': np.nan,\n",
    "            'spectral_entropy': np.nan,\n",
    "            'high_freq_power_ratio': np.nan\n",
    "        }\n",
    "    \n",
    "    # FFT\n",
    "    n = len(signal)\n",
    "    yf = fft(signal)\n",
    "    xf = fftfreq(n, 1/fps)\n",
    "    \n",
    "    # 正の周波数のみ\n",
    "    positive_freq_idx = xf > 0\n",
    "    xf_positive = xf[positive_freq_idx]\n",
    "    power_spectrum = np.abs(yf[positive_freq_idx]) ** 2\n",
    "    \n",
    "    # 支配的周波数\n",
    "    dominant_idx = np.argmax(power_spectrum)\n",
    "    dominant_freq = xf_positive[dominant_idx]\n",
    "    \n",
    "    # スペクトルエントロピー\n",
    "    normalized_power = power_spectrum / (np.sum(power_spectrum) + 1e-10)\n",
    "    spectral_entropy = -np.sum(normalized_power * np.log2(normalized_power + 1e-10))\n",
    "    \n",
    "    # 高周波パワー比(0.5Hz以上を高周波と定義)\n",
    "    high_freq_threshold = 0.5\n",
    "    high_freq_mask = xf_positive > high_freq_threshold\n",
    "    high_freq_power = np.sum(power_spectrum[high_freq_mask])\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    high_freq_power_ratio = high_freq_power / (total_power + 1e-10)\n",
    "    \n",
    "    return {\n",
    "        'dominant_freq': dominant_freq,\n",
    "        'spectral_entropy': spectral_entropy,\n",
    "        'high_freq_power_ratio': high_freq_power_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_motion_energy(flow_magnitudes):\n",
    "    \"\"\"\n",
    "    オプティカルフローから動きのエネルギーを計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    flow_magnitudes : np.ndarray\n",
    "        フロー magnitude の時系列\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    motion_features : dict\n",
    "        動き特徴量\n",
    "    \"\"\"\n",
    "    if len(flow_magnitudes) == 0:\n",
    "        return {\n",
    "            'motion_energy': np.nan,\n",
    "            'motion_variance': np.nan,\n",
    "            'motion_smoothness': np.nan\n",
    "        }\n",
    "    \n",
    "    # 動きエネルギー(二乗和)\n",
    "    motion_energy = np.sum(flow_magnitudes ** 2)\n",
    "    \n",
    "    # 動き分散\n",
    "    motion_variance = np.var(flow_magnitudes)\n",
    "    \n",
    "    # 動きの滑らかさ(一階微分の逆数)\n",
    "    if len(flow_magnitudes) > 1:\n",
    "        motion_diff = np.diff(flow_magnitudes)\n",
    "        motion_smoothness = 1.0 / (np.mean(np.abs(motion_diff)) + 1e-10)\n",
    "    else:\n",
    "        motion_smoothness = np.nan\n",
    "    \n",
    "    return {\n",
    "        'motion_energy': motion_energy,\n",
    "        'motion_variance': motion_variance,\n",
    "        'motion_smoothness': motion_smoothness\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_texture_dynamics(lbp_entropy_series):\n",
    "    \"\"\"\n",
    "    テクスチャの動的変化を計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lbp_entropy_series : np.ndarray\n",
    "        LBPエントロピーの時系列\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    texture_dynamics : dict\n",
    "        テクスチャ動的特徴量\n",
    "    \"\"\"\n",
    "    if len(lbp_entropy_series) < 2:\n",
    "        return {\n",
    "            'texture_change_rate': np.nan,\n",
    "            'texture_stability': np.nan\n",
    "        }\n",
    "    \n",
    "    # テクスチャ変化率(一階微分の平均)\n",
    "    texture_diff = np.diff(lbp_entropy_series)\n",
    "    texture_change_rate = np.mean(np.abs(texture_diff))\n",
    "    \n",
    "    # テクスチャ安定性(変化率の逆数)\n",
    "    texture_stability = 1.0 / (texture_change_rate + 1e-10)\n",
    "    \n",
    "    return {\n",
    "        'texture_change_rate': texture_change_rate,\n",
    "        'texture_stability': texture_stability\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== メイン処理への組み込み =====\n",
    "all_results_list = []\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    \n",
    "    # ROIマスク情報の取得\n",
    "    save_roi_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    roi_vis_path = os.path.join(save_roi_dir, \"roi_visualization.jpg\")\n",
    "  \n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "    \n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "    \n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # RGB信号の読み込み\n",
    "    os.makedirs(save_roi_dir, exist_ok=True)\n",
    "    signals_csv_path = os.path.join(save_roi_dir, f'extracted_signals.csv')\n",
    "    signals_df = pd.read_csv(signals_csv_path)\n",
    "\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    \n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "            \n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "\n",
    "        # 該当する窓の時間範囲内の信号を抽出\n",
    "        bvp_mask = (signals_df['timestamp'] >= window_start_time) & (signals_df['timestamp'] < window_end_time)\n",
    "        \n",
    "        r_signal_in_window = signals_df[bvp_mask]['r_mean'].values\n",
    "        g_signal_in_window = signals_df[bvp_mask]['g_mean'].values\n",
    "        b_signal_in_window = signals_df[bvp_mask]['b_mean'].values\n",
    "\n",
    "        r_std_signal_in_window = signals_df[bvp_mask]['r_std'].values\n",
    "        g_std_signal_in_window = signals_df[bvp_mask]['g_std'].values\n",
    "        b_std_signal_in_window = signals_df[bvp_mask]['b_std'].values\n",
    "\n",
    "        h_signal_in_window = signals_df[bvp_mask]['h_mean'].values\n",
    "        s_signal_in_window = signals_df[bvp_mask]['s_mean'].values\n",
    "        v_signal_in_window = signals_df[bvp_mask]['v_mean'].values\n",
    "\n",
    "        h_std_signal_in_window = signals_df[bvp_mask]['h_std'].values\n",
    "        s_std_signal_in_window = signals_df[bvp_mask]['s_std'].values\n",
    "        v_std_signal_in_window = signals_df[bvp_mask]['v_std'].values\n",
    "\n",
    "        lbp_entropy = signals_df[bvp_mask]['lbp_entropy'].values\n",
    "        lbp_variance = signals_df[bvp_mask]['lbp_variance'].values\n",
    "        lbp_skewness = signals_df[bvp_mask]['lbp_skewness'].values\n",
    "        lbp_kurtosis = signals_df[bvp_mask]['lbp_kurtosis'].values\n",
    "        lbp_chi2_distance = signals_df[bvp_mask]['lbp_chi2_distance'].values\n",
    "        lbp_uniform_ratio = signals_df[bvp_mask]['lbp_uniform_ratio'].values\n",
    "\n",
    "        canny_edge_ratio = signals_df[bvp_mask]['canny_edge_ratio'].values\n",
    "        glcm_isotropy = signals_df[bvp_mask]['glcm_isotropy'].values\n",
    "\n",
    "        flow_mean_motion = signals_df[bvp_mask]['flow_mean_motion'].values\n",
    "        flow_std_motion = signals_df[bvp_mask]['flow_std_motion'].values\n",
    "        flow_ratio_1px = signals_df[bvp_mask]['flow_ratio_1px'].values\n",
    "        flow_ratio_5px = signals_df[bvp_mask]['flow_ratio_5px'].values\n",
    "        flow_ratio_10px = signals_df[bvp_mask]['flow_ratio_10px'].values\n",
    "\n",
    "        ssim_values = signals_df[bvp_mask]['ssim'].values\n",
    "        psnr_values = signals_df[bvp_mask]['psnr'].values\n",
    "\n",
    "        lightness_signal_in_window = signals_df[bvp_mask]['l_mean'].values\n",
    "        min_saturation_in_window = np.min(s_signal_in_window) if len(s_signal_in_window) > 0 else np.nan\n",
    "\n",
    "        angles_in_window = signals_df[bvp_mask]['angle'].values\n",
    "        # ===== 窓内のフレームを読み込んでウェーブレット・FFT解析 =====\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start)\n",
    "        gray_frames = []\n",
    "\n",
    "        for frame_idx in range(int(frame_start), int(frame_end)):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frames.append(gray_frame)\n",
    "        \n",
    "        # ウェーブレットHHエネルギー\n",
    "        wavelet_features = calculate_wavelet_hh_energy(gray_frames)\n",
    "        \n",
    "        # FFT高周波エネルギー比\n",
    "        fft_features = calculate_fft_high_freq_ratio(gray_frames, threshold_ratio=0.5)\n",
    "        \n",
    "        # 時系列信号の周波数特徴(G信号で計算)\n",
    "        temporal_freq_features_g = calculate_temporal_frequency_features(g_signal_in_window, fps)\n",
    "        \n",
    "        # 動き特徴量\n",
    "        motion_features = calculate_motion_energy(flow_mean_motion)\n",
    "        \n",
    "        # テクスチャ動的特徴\n",
    "        texture_dynamics = calculate_texture_dynamics(lbp_entropy)\n",
    "\n",
    "        # 窓情報を保存\n",
    "        window_info = {\n",
    "            'window_index': idx,\n",
    "            'window_size': window_size,\n",
    "            'stride': stride,\n",
    "            'frame_start': frame_start,\n",
    "            'frame_end': frame_end,\n",
    "            'window_start_time': window_start_time,\n",
    "            'window_end_time': window_end_time,\n",
    "            \n",
    "            # 既存の信号\n",
    "            'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "            'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "            'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "            'r_std_signal_in_window': array_to_full_string(r_std_signal_in_window),\n",
    "            'g_std_signal_in_window': array_to_full_string(g_std_signal_in_window),\n",
    "            'b_std_signal_in_window': array_to_full_string(b_std_signal_in_window),\n",
    "            'h_signal_in_window': array_to_full_string(h_signal_in_window),\n",
    "            's_signal_in_window': array_to_full_string(s_signal_in_window),\n",
    "            'v_signal_in_window': array_to_full_string(v_signal_in_window),\n",
    "            'h_std_signal_in_window': array_to_full_string(h_std_signal_in_window),\n",
    "            's_std_signal_in_window': array_to_full_string(s_std_signal_in_window),\n",
    "            'v_std_signal_in_window': array_to_full_string(v_std_signal_in_window),\n",
    "            'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window),\n",
    "            'ecg_bpm_in_window': array_to_full_string(ecg_bpm_in_window),\n",
    "            'ecg_bpm_in_window_mean': ecg_bpm_in_window_mean,\n",
    "            'min_saturation_in_window': min_saturation_in_window,\n",
    "            \n",
    "            # LBP特徴量\n",
    "            'lbp_entropy': array_to_full_string(lbp_entropy),\n",
    "            'lbp_variance': array_to_full_string(lbp_variance),\n",
    "            'lbp_skewness': array_to_full_string(lbp_skewness),\n",
    "            'lbp_kurtosis': array_to_full_string(lbp_kurtosis),\n",
    "            'lbp_chi2_distance': array_to_full_string(lbp_chi2_distance),\n",
    "            'lbp_uniform_ratio': array_to_full_string(lbp_uniform_ratio),\n",
    "            \n",
    "            # Canny & GLCM\n",
    "            'canny_edge_ratio': array_to_full_string(canny_edge_ratio),\n",
    "            'glcm_isotropy': array_to_full_string(glcm_isotropy),\n",
    "            \n",
    "            # オプティカルフロー\n",
    "            'flow_mean_motion': array_to_full_string(flow_mean_motion),\n",
    "            'flow_std_motion': array_to_full_string(flow_std_motion),\n",
    "            'flow_ratio_1px': array_to_full_string(flow_ratio_1px),\n",
    "            'flow_ratio_5px': array_to_full_string(flow_ratio_5px),\n",
    "            'flow_ratio_10px': array_to_full_string(flow_ratio_10px),\n",
    "            \n",
    "            # ===== 新規追加: ウェーブレット特徴量 =====\n",
    "            'wavelet_hh_energies': array_to_full_string(wavelet_features['hh_energies']),\n",
    "            'wavelet_mean_hh_energy': wavelet_features['mean_hh_energy'],\n",
    "            'wavelet_std_hh_energy': wavelet_features['std_hh_energy'],\n",
    "            'wavelet_max_hh_energy': wavelet_features['max_hh_energy'],\n",
    "            'wavelet_min_hh_energy': wavelet_features['min_hh_energy'],\n",
    "            \n",
    "            # ===== 新規追加: FFT高周波エネルギー比 =====\n",
    "            'fft_high_freq_ratios': array_to_full_string(fft_features['high_freq_ratios']),\n",
    "            'fft_mean_high_freq_ratio': fft_features['mean_high_freq_ratio'],\n",
    "            'fft_std_high_freq_ratio': fft_features['std_high_freq_ratio'],\n",
    "            'fft_max_high_freq_ratio': fft_features['max_high_freq_ratio'],\n",
    "            'fft_min_high_freq_ratio': fft_features['min_high_freq_ratio'],\n",
    "            \n",
    "            # ===== 新規追加: 時系列周波数特徴 =====\n",
    "            'temporal_dominant_freq_g': temporal_freq_features_g['dominant_freq'],\n",
    "            'temporal_spectral_entropy_g': temporal_freq_features_g['spectral_entropy'],\n",
    "            'temporal_high_freq_power_ratio_g': temporal_freq_features_g['high_freq_power_ratio'],\n",
    "            \n",
    "            # ===== 新規追加: 動き特徴量 =====\n",
    "            'motion_energy': motion_features['motion_energy'],\n",
    "            'motion_variance': motion_features['motion_variance'],\n",
    "            'motion_smoothness': motion_features['motion_smoothness'],\n",
    "            \n",
    "            # ===== 新規追加: テクスチャ動的特徴 =====\n",
    "            'texture_change_rate': texture_dynamics['texture_change_rate'],\n",
    "            'texture_stability': texture_dynamics['texture_stability'],\n",
    "\n",
    "            'angles_in_window': array_to_full_string(angles_in_window),\n",
    "        }\n",
    "        all_window_results.append(window_info)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_csv_path = os.path.join(save_roi_dir, f'window_signals_{dataName}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n結果をCSVに保存: {results_csv_path}\")\n",
    "    \n",
    "    all_results_list.append(results_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"全ての動画の解析が完了しました!\")\n",
    "print(f\"処理した動画数: {len(movie_paths)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b95e9c",
   "metadata": {},
   "source": [
    "成果物:window_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb5e34",
   "metadata": {},
   "source": [
    "## 窓ごとにbpmMAE・尖度・歪度を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_window_fft(values, fps):\n",
    "    \"\"\"\n",
    "    時系列データの最大周波数とスペクトル情報を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        分析対象の時系列データ\n",
    "    fps : int\n",
    "        サンプリング周波数（1秒あたりのフレーム数）\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        以下のキーを含む辞書：\n",
    "        - 'max_freq': 検出された最大周波数\n",
    "        - 'max_amplitude': 最大周波数のときの振幅\n",
    "        - 'frequencies': 周波数配列（正の周波数のみ）\n",
    "        - 'amplitudes': 振幅配列（正の周波数のみ）\n",
    "        - 'power_spectrum': パワースペクトル\n",
    "        - 'dominant_freqs': 上位5つの卓越周波数とその振幅\n",
    "        - 'spectral_centroid': スペクトル重心\n",
    "        - 'spectral_bandwidth': スペクトル帯域幅\n",
    "        - 'total_power': 全体のパワー\n",
    "    \"\"\"\n",
    "    # データをnumpy配列に変換\n",
    "    values = np.array(values)\n",
    "\n",
    "    # ゼロパディングで分解能を向上（窓長の8倍）\n",
    "    n_pad = len(values) * 8\n",
    "\n",
    "    # ハミング窓を適用（オプション：コメントアウトされている）\n",
    "    # window = np.hamming(len(values))\n",
    "    # windowed_data = values * window\n",
    "\n",
    "    # FFTを実行（ゼロパディング適用）\n",
    "    fft_result = np.fft.fft(values, n=n_pad)\n",
    "    fft_freq = np.fft.fftfreq(n_pad, 1 / fps)\n",
    "\n",
    "    # 正の周波数のみを取得\n",
    "    positive_freq_idx = fft_freq > 0\n",
    "    positive_fft = np.abs(fft_result[positive_freq_idx])\n",
    "    positive_freq = fft_freq[positive_freq_idx]\n",
    "    \n",
    "    # パワースペクトルを計算\n",
    "    power_spectrum = positive_fft ** 2\n",
    "\n",
    "    # 最大周波数の検出と補間\n",
    "    max_idx = np.argmax(positive_fft)\n",
    "    max_amplitude = positive_fft[max_idx]\n",
    "    \n",
    "    if 0 < max_idx < len(positive_fft) - 1:\n",
    "        # 3点を使用した放物線補間\n",
    "        alpha = positive_fft[max_idx - 1]\n",
    "        beta = positive_fft[max_idx]\n",
    "        gamma = positive_fft[max_idx + 1]\n",
    "        peak_pos = 0.5 * (alpha - gamma) / (alpha - 2 * beta + gamma)\n",
    "\n",
    "        # 補間された周波数と振幅\n",
    "        freq_resolution = fps / n_pad\n",
    "        max_freq = positive_freq[max_idx] + peak_pos * freq_resolution\n",
    "        \n",
    "        # 補間された振幅（放物線の頂点）\n",
    "        max_amplitude = beta - 0.25 * (alpha - gamma) * peak_pos\n",
    "    else:\n",
    "        max_freq = positive_freq[max_idx]\n",
    "    \n",
    "    # 上位5つの卓越周波数を検出\n",
    "    top_indices = np.argsort(positive_fft)[-5:][::-1]\n",
    "    dominant_freqs = [(positive_freq[idx], positive_fft[idx]) for idx in top_indices]\n",
    "    \n",
    "    # スペクトル特徴量の計算\n",
    "    # スペクトル重心（周波数の重み付き平均）\n",
    "    spectral_centroid = np.sum(positive_freq * positive_fft) / np.sum(positive_fft)\n",
    "    \n",
    "    # スペクトル帯域幅（重心からの重み付き分散）\n",
    "    spectral_bandwidth = np.sqrt(\n",
    "        np.sum(((positive_freq - spectral_centroid) ** 2) * positive_fft) / np.sum(positive_fft)\n",
    "    )\n",
    "    \n",
    "    # 全体のパワー\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    \n",
    "    # 結果を辞書にまとめる\n",
    "    result = {\n",
    "        'max_freq': max_freq,\n",
    "        'max_amplitude': max_amplitude,\n",
    "        'frequencies': positive_freq,\n",
    "        'amplitudes': positive_fft,\n",
    "        'power_spectrum': power_spectrum,\n",
    "        'dominant_freqs': dominant_freqs,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'total_power': total_power,\n",
    "        'freq_resolution': fps / n_pad,  # 周波数分解能\n",
    "        'nyquist_freq': fps / 2  # ナイキスト周波数\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61194657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_BVPsignal(r_signals, g_signals, b_signals, s_signal, fps, deviceType, bvpMethod, bvpMethodName, method_params=None):\n",
    "    \"\"\"\n",
    "    RGB信号からBVP信号を抽出（拡張POS対応版）\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method_params : dict, optional\n",
    "        拡張POSのパラメータ\n",
    "        - use_extended: bool, 拡張POSを使用するか\n",
    "        - u_v: array, 蒸気ベクトル\n",
    "        - lambda1: float, 鏡面反射抑制重み\n",
    "        - lambda2: float, 蒸気抑制重み\n",
    "        - check_stationarity: bool, 定常性チェックするか\n",
    "        - stationarity_threshold: float, 定常性判定閾値\n",
    "    \"\"\"\n",
    "    rgb_signal = np.array([[r_signals, g_signals, b_signals]], dtype=np.float32)\n",
    "    print(f\"\\nRGB信号の形状: {rgb_signal.shape}\")\n",
    "    \n",
    "    signal_length = rgb_signal.shape[2]\n",
    "    min_required_length = 50\n",
    "    \n",
    "    if signal_length < min_required_length:\n",
    "        print(f\"警告: 信号長が短すぎます ({signal_length} < {min_required_length})。処理をスキップします。\")\n",
    "        return None, None\n",
    "    \n",
    "    filtered_signal = [rgb_signal]\n",
    "    \n",
    "    # デフォルトのメソッドパラメータ\n",
    "    if method_params is None:\n",
    "        method_params = {}\n",
    "    \n",
    "    # メソッド別パラメータ設定\n",
    "    if bvpMethodName in [\"cupy_POS\", \"cpu_POS\"]:\n",
    "        method_params['fps'] = fps\n",
    "    elif bvpMethodName == \"cupy_POS_extended\":\n",
    "        # 拡張POSのデフォルトパラメータ\n",
    "        if 'fps' not in method_params:\n",
    "            method_params['fps'] = fps\n",
    "        if 'use_extended' not in method_params:\n",
    "            method_params['use_extended'] = True\n",
    "        method_params['saturation_signal'] = s_signal\n",
    "    elif bvpMethodName in [\"cpu_ICA\", \"cpu_PCA\"]:\n",
    "        method_params['component'] = 'all_comp'\n",
    "    \n",
    "    print(f\"\\nBVP抽出開始 (メソッド: {bvpMethodName})\")\n",
    "    print(f\"パラメータ: {method_params}\")\n",
    "    \n",
    "    # BVP信号抽出\n",
    "    if method_params:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod,\n",
    "            params=method_params\n",
    "        )\n",
    "    else:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod\n",
    "        )\n",
    "    \n",
    "    # 生のBVP信号を保存\n",
    "    raw_bvp_signal = bvp_signal[0].copy() if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    # 後処理フィルタリング\n",
    "    bvp_signal = vhr.BVP.apply_filter(\n",
    "        bvp_signal,\n",
    "        vhr.BVP.BPfilter,\n",
    "        params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "    )\n",
    "    \n",
    "    bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "    \n",
    "    filtered_bvp_signal = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    print(f\"\\nBVP信号抽出完了\")\n",
    "    return raw_bvp_signal, filtered_bvp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メソッドの組み合わせを定義\n",
    "methodCombinations = [\n",
    "    ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "]\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{dataName}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # window_signalsの読み込み\n",
    "    os.makedirs(os.path.join(rootDir, SAVE_DIR), exist_ok=True)\n",
    "    window_signals_data_path = os.path.join(rootDir, SAVE_DIR, f'{\"window_signals_\" + dataName}.csv')\n",
    "    window_signals_data_df = pd.read_csv(window_signals_data_path)\n",
    "    print(f'Loaded window signals data from {window_signals_data_path}, {len(window_signals_data_df)} rows')\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    \n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if window_end_time > total_frames / fps:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                       (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "\n",
    "        # RGB信号を抽出\n",
    "        bvp_mask = window_signals_data_df['window_index'] == idx\n",
    "        print(f'    BVP mask has {bvp_mask.sum()} matching rows')\n",
    "\n",
    "        filtered_rows = window_signals_data_df[bvp_mask]\n",
    "\n",
    "        r_signal_in_window = filtered_rows['r_signal_in_window'].values[0]\n",
    "        g_signal_in_window = filtered_rows['g_signal_in_window'].values[0]\n",
    "        b_signal_in_window = filtered_rows['b_signal_in_window'].values[0]\n",
    "        saturation_signal_in_window = filtered_rows['s_signal_in_window'].values[0]\n",
    "        lightness_signal_in_window = filtered_rows['lightness_signal_in_window'].values[0]\n",
    "\n",
    "        # 文字列をNumPy配列に変換\n",
    "        r_signal_in_window = np.fromstring(r_signal_in_window[1:-1], sep=' ')\n",
    "        print(f'    R signal in window length: {len(r_signal_in_window)}')\n",
    "        g_signal_in_window = np.fromstring(g_signal_in_window[1:-1], sep=' ')\n",
    "        b_signal_in_window = np.fromstring(b_signal_in_window[1:-1], sep=' ')\n",
    "        saturation_signal_in_window = np.fromstring(saturation_signal_in_window[1:-1], sep=' ')\n",
    "        lightness_signal_in_window = np.fromstring(lightness_signal_in_window[1:-1], sep=' ')\n",
    "        \n",
    "        if len(r_signal_in_window) == 0 or len(g_signal_in_window) == 0 or len(b_signal_in_window) == 0:\n",
    "            raise ValueError(\"RGB信号が窓内に存在しません\")\n",
    "\n",
    "        # BVPメソッドの設定\n",
    "        for methodCombination in methodCombinations:\n",
    "            deviceType = methodCombination[0] \n",
    "            bvpMethod = methodCombination[1] \n",
    "            bvpMethodName = methodCombination[2]\n",
    "            method_params = methodCombination[3].copy() if len(methodCombination) > 3 else {}\n",
    "\n",
    "\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"実行メソッド: {bvpMethodName}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "            # rgbからBVPを計算\n",
    "            raw_bvp_signal_in_window, filtered_bvp_signal_in_window = extract_BVPsignal(\n",
    "                r_signal_in_window,\n",
    "                g_signal_in_window,\n",
    "                b_signal_in_window,\n",
    "                saturation_signal_in_window,\n",
    "                fps,\n",
    "                deviceType,\n",
    "                bvpMethod,\n",
    "                bvpMethodName,\n",
    "                method_params=method_params\n",
    "            )\n",
    "            \n",
    "            # BVP信号の抽出に失敗した場合はスキップ\n",
    "            if filtered_bvp_signal_in_window is None:\n",
    "                print(f\"ウィンドウ {idx} をスキップ: BVP信号の抽出に失敗\")\n",
    "                continue\n",
    "            \n",
    "            # FFT解析\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "            filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "            fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "            # MAEの計算\n",
    "            rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "            rppg_freq = fft_result_dic['frequencies']\n",
    "            rppg_amplitude = fft_result_dic['amplitudes']\n",
    "            rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "            bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "            print(f\"\\n結果サマリー:\")\n",
    "            print(f\"  ECG BPM: {ecg_bpm_in_window_mean:.2f}\")\n",
    "            print(f\"  rPPG BPM: {rppg_bpm:.2f}\")\n",
    "            print(f\"  MAE: {bpm_MAE:.2f}\")\n",
    "\n",
    "            # raw_bvp_singalとfiltered_bvp_signalの尖度と歪度を計算\n",
    "            if raw_bvp_signal_in_window is not None:\n",
    "                raw_bvp_kurtosis = scipy.stats.kurtosis(raw_bvp_signal_in_window)\n",
    "                raw_bvp_skewness = scipy.stats.skew(raw_bvp_signal_in_window)\n",
    "                filtered_bvp_kurtosis = scipy.stats.kurtosis(filtered_bvp_signal_in_window)\n",
    "                filtered_bvp_skewness = scipy.stats.skew(filtered_bvp_signal_in_window)\n",
    "\n",
    "            # 窓情報を保存\n",
    "            window_info = {\n",
    "                'window_index': idx,\n",
    "                'bvp_method': bvpMethodName,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'saturation_signal_in_window': array_to_full_string(saturation_signal_in_window),\n",
    "                'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window),\n",
    "                'raw_bvp_in_window': raw_bvp_signal_in_window,\n",
    "                'filtered_bvp_in_window': filtered_bvp_signal_in_window,\n",
    "                'ecg_bpm_in_window': ecg_bpm_in_window,\n",
    "                'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "                'rppg_bpm': rppg_bpm,\n",
    "                'bpm_MAE': bpm_MAE,\n",
    "                'max_freq': fft_result_dic['max_freq'],\n",
    "                'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "                'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "                'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "                'total_power': fft_result_dic['total_power'],\n",
    "                'raw_bvp_kurtosis': raw_bvp_kurtosis,\n",
    "                'raw_bvp_skewness': raw_bvp_skewness,\n",
    "                'filtered_bvp_kurtosis': filtered_bvp_kurtosis,\n",
    "                'filtered_bvp_skewness': filtered_bvp_skewness\n",
    "            }\n",
    "            all_window_results.append(window_info)\n",
    "    \n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'window_analysis_{dataName}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6b4c1",
   "metadata": {},
   "source": [
    "### 現段階の成果物\n",
    "- extracted_signals\n",
    "- window_signals\n",
    "- window_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885455c",
   "metadata": {},
   "source": [
    "### 相関解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(value_str):\n",
    "    \"\"\"文字列から配列を抽出し、統計量を計算\"\"\"\n",
    "    if pd.isnull(value_str):\n",
    "        return pd.Series([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    \n",
    "    try:\n",
    "        values = np.fromstring(value_str[1:-1], sep=' ')\n",
    "        mean_val = values.mean()\n",
    "        std_val = values.std()\n",
    "        max_val = values.max()\n",
    "        min_val = values.min()\n",
    "        iqr_val = np.percentile(values, 75) - np.percentile(values, 25)\n",
    "        return pd.Series([mean_val, std_val, max_val, min_val, iqr_val])\n",
    "    except:\n",
    "        return pd.Series([np.nan, np.nan, np.nan, np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_mae_correlations(df, feature_names, save_path=None, title_prefix=\"\", top_n=20):\n",
    "    \"\"\"\n",
    "    各特徴量とMAEの相関を計算し、可視化\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        特徴量とbpm_MAEを含むDataFrame\n",
    "    feature_names : list\n",
    "        特徴量の列名リスト\n",
    "    save_path : str or None\n",
    "        保存先パス\n",
    "    title_prefix : str\n",
    "        タイトルの接頭辞\n",
    "    top_n : int\n",
    "        表示する上位特徴量の数\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    corr_df : pd.DataFrame\n",
    "        相関係数のDataFrame\n",
    "    \"\"\"\n",
    "    if 'bpm_MAE' not in df.columns:\n",
    "        print(\"警告: bpm_MAE列が見つかりません。\")\n",
    "        return None\n",
    "    \n",
    "    # 相関を計算\n",
    "    correlations = []\n",
    "    for feature in feature_names:\n",
    "        if feature in df.columns:\n",
    "            # 欠損値を除外\n",
    "            valid_mask = df[feature].notna() & df['bpm_MAE'].notna()\n",
    "            if valid_mask.sum() > 10:  # 最低10サンプル必要\n",
    "                try:\n",
    "                    corr = df.loc[valid_mask, feature].corr(df.loc[valid_mask, 'bpm_MAE'])\n",
    "                    # NaNでない場合のみ追加\n",
    "                    if not np.isnan(corr):\n",
    "                        correlations.append({\n",
    "                            'feature': feature,\n",
    "                            'correlation': corr,\n",
    "                            'abs_correlation': abs(corr),\n",
    "                            'n_samples': valid_mask.sum()\n",
    "                        })\n",
    "                        print(f\"{feature} と MAE の相関: {corr:.4f} (サンプル数: {valid_mask.sum()})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"警告: {feature} の相関計算でエラー: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # correlationsが空の場合の処理\n",
    "    if len(correlations) == 0:\n",
    "        print(f\"警告: {title_prefix}有効な相関が計算できませんでした。\")\n",
    "        return None\n",
    "    \n",
    "    # DataFrameに変換してソート\n",
    "    corr_df = pd.DataFrame(correlations).sort_values('abs_correlation', ascending=False)\n",
    "    \n",
    "    # 上位を表示\n",
    "    print(f\"\\n=== {title_prefix}MAEと相関が強い特徴量 Top {min(top_n, len(corr_df))} ===\")\n",
    "    print(corr_df.head(top_n).to_string(index=False))\n",
    "    \n",
    "    # 可視化\n",
    "    top_n_actual = min(top_n, len(corr_df))\n",
    "    plt.figure(figsize=(12, max(8, top_n_actual * 0.4)))\n",
    "    top_features = corr_df.head(top_n_actual)\n",
    "    colors = ['red' if x < 0 else 'blue' for x in top_features['correlation'].values]\n",
    "    plt.barh(range(len(top_features)), top_features['correlation'].values, color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'].values, fontsize=10)\n",
    "    plt.xlabel('Correlation with MAE', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title(f'{title_prefix}Top {top_n_actual} Features Correlated with MAE', fontsize=14)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"相関グラフを保存: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "\n",
    "def plot_window_param_mae_time_series(df, feature_names=None, top_n=5, corr_df=None, \n",
    "                                       save_path=None, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    上位相関特徴量とMAEの時系列プロット\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        特徴量とbpm_MAEを含むDataFrame\n",
    "    feature_names : list or None\n",
    "        特徴量のリスト（Noneの場合はcorr_dfから取得）\n",
    "    top_n : int\n",
    "        プロットする特徴量の数\n",
    "    corr_df : pd.DataFrame or None\n",
    "        相関係数のDataFrame\n",
    "    save_path : str or None\n",
    "        保存先パス\n",
    "    title_prefix : str\n",
    "        タイトルの接頭辞\n",
    "    \"\"\"\n",
    "    if 'bpm_MAE' not in df.columns:\n",
    "        print(\"警告: bpm_MAE列が見つかりません。\")\n",
    "        return\n",
    "    \n",
    "    # 上位特徴量を取得\n",
    "    if corr_df is not None and len(corr_df) > 0:\n",
    "        top_n_actual = min(top_n, len(corr_df))\n",
    "        top_features = corr_df.head(top_n_actual)['feature'].values\n",
    "    elif feature_names is not None:\n",
    "        top_n_actual = min(top_n, len(feature_names))\n",
    "        top_features = feature_names[:top_n_actual]\n",
    "    else:\n",
    "        print(\"警告: プロットする特徴量が指定されていません。\")\n",
    "        return\n",
    "    \n",
    "    # window_start_timeがない場合はスキップ\n",
    "    if 'window_start_time' not in df.columns:\n",
    "        print(\"警告: window_start_time列が見つかりません。時系列プロットをスキップします。\")\n",
    "        return\n",
    "    \n",
    "    # プロット\n",
    "    fig, axes = plt.subplots(top_n_actual + 1, 1, figsize=(14, 3*(top_n_actual + 1)))\n",
    "    \n",
    "    if top_n_actual == 0:\n",
    "        axes = [axes]\n",
    "    elif not isinstance(axes, np.ndarray):\n",
    "        axes = [axes]\n",
    "    \n",
    "    # MAEをプロット\n",
    "    if 'data_name' in df.columns and df['data_name'].nunique() > 1:\n",
    "        for data_name in df['data_name'].unique():\n",
    "            data_subset = df[df['data_name'] == data_name].sort_values('window_start_time')\n",
    "            axes[0].plot(data_subset['window_start_time'], data_subset['bpm_MAE'], \n",
    "                        label=data_name, alpha=0.7, marker='o', markersize=3)\n",
    "        axes[0].legend(loc='upper right', fontsize=8)\n",
    "    else:\n",
    "        df_sorted = df.sort_values('window_start_time')\n",
    "        axes[0].plot(df_sorted['window_start_time'], df_sorted['bpm_MAE'], \n",
    "                    alpha=0.7, marker='o', markersize=3)\n",
    "    \n",
    "    axes[0].set_ylabel('BPM MAE', fontsize=12)\n",
    "    axes[0].set_xlabel('Window Start Time (s)', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_title('MAE', fontsize=11)\n",
    "    \n",
    "    # 各特徴量をプロット\n",
    "    for i, feature in enumerate(top_features, start=1):\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        if 'data_name' in df.columns and df['data_name'].nunique() > 1:\n",
    "            for data_name in df['data_name'].unique():\n",
    "                data_subset = df[df['data_name'] == data_name].sort_values('window_start_time')\n",
    "                axes[i].plot(data_subset['window_start_time'], data_subset[feature], \n",
    "                            label=data_name, alpha=0.7, marker='o', markersize=3)\n",
    "        else:\n",
    "            df_sorted = df.sort_values('window_start_time')\n",
    "            axes[i].plot(df_sorted['window_start_time'], df_sorted[feature], \n",
    "                        alpha=0.7, marker='o', markersize=3)\n",
    "        \n",
    "        axes[i].set_ylabel(feature, fontsize=10)\n",
    "        axes[i].set_xlabel('Window Start Time (s)', fontsize=12)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 相関係数を表示\n",
    "        if corr_df is not None:\n",
    "            corr_row = corr_df[corr_df['feature'] == feature]\n",
    "            if not corr_row.empty:\n",
    "                corr_val = corr_row['correlation'].values[0]\n",
    "                axes[i].set_title(f'{feature} (r={corr_val:.3f})', fontsize=11)\n",
    "    \n",
    "    plt.suptitle(f'{title_prefix}Top Features and MAE Time Series', fontsize=14, y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"時系列グラフを保存: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_param_vs_mae(df, feature_names=None, top_n=9, corr_df=None, \n",
    "                      save_path=None, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    上位相関特徴量とMAEの散布図（3x3グリッド）\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        特徴量とbpm_MAEを含むDataFrame\n",
    "    feature_names : list or None\n",
    "        特徴量のリスト\n",
    "    top_n : int\n",
    "        プロットする特徴量の数\n",
    "    corr_df : pd.DataFrame or None\n",
    "        相関係数のDataFrame\n",
    "    save_path : str or None\n",
    "        保存先パス\n",
    "    title_prefix : str\n",
    "        タイトルの接頭辞\n",
    "    \"\"\"\n",
    "    if 'bpm_MAE' not in df.columns:\n",
    "        print(\"警告: bpm_MAE列が見つかりません。\")\n",
    "        return\n",
    "    \n",
    "    # 上位特徴量を取得\n",
    "    if corr_df is not None and len(corr_df) > 0:\n",
    "        top_n_actual = min(top_n, len(corr_df))\n",
    "        top_features = corr_df.head(top_n_actual)['feature'].values\n",
    "    elif feature_names is not None:\n",
    "        top_n_actual = min(top_n, len(feature_names))\n",
    "        top_features = feature_names[:top_n_actual]\n",
    "    else:\n",
    "        print(\"警告: プロットする特徴量が指定されていません。\")\n",
    "        return\n",
    "    \n",
    "    # グリッドサイズを計算\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(top_features) / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    \n",
    "    # axesを1次元配列に変換\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif n_rows == 1 or n_cols == 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(top_features):\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 窓サイズごとに色分け\n",
    "        if 'window_size' in df.columns and df['window_size'].nunique() > 1:\n",
    "            for window_size in sorted(df['window_size'].unique()):\n",
    "                data_subset = df[df['window_size'] == window_size]\n",
    "                ax.scatter(data_subset[feature], data_subset['bpm_MAE'], \n",
    "                          label=f'{window_size}s', alpha=0.6, s=30)\n",
    "            ax.legend(title='Window', fontsize=8)\n",
    "        else:\n",
    "            ax.scatter(df[feature], df['bpm_MAE'], alpha=0.6, s=30)\n",
    "        \n",
    "        ax.set_xlabel(feature, fontsize=10)\n",
    "        ax.set_ylabel('BPM MAE', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 相関係数を表示\n",
    "        if corr_df is not None:\n",
    "            corr_row = corr_df[corr_df['feature'] == feature]\n",
    "            if not corr_row.empty:\n",
    "                corr_val = corr_row['correlation'].values[0]\n",
    "                ax.set_title(f'r={corr_val:.3f}', fontsize=11)\n",
    "    \n",
    "    # 余分なサブプロットを非表示\n",
    "    for idx in range(len(top_features), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{title_prefix}Top Features vs MAE', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"散布図を保存: {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_window_data(dataFrameArrays, data_names, exclude_cols=None, array_cols=None):\n",
    "    \"\"\"\n",
    "    窓の特徴量CSVファイルを読み込み\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataFrameArrays : list of sdataframes\n",
    "        窓特徴量のDataFrameリスト\n",
    "    data_names : list of str\n",
    "        各DataFrameに対応するデータ名リスト\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    all_data : pd.DataFrame\n",
    "        統合されたデータ\n",
    "    feature_names : list\n",
    "        特徴量の列名リスト\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for df, data_name in zip(dataFrameArrays, data_names):\n",
    "        df['data_name'] = data_name\n",
    "        all_data.append(df)\n",
    "    \n",
    "    # データを統合\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    exclude_cols.extend(array_cols)\n",
    "    \n",
    "    feature_names = [col for col in combined_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    return combined_df, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ffa88d",
   "metadata": {},
   "source": [
    "動画別 × 窓長ごとに相関解析 + 全体×窓長ごとに相関解析してTOP10を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08637c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"動画: {dataName}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # window_analysis (MAEを含む)のCSVを読み込み\n",
    "    window_analysis_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_analysis_{dataName}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_analysis_csv_path):\n",
    "        print(f\"警告: {window_analysis_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "    \n",
    "    # window_analysis_dataframeを読み込み（MAEを含む）\n",
    "    print(\"窓解析データを読み込み中...\")\n",
    "    window_analysis_dataframe = pd.read_csv(window_analysis_csv_path)\n",
    "    \n",
    "    # window_signals (特徴量)のCSVを読み込み\n",
    "    window_signals_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_signals_{dataName}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_signals_csv_path):\n",
    "        print(f\"警告: {window_signals_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    # =====================特徴量データを読み込み======================\n",
    "    window_signals_dataframe = pd.read_csv(window_signals_csv_path)\n",
    "    \n",
    "    # 時系列データの統計量を計算して特徴量に追加\n",
    "    array_cols = [\n",
    "        'r_signal_in_window', 'g_signal_in_window', 'b_signal_in_window',\n",
    "        'r_std_signal_in_window', 'g_std_signal_in_window', 'b_std_signal_in_window',\n",
    "        'h_signal_in_window', 's_signal_in_window', 'v_signal_in_window',\n",
    "        'h_std_signal_in_window', 's_std_signal_in_window', 'v_std_signal_in_window',\n",
    "        'lightness_signal_in_window', \n",
    "        'lbp_entropy', 'lbp_variance', 'lbp_skewness', 'lbp_kurtosis',\n",
    "        'lbp_chi2_distance', 'lbp_uniform_ratio',\n",
    "        'canny_edge_ratio', 'glcm_isotropy',\n",
    "        'flow_mean_motion', 'flow_std_motion', 'flow_ratio_1px', 'flow_ratio_5px', 'flow_ratio_10px',\n",
    "        'wavelet_hh_energies', 'fft_high_freq_ratios',\n",
    "        'angles_in_window'\n",
    "    ]\n",
    "    \n",
    "    # それぞれに対して集約統計量を計算\n",
    "    for col in array_cols:\n",
    "        if col in window_signals_dataframe.columns:\n",
    "            print(f\"処理中: {col}\")\n",
    "            stats_df = window_signals_dataframe[col].apply(calculate_stats)\n",
    "            stats_df.columns = [f'{col}_mean', f'{col}_std', f'{col}_max', f'{col}_min', f'{col}_iqr']\n",
    "            window_signals_dataframe = pd.concat([window_signals_dataframe, stats_df], axis=1)\n",
    "    \n",
    "    # window_indexでマージして、MAEを追加\n",
    "    window_signals_dataframe = pd.merge(\n",
    "        window_signals_dataframe, \n",
    "        window_analysis_dataframe[['window_index', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm']],\n",
    "        on='window_index',\n",
    "        how='left'\n",
    "    )\n",
    "    print(window_analysis_dataframe.head())\n",
    "\n",
    "\n",
    "    # =====================窓特徴量データを読み込み==========================\n",
    "    df_all, feature_names = load_window_data(\n",
    "        dataFrameArrays=[window_signals_dataframe],\n",
    "        data_names=[dataName],\n",
    "        exclude_cols=[\n",
    "            'window_index', 'window_size', 'stride', 'frame_start', 'frame_end',\n",
    "            'window_start_time', 'window_end_time', 'data_name', 'ecg_bpm_in_window', 'ecg_bpm_in_window_mean', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm'\n",
    "        ],\n",
    "        array_cols=array_cols\n",
    "    )\n",
    "\n",
    "    print(f\"特徴量数: {len(feature_names)}\")\n",
    "    \n",
    "    # =====================窓長ごとに指標とMAEの相関を計算=====================\n",
    "    for window_size in WINDOW_SIZES:\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"窓長: {window_size}秒\")\n",
    "        print(f\"{'─'*60}\")\n",
    "        \n",
    "        # 該当する窓長のデータのみを抽出\n",
    "        df_window = df_all[df_all['window_size'] == window_size].copy()\n",
    "        \n",
    "        if len(df_window) == 0:\n",
    "            print(f\"警告: 窓長{window_size}秒のデータがありません。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"データ数: {len(df_window)} 窓\")\n",
    "        \n",
    "        # 保存ディレクトリ\n",
    "        save_dir = os.path.join(rootDir, SAVE_DIR, 'corr_window_analysis', \n",
    "                               f'per_video_per_window', f'{dataName}_window_{window_size}s')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 相関解析\n",
    "        corr_df = calculate_feature_mae_correlations(\n",
    "            df_window, \n",
    "            feature_names,\n",
    "            save_path=os.path.join(save_dir, \"feature_mae_correlations.png\"),\n",
    "            title_prefix=f\"{dataName} - {window_size}s: \",\n",
    "            top_n=20\n",
    "        )\n",
    "\n",
    "            # CSVに保存\n",
    "        corr_df.to_csv(os.path.join(save_dir, \"feature_mae_correlations.csv\"), index=False, encoding='utf-8-sig')\n",
    "        print(f\"相関係数CSVを保存: {os.path.join(save_dir, 'feature_mae_correlations.csv')}\")\n",
    "\n",
    "        # MAEと指標の時系列プロット\n",
    "        if corr_df is not None:\n",
    "            plot_window_param_mae_time_series(\n",
    "                df_window,\n",
    "                top_n=5,\n",
    "                corr_df=corr_df,\n",
    "                save_path=os.path.join(save_dir, \"param_mae_time_series.png\"),\n",
    "                title_prefix=f\"{dataName} - {window_size}s: \"\n",
    "            )\n",
    "            \n",
    "            # ===== 指標-MAE散布図 =====\n",
    "            print(\"\\n[MAE分析]\")\n",
    "            plot_param_vs_mae(\n",
    "                df_window,\n",
    "                top_n=9,\n",
    "                corr_df=corr_df,\n",
    "                save_path=os.path.join(save_dir, \"param_vs_mae_scatter.png\"),\n",
    "                title_prefix=f\"{dataName} - {window_size}s: \"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63d0f3",
   "metadata": {},
   "source": [
    "パターン2: 全動画を統合 × 窓長ごとに相関解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd921412",
   "metadata": {},
   "source": [
    "ここ実行前にpath関連を全動画に変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"パターン3: 全動画を統合 × 窓長ごとに相関解析\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_dataframes = []\n",
    "all_data_names = []\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    \n",
    "    window_analysis_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_analysis_{dataName}.csv')\n",
    "    window_signals_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_signals_{dataName}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_analysis_csv_path) or not os.path.exists(window_signals_csv_path):\n",
    "        print(f\"警告: {dataName} のファイルが見つかりません。スキップします。\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"読み込み中: {dataName}\")\n",
    "    \n",
    "    window_analysis_dataframe = pd.read_csv(window_analysis_csv_path)\n",
    "    window_signals_dataframe = pd.read_csv(window_signals_csv_path)\n",
    "    \n",
    "    array_cols = [\n",
    "        'r_signal_in_window', 'g_signal_in_window', 'b_signal_in_window',\n",
    "        'r_std_signal_in_window', 'g_std_signal_in_window', 'b_std_signal_in_window',\n",
    "        'h_signal_in_window', 's_signal_in_window', 'v_signal_in_window',\n",
    "        'h_std_signal_in_window', 's_std_signal_in_window', 'v_std_signal_in_window',\n",
    "        'lightness_signal_in_window', \n",
    "        'lbp_entropy', 'lbp_variance', 'lbp_skewness', 'lbp_kurtosis',\n",
    "        'lbp_chi2_distance', 'lbp_uniform_ratio',\n",
    "        'canny_edge_ratio', 'glcm_isotropy',\n",
    "        'flow_mean_motion', 'flow_std_motion', 'flow_ratio_1px', 'flow_ratio_5px', 'flow_ratio_10px',\n",
    "        'wavelet_hh_energies', 'fft_high_freq_ratios',\n",
    "        'angles_in_window'\n",
    "    ]\n",
    "    \n",
    "    for col in array_cols:\n",
    "        if col in window_signals_dataframe.columns:\n",
    "            print(f\"  処理中: {col}\")\n",
    "            stats_df = window_signals_dataframe[col].apply(calculate_stats)\n",
    "            stats_df.columns = [f'{col}_mean', f'{col}_std', f'{col}_max', f'{col}_min', f'{col}_iqr']\n",
    "            window_signals_dataframe = pd.concat([window_signals_dataframe, stats_df], axis=1)\n",
    "    \n",
    "    # valid_g_signalとvalid_canny_signalのノイズ特徴量を計算\n",
    "    print(f\"  === {dataName}: ノイズ特徴量の計算 ===\")\n",
    "    \n",
    "    long_noise_threshold_array = [15, 30]\n",
    "    \n",
    "    # MAEを追加\n",
    "    window_signals_dataframe = pd.merge(\n",
    "        window_signals_dataframe, \n",
    "        window_analysis_dataframe[['window_index', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm']],\n",
    "        on='window_index',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    all_dataframes.append(window_signals_dataframe)\n",
    "    all_data_names.append(dataName)\n",
    "\n",
    "print(f\"\\n読み込んだ動画数: {len(all_dataframes)}\")\n",
    "\n",
    "df_all_videos, feature_names = load_window_data(\n",
    "    all_dataframes, \n",
    "    all_data_names, \n",
    "    array_cols=array_cols,\n",
    "    exclude_cols=[\n",
    "        'window_index', 'window_size', 'stride', 'frame_start', 'frame_end',\n",
    "        'window_start_time', 'window_end_time', 'data_name', 'ecg_bpm_in_window', 'ecg_bpm_in_window_mean', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm'\n",
    "    ])\n",
    "\n",
    "print(f\"\\n全動画統合データ数: {len(df_all_videos)} 窓\")\n",
    "print(f\"特徴量数: {len(feature_names)}\")\n",
    "print(f\"動画別の内訳: {df_all_videos['data_name'].value_counts().to_dict()}\")\n",
    "\n",
    "for window_size in WINDOW_SIZES:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"窓長: {window_size}秒（全動画統合）\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    df_window = df_all_videos[df_all_videos['window_size'] == window_size].copy()\n",
    "    \n",
    "    if len(df_window) == 0:\n",
    "        print(f\"警告: 窓長{window_size}秒のデータがありません。スキップします。\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"データ数: {len(df_window)} 窓\")\n",
    "    print(f\"動画別の内訳: {df_window['data_name'].value_counts().to_dict()}\")\n",
    "    \n",
    "    save_dir = os.path.join('corr_window_analysis_combined',f'window_{window_size}s')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 相関解析\n",
    "    corr_df = calculate_feature_mae_correlations(\n",
    "        df_window, \n",
    "        feature_names,\n",
    "        save_path=os.path.join(save_dir, \"feature_mae_correlations.png\"),\n",
    "        title_prefix=f\"全動画 - {window_size}s: \",\n",
    "        top_n=20\n",
    "    )\n",
    "    \n",
    "    # MAEと指標の時系列プロット\n",
    "    if corr_df is not None:\n",
    "        plot_window_param_mae_time_series(\n",
    "            df_window,\n",
    "            top_n=5,\n",
    "            corr_df=corr_df,\n",
    "            save_path=os.path.join(save_dir, \"param_mae_time_series.png\"),\n",
    "            title_prefix=f\"全動画 - {window_size}s: \"\n",
    "        )\n",
    "        \n",
    "        # ===== パラメータ-MAE散布図 =====\n",
    "        print(\"\\n[MAE分析]\")\n",
    "        plot_param_vs_mae(\n",
    "            df_window,\n",
    "            top_n=9,\n",
    "            corr_df=corr_df,\n",
    "            save_path=os.path.join(save_dir, \"param_vs_mae_scatter.png\"),\n",
    "            title_prefix=f\"全動画 - {window_size}s: \"\n",
    "        )\n",
    "    \n",
    "    # 動画別の上位特徴量の分布\n",
    "    if corr_df is not None and len(corr_df) > 0:\n",
    "        # 上位3つの特徴量について動画別分布を可視化\n",
    "        top_n_features = min(3, len(corr_df))\n",
    "        \n",
    "        fig, axes = plt.subplots(1, top_n_features, figsize=(6*top_n_features, 6))\n",
    "        if top_n_features == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx in range(top_n_features):\n",
    "            top_feature = corr_df.iloc[idx]['feature']\n",
    "            correlation = corr_df.iloc[idx]['correlation']\n",
    "            \n",
    "            ax = axes[idx]\n",
    "            df_window.boxplot(column=top_feature, by='data_name', ax=ax)\n",
    "            ax.set_title(f'{top_feature}\\n(相関: {correlation:.3f})')\n",
    "            ax.set_xlabel('Video')\n",
    "            ax.set_ylabel(top_feature)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            plt.sca(ax)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        plt.suptitle(f'全動画 - {window_size}s: 上位特徴量の動画別分布')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, \"top_features_by_video.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"パターン3完了\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640079ce",
   "metadata": {},
   "source": [
    "### 偏相関解析(今回は1つの変数で蒸気の有無を予測するのでしなくてよい)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cad970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_correlations(df, target_col, feature_cols, method='pearson'):\n",
    "    \"\"\"\n",
    "    各特徴量と目標変数の偏相関係数を計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        データフレーム\n",
    "    target_col : str\n",
    "        目標変数のカラム名 (例: 'bpm_MAE')\n",
    "    feature_cols : list\n",
    "        特徴量のカラム名リスト (上位N個)\n",
    "    method : str\n",
    "        相関係数の種類 ('pearson', 'spearman')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        カラム: ['feature', 'simple_corr', 'partial_corr', 'p_value', 'diff']\n",
    "        - simple_corr: 単純相関係数\n",
    "        - partial_corr: 偏相関係数\n",
    "        - p_value: 偏相関のp値\n",
    "        - diff: simple_corr - partial_corr (減少量)\n",
    "    \"\"\"\n",
    "    import pingouin as pg\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 欠損値を除去\n",
    "    df_clean = df[[target_col] + feature_cols].dropna()\n",
    "    \n",
    "    for feature in feature_cols:\n",
    "        # 単純相関\n",
    "        simple_corr = df_clean[feature].corr(df_clean[target_col], method=method)\n",
    "        \n",
    "        # 偏相関: 他の全特徴量を制御変数として使用\n",
    "        covar = [f for f in feature_cols if f != feature]\n",
    "        \n",
    "        partial_result = pg.partial_corr(\n",
    "            data=df_clean,\n",
    "            x=feature,\n",
    "            y=target_col,\n",
    "            covar=covar,\n",
    "            method=method\n",
    "        )\n",
    "        \n",
    "        partial_corr = partial_result['r'].values[0]\n",
    "        p_value = partial_result['p-val'].values[0]\n",
    "        \n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'simple_corr': simple_corr,\n",
    "            'partial_corr': partial_corr,\n",
    "            'p_value': p_value,\n",
    "            'diff': simple_corr - partial_corr\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('partial_corr', key=abs, ascending=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_vs_partial_correlation(results_df, save_path=None, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    単純相関と偏相関の比較を可視化\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        calculate_partial_correlations() の出力\n",
    "    save_path : str\n",
    "        保存先パス\n",
    "    title_prefix : str\n",
    "        タイトルの接頭辞\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # ===== 左: 単純相関 vs 偏相関の棒グラフ =====\n",
    "    ax1 = axes[0]\n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.barh(x - width/2, results_df['simple_corr'].abs(), \n",
    "                     width, label='単純相関', alpha=0.8, color='steelblue')\n",
    "    bars2 = ax1.barh(x + width/2, results_df['partial_corr'].abs(), \n",
    "                     width, label='偏相関', alpha=0.8, color='coral')\n",
    "    \n",
    "    ax1.set_yticks(x)\n",
    "    ax1.set_yticklabels(results_df['feature'], fontsize=9)\n",
    "    ax1.set_xlabel('相関係数の絶対値', fontsize=11)\n",
    "    ax1.set_title(f'{title_prefix}単純相関 vs 偏相関', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # ===== 右: 相関の減少量 =====\n",
    "    ax2 = axes[1]\n",
    "    colors = ['red' if d > 0 else 'green' for d in results_df['diff']]\n",
    "    \n",
    "    ax2.barh(results_df['feature'], results_df['diff'], color=colors, alpha=0.7)\n",
    "    ax2.set_xlabel('減少量 (単純相関 - 偏相関)', fontsize=11)\n",
    "    ax2.set_title(f'{title_prefix}相関係数の減少量', fontsize=12, fontweight='bold')\n",
    "    ax2.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    # 注釈\n",
    "    ax2.text(0.98, 0.02, '正: 他の特徴量との相関が高い\\n負: 独立性が高い', \n",
    "             transform=ax2.transAxes, fontsize=9, \n",
    "             verticalalignment='bottom', horizontalalignment='right',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"保存完了: {save_path}\")\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6182b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"動画: {dataName}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # window_analysis (MAEを含む)のCSVを読み込み\n",
    "    window_analysis_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_analysis_{dataName}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_analysis_csv_path):\n",
    "        print(f\"警告: {window_analysis_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "    \n",
    "    # window_analysis_dataframeを読み込み(MAEを含む)\n",
    "    print(\"窓解析データを読み込み中...\")\n",
    "    window_analysis_dataframe = pd.read_csv(window_analysis_csv_path)\n",
    "    \n",
    "    # window_signals (特徴量)のCSVを読み込み\n",
    "    window_signals_csv_path = os.path.join(rootDir, SAVE_DIR, f'window_signals_{dataName}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_signals_csv_path):\n",
    "        print(f\"警告: {window_signals_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    # =====================特徴量データを読み込み======================\n",
    "    window_signals_dataframe = pd.read_csv(window_signals_csv_path)\n",
    "    \n",
    "    # 時系列データの統計量を計算して特徴量に追加\n",
    "    array_cols = [\n",
    "        'r_signal_in_window', 'g_signal_in_window', 'b_signal_in_window',\n",
    "        'r_std_signal_in_window', 'g_std_signal_in_window', 'b_std_signal_in_window',\n",
    "        'h_signal_in_window', 's_signal_in_window', 'v_signal_in_window',\n",
    "        'h_std_signal_in_window', 's_std_signal_in_window', 'v_std_signal_in_window',\n",
    "        'lightness_signal_in_window', \n",
    "        'lbp_entropy', 'lbp_variance', 'lbp_skewness', 'lbp_kurtosis',\n",
    "        'lbp_chi2_distance', 'lbp_uniform_ratio',\n",
    "        'canny_edge_ratio', 'glcm_isotropy',\n",
    "        'flow_mean_motion', 'flow_std_motion', 'flow_ratio_1px', 'flow_ratio_5px', 'flow_ratio_10px',\n",
    "        'wavelet_hh_energies', 'fft_high_freq_ratios',\n",
    "        'angles_in_window'\n",
    "    ]\n",
    "    \n",
    "    # それぞれに対して集約統計量を計算\n",
    "    for col in array_cols:\n",
    "        if col in window_signals_dataframe.columns:\n",
    "            print(f\"処理中: {col}\")\n",
    "            stats_df = window_signals_dataframe[col].apply(calculate_stats)\n",
    "            stats_df.columns = [f'{col}_mean', f'{col}_std', f'{col}_max', f'{col}_min', f'{col}_iqr']\n",
    "            window_signals_dataframe = pd.concat([window_signals_dataframe, stats_df], axis=1)\n",
    "    \n",
    "    # window_indexでマージして、MAEを追加\n",
    "    window_signals_dataframe = pd.merge(\n",
    "        window_signals_dataframe, \n",
    "        window_analysis_dataframe[['window_index', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm']],\n",
    "        on='window_index',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # =====================窓特徴量データを読み込み==========================\n",
    "    df_all, feature_names = load_window_data(\n",
    "        dataFrameArrays=[window_signals_dataframe],\n",
    "        data_names=[dataName],\n",
    "        exclude_cols=[\n",
    "            'window_index', 'window_size', 'stride', 'frame_start', 'frame_end',\n",
    "            'window_start_time', 'window_end_time', 'data_name', 'ecg_bpm_in_window', \n",
    "            'ecg_bpm_in_window_mean', 'bpm_MAE', 'ecg_bpm_mean', 'rppg_bpm'\n",
    "        ],\n",
    "        array_cols=array_cols\n",
    "    )\n",
    "\n",
    "    print(f\"特徴量数: {len(feature_names)}\")\n",
    "    \n",
    "    # =====================窓長ごとに偏相関解析=====================\n",
    "    for window_size in WINDOW_SIZES:\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"窓長: {window_size}秒\")\n",
    "        print(f\"{'─'*60}\")\n",
    "        \n",
    "        # 該当する窓長のデータのみを抽出\n",
    "        df_window = df_all[df_all['window_size'] == window_size].copy()\n",
    "        \n",
    "        if len(df_window) == 0:\n",
    "            print(f\"警告: 窓長{window_size}秒のデータがありません。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"データ数: {len(df_window)} 窓\")\n",
    "        \n",
    "        # 保存ディレクトリ\n",
    "        save_dir = os.path.join(rootDir, SAVE_DIR, 'corr_window_analysis', \n",
    "                               f'per_video_per_window', f'{dataName}_window_{window_size}s')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 相関解析結果を読み込み\n",
    "        corr_csv_path = os.path.join(save_dir, 'feature_mae_correlations.csv')\n",
    "        \n",
    "        if not os.path.exists(corr_csv_path):\n",
    "            print(f\"警告: {corr_csv_path} が見つかりません。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        print(\"相関解析データを読み込み中...\")\n",
    "        corr_df = pd.read_csv(corr_csv_path)\n",
    "        \n",
    "        # ===== 偏相関解析 (新規) =====\n",
    "        print(\"\\n[偏相関解析]\")\n",
    "        \n",
    "        # 上位10特徴量を取得\n",
    "        top_features = corr_df.head(10)['feature'].tolist()\n",
    "        print(f\"上位10特徴量: {top_features}\")\n",
    "        \n",
    "        # 偏相関を計算\n",
    "        try:\n",
    "            partial_corr_df = calculate_partial_correlations(\n",
    "                df=df_window,\n",
    "                target_col='bpm_MAE',\n",
    "                feature_cols=top_features,\n",
    "                method='pearson'\n",
    "            )\n",
    "            \n",
    "            # 結果を表示\n",
    "            print(\"\\n偏相関解析結果:\")\n",
    "            print(partial_corr_df.to_string(index=False))\n",
    "            \n",
    "            # 可視化\n",
    "            plot_simple_vs_partial_correlation(\n",
    "                results_df=partial_corr_df,\n",
    "                save_path=os.path.join(save_dir, \"simple_vs_partial_correlation.png\"),\n",
    "                title_prefix=f\"{dataName} - {window_size}s: \"\n",
    "            )\n",
    "            \n",
    "            # CSVとして保存\n",
    "            partial_corr_df.to_csv(\n",
    "                os.path.join(save_dir, \"partial_correlations.csv\"),\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"偏相関結果を保存しました: {save_dir}/partial_correlations.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"エラー: 偏相関計算中にエラーが発生しました: {e}\")\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvhr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
