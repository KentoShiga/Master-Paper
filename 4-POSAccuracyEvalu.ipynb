{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd82819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from scipy import signal, integrate\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.color import rgb2lab\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import pyVHR as vhr\n",
    "from pyVHR.extraction.sig_processing import SignalProcessing\n",
    "from pyVHR.plot.visualize import *\n",
    "from pyVHR.BVP import *\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'\n",
    "\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e77f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力とする動画と動画のファイル名を取得\n",
    "root_dir = \"experimentData\\\\\"\n",
    "data_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "movie_paths = []\n",
    "movie_names = []\n",
    "true_value_csv_array = []\n",
    "true_value_rri_csv_array = []\n",
    "print(\"動画ディレクトリ:\", data_dirs)\n",
    "\n",
    "for i in range(len(data_dirs)):\n",
    "    data_dir = data_dirs[i]\n",
    "\n",
    "    # 動画ファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.avi')]\n",
    "    movie_paths.extend(movie_files)\n",
    "\n",
    "    movie_name = os.path.basename(data_dir)\n",
    "    movie_names.append(movie_name)\n",
    "\n",
    "    # ppgファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    true_value_csv_array = [f.replace('.avi', '.csv') for f in movie_paths if f.endswith('.avi')]\n",
    "    true_value_rri_csv_array.append(os.path.join(data_dir, 'RRI_Simple_' + movie_name + '.csv'))\n",
    "\n",
    "\n",
    "f_1_ffi = 0.0399  # LFのはじめ\n",
    "f_2 = 0.151  # LFの終わり、HFのはじめ\n",
    "f_3 = 0.401  # HFの終わり\n",
    "\n",
    "start_index = 0\n",
    "# start_index = 17\n",
    "end_index = 2\n",
    "# end_index = len(movie_paths)\n",
    "# start_index = end_index - 1  # 最後の動画のみを対象とする\n",
    "\n",
    "data_dirs = data_dirs[start_index:end_index]\n",
    "movie_paths = movie_paths[start_index:end_index]\n",
    "movie_names = movie_names[start_index:end_index]\n",
    "true_value_csv_array = true_value_csv_array[start_index:end_index]\n",
    "true_value_rri_csv_array = true_value_rri_csv_array[start_index:end_index]\n",
    "\n",
    "print(f\"data_dirs: {data_dirs}\")\n",
    "print(f\"movie_paths: {movie_paths}\")\n",
    "print(f\"movie_names: {movie_names}\")\n",
    "print(f\"true_value_csv_array: {true_value_csv_array}\")\n",
    "print(f\"true_value_rri_csv_array: {true_value_rri_csv_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502add19",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR  = \"POSAccuracyEvalu\"\n",
    "SPLIT_TIME = 90\n",
    "WINDOW_SIZES = [2, 4, 6, 8, 10]\n",
    "STRIDES = [2]\n",
    "RPPG_ACCURACY_EVAL_DIR = \"rppgAccuracyEvalu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdee40",
   "metadata": {},
   "source": [
    "成果物\n",
    "- 1フレームずつのRGBシグナル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8d02d",
   "metadata": {},
   "source": [
    "## windowごとにRGB信号を分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_full_string(arr):\n",
    "    \"\"\"NumPy配列を省略なしの文字列に変換\"\"\"\n",
    "    if isinstance(arr, str):\n",
    "        return arr\n",
    "    elif isinstance(arr, (np.ndarray, list)):\n",
    "        # NumPy配列またはリストを完全な文字列に変換\n",
    "        arr_np = np.array(arr)\n",
    "        return np.array2string(arr_np, threshold=np.inf, max_line_width=np.inf, separator=' ')\n",
    "    else:\n",
    "        return str(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrideSegmentCalculator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_sizes: List[float] = [2, 3, 4, 5],\n",
    "        strides: List[float] = [0.1, 0.5, 1, 1.5, 2],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_sizes : List[float]\n",
    "            窓幅（秒）のリスト\n",
    "        strides : List[float]\n",
    "            移動秒数のリスト\n",
    "        \"\"\"\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "    def calculate_overlap(self, window_size: float, stride: float) -> float:\n",
    "        \"\"\"\n",
    "        窓幅と移動秒数からオーバーラップ率を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            オーバーラップ率（%）\n",
    "        \"\"\"\n",
    "        if stride >= window_size:\n",
    "            return 0\n",
    "        overlap = (window_size - stride) / window_size * 100\n",
    "        return round(overlap, 2)\n",
    "\n",
    "    def calculate_segments(\n",
    "        self, window_size: float, stride: float, total_frames: int, fps: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        フレーム数から解析区間を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple[int, int]]\n",
    "            各区間の(開始フレーム, 終了フレーム)のリスト\n",
    "        \"\"\"\n",
    "        frames_per_window = round(window_size * fps)\n",
    "        frames_per_stride = round(stride * fps)\n",
    "\n",
    "        segments = []\n",
    "        start_frame = 0\n",
    "\n",
    "        while start_frame + frames_per_window <= total_frames:\n",
    "            segments.append((start_frame, start_frame + frames_per_window))\n",
    "            start_frame += frames_per_stride\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def create_analysis_dataframe(self, total_frames: int, fps: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        全ての窓幅と移動秒数の組み合わせに対してDataFrameを生成\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            各条件でのセグメント情報を含むDataFrame\n",
    "            columns: window_size, stride, overlap, segment_number, frame_start, frame_end\n",
    "        \"\"\"\n",
    "        data_dict = {\n",
    "            \"window_size\": [],\n",
    "            \"stride\": [],\n",
    "            \"overlap\": [],\n",
    "            \"segment_number\": [],\n",
    "            \"frame_start\": [],\n",
    "            \"frame_end\": [],\n",
    "        }\n",
    "\n",
    "        for window_size in self.window_sizes:\n",
    "            for stride in self.strides:\n",
    "                overlap = self.calculate_overlap(window_size, stride)\n",
    "                segments = self.calculate_segments(\n",
    "                    window_size, stride, total_frames, fps\n",
    "                )\n",
    "\n",
    "                for i, (start_frame, end_frame) in enumerate(segments):\n",
    "                    data_dict[\"window_size\"].append(window_size)\n",
    "                    data_dict[\"stride\"].append(stride)\n",
    "                    data_dict[\"overlap\"].append(overlap)\n",
    "                    data_dict[\"segment_number\"].append(i)\n",
    "                    data_dict[\"frame_start\"].append(start_frame)\n",
    "                    data_dict[\"frame_end\"].append(end_frame)\n",
    "\n",
    "        return pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "class PulseAnalysisDataStrides:\n",
    "    def __init__(self, window_sizes, strides):\n",
    "        # 窓枠とストライドの値を定義\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "        # accuracyのみを格納するDataFrameを初期化\n",
    "        self.results = pd.DataFrame(\n",
    "            index=pd.Index(self.window_sizes, name=\"window_size\"),\n",
    "            columns=pd.Index(self.strides, name=\"strides\"),\n",
    "        )\n",
    "\n",
    "    def add_accuracy(self, window_size: float, strides: int, accuracy: float):\n",
    "        \"\"\"\n",
    "        精度データを追加する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        strides : int\n",
    "            ストライド（s）\n",
    "        accuracy : float\n",
    "            精度値\n",
    "        \"\"\"\n",
    "        self.results.loc[window_size, strides] = accuracy\n",
    "\n",
    "    def _create_heatmap_dataframe(self):\n",
    "        \"\"\"\n",
    "        ヒートマップ用のDataFrameを作成する内部メソッド\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            ヒートマップ用に整形されたDataFrame\n",
    "        \"\"\"\n",
    "        data = {\"stride\": self.strides}\n",
    "        for window_size in self.window_sizes:\n",
    "            data[window_size] = [\n",
    "                self.results.loc[window_size, stride] for stride in self.strides\n",
    "            ]\n",
    "        df = pd.DataFrame(data).set_index(\"stride\").T\n",
    "        return df\n",
    "\n",
    "    def save_heatmap(\n",
    "        self,\n",
    "        title: str,\n",
    "        save_path: str,\n",
    "        figsize: tuple = (10, 8),\n",
    "        cmap: str = \"YlGnBu\",\n",
    "        colorbar_label: str = \"MAE\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        cmap : str, optional\n",
    "            カラーマップ (default: 'YlGnBu')\n",
    "        colorbar_label : str, optional\n",
    "            カラーバーのラベル (default: 'MAE')\n",
    "        \"\"\"\n",
    "        df = self._create_heatmap_dataframe()\n",
    "\n",
    "        # ヒートマップを作成\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(\n",
    "            df, annot=True, fmt=\".4f\", cmap=cmap, cbar_kws={\"label\": colorbar_label}\n",
    "        )\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.xlabel(\"Stride [s]\")\n",
    "        plt.ylabel(\"Window Size [s]\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def save_heatmap_std(self, title: str, save_path: str, figsize: tuple = (10, 8)):\n",
    "        \"\"\"\n",
    "        標準偏差のヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        \"\"\"\n",
    "        self.save_heatmap(\n",
    "            title,\n",
    "            save_path,\n",
    "            figsize,\n",
    "            cmap=\"Reds\",\n",
    "            colorbar_label=\"Standard Deviation\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_list = []\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    window_signals_data_csv_path = os.path.join(rootDir, RPPG_ACCURACY_EVAL_DIR, f'window_signals_{dataName}.csv')\n",
    "    window_signals_df  = pd.read_csv(window_signals_data_csv_path)\n",
    "    print(window_signals_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d759bd0",
   "metadata": {},
   "source": [
    "## 窓ごとにBVP解析\n",
    "初期か処理のセクション2で同じことやってるので流用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8112dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    window_analysis_data_csv_path = os.path.join(rootDir, RPPG_ACCURACY_EVAL_DIR, f'window_signals_{dataName}.csv')\n",
    "    window_analysis_df = pd.read_csv(window_analysis_data_csv_path)\n",
    "    print(window_analysis_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f792c4",
   "metadata": {},
   "source": [
    "### 窓ごとに輝度変動成分を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac873fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_window_fft(values, fps):\n",
    "    \"\"\"\n",
    "    時系列データの最大周波数とスペクトル情報を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        分析対象の時系列データ\n",
    "    fps : int\n",
    "        サンプリング周波数（1秒あたりのフレーム数）\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        以下のキーを含む辞書：\n",
    "        - 'max_freq': 検出された最大周波数\n",
    "        - 'max_amplitude': 最大周波数のときの振幅\n",
    "        - 'frequencies': 周波数配列（正の周波数のみ）\n",
    "        - 'amplitudes': 振幅配列（正の周波数のみ）\n",
    "        - 'power_spectrum': パワースペクトル\n",
    "        - 'dominant_freqs': 上位5つの卓越周波数とその振幅\n",
    "        - 'spectral_centroid': スペクトル重心\n",
    "        - 'spectral_bandwidth': スペクトル帯域幅\n",
    "        - 'total_power': 全体のパワー\n",
    "    \"\"\"\n",
    "    # データをnumpy配列に変換\n",
    "    values = np.array(values)\n",
    "\n",
    "    # ゼロパディングで分解能を向上（窓長の8倍）\n",
    "    n_pad = len(values) * 8\n",
    "\n",
    "    # ハミング窓を適用（オプション：コメントアウトされている）\n",
    "    # window = np.hamming(len(values))\n",
    "    # windowed_data = values * window\n",
    "\n",
    "    # FFTを実行（ゼロパディング適用）\n",
    "    fft_result = np.fft.fft(values, n=n_pad)\n",
    "    fft_freq = np.fft.fftfreq(n_pad, 1 / fps)\n",
    "\n",
    "    # 正の周波数のみを取得\n",
    "    positive_freq_idx = fft_freq > 0\n",
    "    positive_fft = np.abs(fft_result[positive_freq_idx])\n",
    "    positive_freq = fft_freq[positive_freq_idx]\n",
    "    \n",
    "    # パワースペクトルを計算\n",
    "    power_spectrum = positive_fft ** 2\n",
    "\n",
    "    # 最大周波数の検出と補間\n",
    "    max_idx = np.argmax(positive_fft)\n",
    "    max_amplitude = positive_fft[max_idx]\n",
    "    \n",
    "    if 0 < max_idx < len(positive_fft) - 1:\n",
    "        # 3点を使用した放物線補間\n",
    "        alpha = positive_fft[max_idx - 1]\n",
    "        beta = positive_fft[max_idx]\n",
    "        gamma = positive_fft[max_idx + 1]\n",
    "        peak_pos = 0.5 * (alpha - gamma) / (alpha - 2 * beta + gamma)\n",
    "\n",
    "        # 補間された周波数と振幅\n",
    "        freq_resolution = fps / n_pad\n",
    "        max_freq = positive_freq[max_idx] + peak_pos * freq_resolution\n",
    "        \n",
    "        # 補間された振幅（放物線の頂点）\n",
    "        max_amplitude = beta - 0.25 * (alpha - gamma) * peak_pos\n",
    "    else:\n",
    "        max_freq = positive_freq[max_idx]\n",
    "    \n",
    "    # 上位5つの卓越周波数を検出\n",
    "    top_indices = np.argsort(positive_fft)[-5:][::-1]\n",
    "    dominant_freqs = [(positive_freq[idx], positive_fft[idx]) for idx in top_indices]\n",
    "    \n",
    "    # スペクトル特徴量の計算\n",
    "    # スペクトル重心（周波数の重み付き平均）\n",
    "    spectral_centroid = np.sum(positive_freq * positive_fft) / np.sum(positive_fft)\n",
    "    \n",
    "    # スペクトル帯域幅（重心からの重み付き分散）\n",
    "    spectral_bandwidth = np.sqrt(\n",
    "        np.sum(((positive_freq - spectral_centroid) ** 2) * positive_fft) / np.sum(positive_fft)\n",
    "    )\n",
    "    \n",
    "    # 全体のパワー\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    \n",
    "    # 結果を辞書にまとめる\n",
    "    result = {\n",
    "        'max_freq': max_freq,\n",
    "        'max_amplitude': max_amplitude,\n",
    "        'frequencies': positive_freq,\n",
    "        'amplitudes': positive_fft,\n",
    "        'power_spectrum': power_spectrum,\n",
    "        'dominant_freqs': dominant_freqs,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'total_power': total_power,\n",
    "        'freq_resolution': fps / n_pad,  # 周波数分解能\n",
    "        'nyquist_freq': fps / 2  # ナイキスト周波数\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メソッドの組み合わせを定義\n",
    "methodCombinations = [\n",
    "    ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "]\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    all_window_results = []\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # window_signalsの読み込み\n",
    "    os.makedirs(os.path.join(rootDir, SAVE_DIR), exist_ok=True)\n",
    "    window_analysis_data_path = os.path.join(rootDir, RPPG_ACCURACY_EVAL_DIR, f'{\"window_analysis_\" + dataName}.csv')\n",
    "    window_analysis_data_df  = pd.read_csv(window_analysis_data_path)\n",
    "    print(f'Loaded window signals data from {window_analysis_data_path}, {len(window_analysis_data_df)} rows')\n",
    "\n",
    "    # bvp_methodが'cupy_POS'のデータのみを抽出\n",
    "    pos_window_analysis_data_df = window_analysis_data_df[window_analysis_data_df['bvp_method'] == 'cupy_POS'].copy()\n",
    "    \n",
    "    window_index  = 0\n",
    "    for idx, row in pos_window_analysis_data_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "        original_bpm_mae = row['bpm_MAE']\n",
    "\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {int(window_start_time // 60)}m{window_start_time % 60:.2f}s-{int(window_end_time // 60)}m{window_end_time % 60:.2f}s\")\n",
    "\n",
    "        r_signal_in_window = row['r_signal_in_window']\n",
    "        g_signal_in_window = row['g_signal_in_window']\n",
    "        b_signal_in_window = row['b_signal_in_window']\n",
    "        ecg_bpm_in_window = row['ecg_bpm_in_window']\n",
    "\n",
    "        # 文字列をNumPy配列に変換\n",
    "        r_signal_in_window = np.fromstring(r_signal_in_window[1:-1], sep=' ')\n",
    "        g_signal_in_window = np.fromstring(g_signal_in_window[1:-1], sep=' ')\n",
    "        b_signal_in_window = np.fromstring(b_signal_in_window[1:-1], sep=' ')\n",
    "        ecg_bpm_in_window = np.fromstring(ecg_bpm_in_window[1:-1], sep=' ')\n",
    "        ecg_bpm_in_window_mean = np.nanmean(ecg_bpm_in_window)\n",
    "\n",
    "        if len(r_signal_in_window) == 0 or len(g_signal_in_window) == 0 or len(b_signal_in_window) == 0:\n",
    "            raise ValueError(\"RGB信号が窓内に存在しません\")\n",
    "        \n",
    "        rgb_signal = np.array([[r_signal_in_window, g_signal_in_window, b_signal_in_window]], dtype=np.float32)\n",
    "        rgb_cupy = cp.asarray(rgb_signal)\n",
    "        \n",
    "         # POS法のパラメータ\n",
    "        eps = 10**-9\n",
    "        X = rgb_cupy\n",
    "        fps_cupy = cp.float32(fps)\n",
    "        e, c, f = X.shape  # e = #estimators, c = 3 rgb ch., f = #frames\n",
    "        w = int(1.6 * fps_cupy)  # window length\n",
    "\n",
    "        # 固定の拍動ベクトル(論文の式30)\n",
    "        u_pbv = cp.array([0.33, 0.77, 0.53], dtype=cp.float32)\n",
    "\n",
    "        # 肌色調ベクトル\n",
    "        # r_signal_in_window_square = r_signal_in_window ** 2\n",
    "        # g_signal_in_window_square = g_signal_in_window ** 2\n",
    "        # b_signal_in_window_square = b_signal_in_window ** 2\n",
    "\n",
    "        # normalized_r_signal_in_window = r_signal_in_window / np.sqrt(r_signal_in_window_square + g_signal_in_window_square + b_signal_in_window_square)\n",
    "        # normalized_g_signal_in_window = g_signal_in_window / np.sqrt(r_signal_in_window_square + g_signal_in_window_square + b_signal_in_window_square)\n",
    "        # normalized_b_signal_in_window = b_signal_in_window / np.sqrt(r_signal_in_window_square + g_signal_in_window_square + b_signal_in_window_square)\n",
    "\n",
    "        # skin_vector_array = np.array([normalized_r_signal_in_window, normalized_g_signal_in_window, normalized_b_signal_in_window])\n",
    "        # skin_vector = cp.mean(cp.asarray(skin_vector_array), axis=1)\n",
    "\n",
    "        # POS法の標準化された肌色ベクトル(uskin)と血液量パルスベクトル(upbv)に直交する法線ベクトルを計算\n",
    "\n",
    "        # u_skin = skin_vector / (cp.linalg.norm(skin_vector) + eps)\n",
    "        u_skin = [0.37,0.56,0.75]\n",
    "        # u_pbvとu_skinに直交するベクトルを求める\n",
    "        uskin = cp.asnumpy(u_skin)\n",
    "        upbv = cp.asnumpy(u_pbv)\n",
    "        v_n = cp.cross(u_skin, u_pbv)\n",
    "        normalize_v_n = v_n / cp.linalg.norm(v_n)\n",
    "\n",
    "        # 投影行列P(1x3の行ベクトル)\n",
    "        P = cp.reshape(normalize_v_n, (1, 3))\n",
    "\n",
    "        normalize_v_n_np = cp.asnumpy(normalize_v_n)\n",
    "        print(f\"肌色調ベクトル uskin: {uskin}, 法線ベクトル v_n: {normalize_v_n_np}\")\n",
    "\n",
    "        # 検証\n",
    "        dot_u_skin = np.dot(uskin, normalize_v_n_np)\n",
    "        dot_upbv = np.dot(upbv, normalize_v_n_np)\n",
    "        print(\"u_skin・v_n:\", dot_u_skin)\n",
    "        print(\"u_pbv・v_n:\", dot_upbv)\n",
    "        \n",
    "        # 投影行列P(1x3の行ベクトル)\n",
    "        P = cp.reshape(normalize_v_n, (1, 3))\n",
    "\n",
    "        # 初期化\n",
    "        intensity_signal = cp.zeros((e, f))\n",
    "\n",
    "        # スライディングウィンドウループ\n",
    "        for n in cp.arange(w, f):\n",
    "            m = n - w + 1\n",
    "            \n",
    "            # 時間的正規化\n",
    "            Cn = X[:, :, m:(n + 1)]\n",
    "            M = 1.0 / (cp.mean(Cn, axis=2) + eps)\n",
    "            M_expanded = cp.expand_dims(M, axis=2)\n",
    "            Cn = cp.multiply(M_expanded, Cn)\n",
    "            \n",
    "            # 投影(uskinとupbvに直交する方向に投影してi(t)を抽出)\n",
    "            # Cn shape: (e, 3, window_length)\n",
    "            # P shape: (1, 3)\n",
    "            # 投影結果 shape: (e, window_length)\n",
    "            for estimator_idx in range(e):\n",
    "                \n",
    "                projected = cp.dot(P, Cn[estimator_idx, :, :]).flatten()\n",
    "                # ゼロ平均化\n",
    "                projected = projected - cp.mean(projected)\n",
    "                # オーバーラップ加算\n",
    "                intensity_signal[estimator_idx, m:(n + 1)] = cp.add(\n",
    "                    intensity_signal[estimator_idx, m:(n + 1)], \n",
    "                    projected\n",
    "                )\n",
    "                \n",
    "        # 最終的な強度変動信号をプロット\n",
    "        intensity_np = cp.asnumpy(intensity_signal[0, :])\n",
    "\n",
    "        bvp_cupy = intensity_signal\n",
    "        bvp_numpy = cp.asnumpy(bvp_cupy)\n",
    "\n",
    "        raw_bvp_signal = [bvp_numpy]\n",
    "        bvp_signal = [bvp_numpy.copy()]\n",
    "\n",
    "        # 後処理フィルタリング\n",
    "        bvp_signal = vhr.BVP.apply_filter(\n",
    "            bvp_signal,\n",
    "            vhr.BVP.BPfilter,\n",
    "            params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "        )\n",
    "\n",
    "        bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "\n",
    "        raw_bvp_signal_in_window = raw_bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "        filtered_bvp_signal_in_window = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "\n",
    "        \n",
    "        # FFT解析\n",
    "        raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "        filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "        fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "        # MAEの計算\n",
    "        rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "        rppg_freq = fft_result_dic['frequencies']\n",
    "        rppg_amplitude = fft_result_dic['amplitudes']\n",
    "        rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "        bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "        print(f\"\\n結果サマリー:\")\n",
    "        print(f\"  ECG BPM: {ecg_bpm_in_window_mean:.2f}\")\n",
    "        print(f\"  rPPG BPM: {rppg_bpm:.2f}\")\n",
    "        print(f\"  MAE: {bpm_MAE:.2f}, 元の窓のMAE: {original_bpm_mae:.2f}, 差分: {bpm_MAE - original_bpm_mae:.2f}\")\n",
    "\n",
    "        # fig, axes = plt.subplots(1, 1, figsize=(15, 4))\n",
    "        # axes.plot(intensity_np, color='red', label='Intensity Signal i(t) - Full', linewidth=1.5)\n",
    "        # axes.set_title(f'Window {idx} - Full Intensity Signal (orthogonal to uskin and upbv)\\nMAE: {bpm_MAE:.2f}, 元の窓のMAE: {original_bpm_mae:.2f}, 差分: {bpm_MAE - original_bpm_mae:.2f}')\n",
    "        # axes.set_xlabel('Frame')\n",
    "        # axes.set_ylabel('Amplitude')\n",
    "        # axes.legend()\n",
    "        # axes.grid(True, alpha=0.3)\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # 窓情報を保存\n",
    "        window_info = {\n",
    "            'window_index': window_index,\n",
    "            'window_size': window_size,\n",
    "            'stride': stride,\n",
    "            'frame_start': frame_start,\n",
    "            'frame_end': frame_end,\n",
    "            'window_start_time': window_start_time,\n",
    "            'window_end_time': window_end_time,\n",
    "            'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "            'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "            'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "            'raw_intensity_in_window': raw_bvp_signal_in_window,\n",
    "            'filtered_intensity_in_window': filtered_bvp_signal_in_window,\n",
    "            'ecg_bpm_in_window': ecg_bpm_in_window,\n",
    "            'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "            'rppg_bpm': rppg_bpm,\n",
    "            'bpm_MAE': bpm_MAE,\n",
    "            'original_bpm_MAE': original_bpm_mae,\n",
    "            'max_freq': fft_result_dic['max_freq'],\n",
    "            'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "            'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "            'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "            'total_power': fft_result_dic['total_power']\n",
    "        }\n",
    "        all_window_results.append(window_info)\n",
    "        window_index += 1\n",
    "    \n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'window_intensity_{dataName}.csv')\n",
    "    # results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a4300",
   "metadata": {},
   "source": [
    "### POSの射影行列を系統的に変えることで精度が向上するかをテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf68dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 投影行列のバリエーションを定義\n",
    "PROJECTION_MATRICES = {\n",
    "    'original': np.array([[0, 1, -1], [-2, 1, 1]]),\n",
    "    'modified_1': np.array([[-1, 0, 1], [1, -2, 1]]),\n",
    "    'modified_2': np.array([[1, -1, 0], [1, 1, -2]]),\n",
    "}\n",
    "\n",
    "methodCombinations = [\n",
    "    ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "]\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    window_analysis_path = os.path.join(rootDir, RPPG_ACCURACY_EVAL_DIR, f'window_analysis_{dataName}.csv')\n",
    "    window_analysis_df = pd.read_csv(window_analysis_path)\n",
    "\n",
    "    # 手法がcupy_POSのデータを抽出\n",
    "    high_mae_df = window_analysis_df[window_analysis_df['bvp_method'] == 'cupy_POS'].copy()\n",
    "    print(f'\\n高MAEデータ - {dataName}, 件数: {len(high_mae_df)}')\n",
    "\n",
    "    # 高MAEデータのbpm_MAEの窓長ごとの平均値を計算\n",
    "    if len(high_mae_df) > 0:\n",
    "        mean_high_mae = high_mae_df.groupby('window_size')['bpm_MAE'].mean()\n",
    "        print(f'  高MAEデータの平均MAE:\\n{mean_high_mae}')\n",
    "    else:\n",
    "        print('  高MAEデータが存在しません')\n",
    "\n",
    "    # 結果保存用のリスト\n",
    "    results_list = []\n",
    "    \n",
    "    # high_mae_dfの各行を処理\n",
    "    for idx, row in high_mae_df.iterrows():\n",
    "        window_index = row['window_index']\n",
    "        window_size = row['window_size']\n",
    "        stride = row['stride']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        window_start_time = row['window_start_time']\n",
    "        window_end_time = row['window_end_time']\n",
    "        ecg_bpm_in_window_mean = row['ecg_bpm_mean']\n",
    "        bpm_MAE = row['bpm_MAE']\n",
    "        if bpm_MAE < 5.0:\n",
    "            print(f\"スキップ: ウィンドウ {window_index} はMAEが低いため ({bpm_MAE:.2f})\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {window_index}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # RGB信号を抽出\n",
    "        r_signal_in_window = np.fromstring(row['r_signal_in_window'][1:-1], sep=' ')\n",
    "        g_signal_in_window = np.fromstring(row['g_signal_in_window'][1:-1], sep=' ')\n",
    "        b_signal_in_window = np.fromstring(row['b_signal_in_window'][1:-1], sep=' ')\n",
    "\n",
    "        print(f'  R信号長: {len(r_signal_in_window)}, G信号長: {len(g_signal_in_window)}, B信号長: {len(b_signal_in_window)}')\n",
    "\n",
    "        # rgbからBVPを計算\n",
    "        rgb_signal = np.array([[r_signal_in_window, g_signal_in_window, b_signal_in_window]], dtype=np.float32)\n",
    "        print(f\"\\nRGB信号の形状: {rgb_signal.shape}\")\n",
    "\n",
    "        signal_length = rgb_signal.shape[2]\n",
    "            \n",
    "        filtered_signal = [rgb_signal]\n",
    "        \n",
    "        for proj_name, P in PROJECTION_MATRICES.items():\n",
    "            \n",
    "            # ============================================================================\n",
    "            # 【重要】POS法を直接実装(調整可能)\n",
    "            # ============================================================================\n",
    "            import cupy as cp\n",
    "\n",
    "            # CuPy配列に変換\n",
    "            rgb_cupy = cp.asarray(rgb_signal)\n",
    "\n",
    "            # POS法のパラメータ\n",
    "            eps = 10**-9\n",
    "            X = rgb_cupy\n",
    "            fps_cupy = cp.float32(fps)\n",
    "            e, c, f = X.shape  # e = #estimators, c = 3 rgb ch., f = #frames\n",
    "            w = int(1.6 * fps_cupy)  # window length\n",
    "\n",
    "            # 投影行列P(現在のパターンを使用)\n",
    "            P_cupy = cp.asarray(P)\n",
    "            Q = cp.stack([P_cupy for _ in range(e)], axis=0)\n",
    "\n",
    "            # 初期化\n",
    "            H = cp.zeros((e, f))\n",
    "\n",
    "            # 診断情報を保存するリスト\n",
    "            alpha_list = []\n",
    "            M_list = []\n",
    "            S1_list = []\n",
    "            S2_list = []\n",
    "            alpha_S2_list = []\n",
    "            window_indices = []\n",
    "\n",
    "            # スライディングウィンドウループ\n",
    "            for n in cp.arange(w, f):\n",
    "                m = n - w + 1\n",
    "                \n",
    "                # 時間的正規化\n",
    "                Cn = X[:, :, m:(n + 1)]\n",
    "                M = 1.0 / (cp.mean(Cn, axis=2) + eps)\n",
    "                M_expanded = cp.expand_dims(M, axis=2)\n",
    "                Cn = cp.multiply(M_expanded, Cn)\n",
    "                \n",
    "                # Mの値を保存\n",
    "                M_list.append(cp.asnumpy(M))\n",
    "                \n",
    "                # 投影\n",
    "                S = cp.dot(Q, Cn)\n",
    "                S = S[0, :, :, :]\n",
    "                S = cp.swapaxes(S, 0, 1)\n",
    "                \n",
    "                # チューニング\n",
    "                S1 = S[:, 0, :]\n",
    "                S2 = S[:, 1, :]\n",
    "                alpha = cp.std(S1, axis=1) / (eps + cp.std(S2, axis=1))\n",
    "                \n",
    "                # S1とS2を保存\n",
    "                S1_list.append(cp.asnumpy(S1))\n",
    "                S2_list.append(cp.asnumpy(S2))\n",
    "                \n",
    "                # alphaの値を保存\n",
    "                alpha_list.append(cp.asnumpy(alpha))\n",
    "                \n",
    "                alpha_expanded = cp.expand_dims(alpha, axis=1)\n",
    "                alpha_S2 = alpha_expanded * S2\n",
    "                \n",
    "                # alpha*S2を保存\n",
    "                alpha_S2_list.append(cp.asnumpy(alpha_S2))\n",
    "                \n",
    "                window_indices.append(int(n))\n",
    "                \n",
    "                Hn = cp.add(S1, alpha_S2)\n",
    "                Hnm = Hn - cp.expand_dims(cp.mean(Hn, axis=1), axis=1)\n",
    "                \n",
    "                # オーバーラップ加算\n",
    "                H[:, m:(n + 1)] = cp.add(H[:, m:(n + 1)], Hnm)\n",
    "\n",
    "            # NumPy配列に戻す\n",
    "            bvp_cupy = H\n",
    "            bvp_numpy = cp.asnumpy(bvp_cupy)\n",
    "\n",
    "            raw_bvp_signal = [bvp_numpy]\n",
    "            bvp_signal = [bvp_numpy.copy()]\n",
    "\n",
    "            # 後処理フィルタリング\n",
    "            bvp_signal = vhr.BVP.apply_filter(\n",
    "                bvp_signal,\n",
    "                vhr.BVP.BPfilter,\n",
    "                params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "            )\n",
    "\n",
    "            bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "            filtered_bvp_signal_in_window = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "\n",
    "            # FFT解析\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "            filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "            fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "            # MAEの計算\n",
    "            rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "            rppg_freq = fft_result_dic['frequencies']\n",
    "            rppg_amplitude = fft_result_dic['amplitudes']\n",
    "            rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "            bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "            print(f\"\\n結果サマリー [{proj_name}]:\")\n",
    "            print(f\"  ECG BPM: {ecg_bpm_in_window_mean:.2f}\")\n",
    "            print(f\"  rPPG BPM: {rppg_bpm:.2f}\")\n",
    "            print(f\"  MAE: {bpm_MAE:.2f}\")\n",
    "            \n",
    "            # 結果を辞書形式でリストに追加\n",
    "            result_dict = {\n",
    "                'window_index': window_index,\n",
    "                'projection': proj_name,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'ecg_bpm': ecg_bpm_in_window_mean,\n",
    "                'rppg_bpm': rppg_bpm,\n",
    "                'bpm_MAE': bpm_MAE\n",
    "            }\n",
    "            results_list.append(result_dict)\n",
    "    \n",
    "    # 全ウィンドウの処理が終わった後、DataFrameに変換\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # 結果をCSVに保存\n",
    "    output_path = os.path.join(rootDir, SAVE_DIR, f'projection_comparison_{dataName}.csv')\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n結果を保存しました: {output_path}\")\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"全投影行列パターンの比較サマリー:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    summary = results_df.groupby('projection')['bpm_MAE'].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    projection_comparison_path = os.path.join(rootDir, SAVE_DIR, f'projection_comparison_{dataName}.csv')\n",
    "    \n",
    "    # CSVファイルが存在するか確認\n",
    "    if not os.path.exists(projection_comparison_path):\n",
    "        print(f'ファイルが見つかりません: {projection_comparison_path}')\n",
    "        continue\n",
    "    \n",
    "    # データを読み込む\n",
    "    df = pd.read_csv(projection_comparison_path)\n",
    "    print(f'\\n読み込んだデータ件数: {len(df)}')\n",
    "    print(f'投影パターン: {df[\"projection\"].unique()}')\n",
    "    \n",
    "    # 図の保存先ディレクトリ\n",
    "    figure_dir = os.path.join(rootDir, SAVE_DIR, 'figures')\n",
    "    os.makedirs(figure_dir, exist_ok=True)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. 全データに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # 投影パターンごとにデータを準備\n",
    "    projections = ['original', 'modified_1', 'modified_2']\n",
    "    data_all = [df[df['projection'] == proj]['bpm_MAE'].dropna() for proj in projections]\n",
    "    \n",
    "    # 箱ひげ図を作成\n",
    "    bp1 = ax.boxplot(data_all, tick_labels=projections, patch_artist=True,\n",
    "                     showmeans=True, meanline=True)\n",
    "    \n",
    "    # 色をつける\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for patch, color in zip(bp1['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_xlabel('Projection Matrix', fontsize=12)\n",
    "    ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "    ax.set_title(f'Comparison of Projection Matrices - All Data\\n({dataName})', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 統計情報を追加\n",
    "    stats_text = []\n",
    "    for proj, data in zip(projections, data_all):\n",
    "        stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}')\n",
    "    ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "            fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path_all = os.path.join(figure_dir, f'projection_comparison_all_{dataName}.png')\n",
    "    plt.savefig(output_path_all, dpi=300, bbox_inches='tight')\n",
    "    print(f'\\n全データの箱ひげ図を保存: {output_path_all}')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. Originalが高MAE(MAE>=10)のデータに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    # まず、originalで高MAEのwindow_indexを特定\n",
    "    original_df = df[df['projection'] == 'original'].copy()\n",
    "    high_mae_windows = original_df[original_df['bpm_MAE'] >= 10]['window_index'].unique()\n",
    "    \n",
    "    print(f'\\nOriginalで高MAE(>=10)のウィンドウ数: {len(high_mae_windows)}')\n",
    "    \n",
    "    if len(high_mae_windows) > 0:\n",
    "        # 高MAEウィンドウのデータを抽出\n",
    "        high_mae_df = df[df['window_index'].isin(high_mae_windows)].copy()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # 投影パターンごとにデータを準備\n",
    "        data_high_mae = [high_mae_df[high_mae_df['projection'] == proj]['bpm_MAE'].dropna() \n",
    "                         for proj in projections]\n",
    "        \n",
    "        # 箱ひげ図を作成\n",
    "        bp2 = ax.boxplot(data_high_mae, tick_labels=projections, patch_artist=True,\n",
    "                         showmeans=True, meanline=True)\n",
    "        \n",
    "        # 色をつける\n",
    "        for patch, color in zip(bp2['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_xlabel('Projection Matrix', fontsize=12)\n",
    "        ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "        ax.set_title(f'Comparison of Projection Matrices - High MAE Windows (Original MAE>=10)\\n({dataName})', \n",
    "                     fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axhline(y=10, color='red', linestyle='--', alpha=0.5, label='MAE=10 threshold')\n",
    "        \n",
    "        # 統計情報を追加\n",
    "        stats_text = []\n",
    "        for proj, data in zip(projections, data_high_mae):\n",
    "            improvement = ''\n",
    "            if proj != 'original' and len(data_high_mae[0]) > 0:\n",
    "                original_mean = np.mean(data_high_mae[0])\n",
    "                current_mean = np.mean(data)\n",
    "                improvement = f', Δ={current_mean-original_mean:.2f}'\n",
    "            stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}{improvement}')\n",
    "        \n",
    "        ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                fontsize=9)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path_high = os.path.join(figure_dir, f'projection_comparison_high_mae_{dataName}.png')\n",
    "        plt.savefig(output_path_high, dpi=300, bbox_inches='tight')\n",
    "        print(f'高MAEデータの箱ひげ図を保存: {output_path_high}')\n",
    "        plt.close()\n",
    "        \n",
    "        # 改善率の計算と表示\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'改善効果の分析 ({dataName}):')\n",
    "        print(f'{\"=\"*60}')\n",
    "        original_mean = np.mean(data_high_mae[0])\n",
    "        for proj, data in zip(projections[1:], data_high_mae[1:]):\n",
    "            current_mean = np.mean(data)\n",
    "            improvement = original_mean - current_mean\n",
    "            improvement_rate = (improvement / original_mean) * 100 if original_mean > 0 else 0\n",
    "            print(f'{proj}:')\n",
    "            print(f'  平均MAE: {current_mean:.2f} (Original: {original_mean:.2f})')\n",
    "            print(f'  改善量: {improvement:.2f} bpm')\n",
    "            print(f'  改善率: {improvement_rate:.2f}%')\n",
    "    else:\n",
    "        print('\\n高MAE(>=10)のウィンドウが存在しないため、2つ目の図はスキップします。')\n",
    "    \n",
    "    cap.release()\n",
    "    print(f'\\n{dataName}の処理が完了しました。\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f67cbf",
   "metadata": {},
   "source": [
    "全動画統合の箱ひげ図作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554399af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('全動画統合の箱ひげ図を作成中...')\n",
    "print('='*60)\n",
    "\n",
    "# 全動画のデータを統合\n",
    "all_movies_df_list = []\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    projection_comparison_path = os.path.join(rootDir, SAVE_DIR, f'projection_comparison_{dataName}.csv')\n",
    "    \n",
    "    if os.path.exists(projection_comparison_path):\n",
    "        temp_df = pd.read_csv(projection_comparison_path)\n",
    "        temp_df['movie_name'] = dataName  # 動画名を追加\n",
    "        all_movies_df_list.append(temp_df)\n",
    "        print(f'{dataName}: {len(temp_df)}件のデータを読み込み')\n",
    "\n",
    "if len(all_movies_df_list) > 0:\n",
    "    # 全データを結合\n",
    "    all_movies_df = pd.concat(all_movies_df_list, ignore_index=True)\n",
    "    print(f'\\n統合データ総数: {len(all_movies_df)}件')\n",
    "    print(f'動画数: {len(all_movies_df[\"movie_name\"].unique())}')\n",
    "    print(f'投影パターン: {all_movies_df[\"projection\"].unique()}')\n",
    "    \n",
    "    # 保存先ディレクトリ(最初の動画のディレクトリを使用、または共通ディレクトリを指定)\n",
    "    integrated_figure_dir = os.path.join(SAVE_DIR)\n",
    "    print(f'\\n統合図の保存先ディレクトリ: {integrated_figure_dir}')\n",
    "    os.makedirs(integrated_figure_dir, exist_ok=True)\n",
    "    \n",
    "    projections = ['original', 'modified_1', 'modified_2']\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. 全動画・全データに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    data_integrated_all = [all_movies_df[all_movies_df['projection'] == proj]['bpm_MAE'].dropna() \n",
    "                          for proj in projections]\n",
    "    \n",
    "    bp1 = ax.boxplot(data_integrated_all, tick_labels=projections, patch_artist=True,\n",
    "                     showmeans=True, meanline=True)\n",
    "    \n",
    "    for patch, color in zip(bp1['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_xlabel('Projection Matrix', fontsize=12)\n",
    "    ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "    ax.set_title(f'Comparison of Projection Matrices - All Movies Combined\\n(Total: {len(all_movies_df[\"movie_name\"].unique())} movies)', \n",
    "                 fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 統計情報を追加\n",
    "    stats_text = []\n",
    "    for proj, data in zip(projections, data_integrated_all):\n",
    "        stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}, std={np.std(data):.2f}')\n",
    "    ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "            fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path_integrated_all = os.path.join(integrated_figure_dir, 'projection_comparison_all_movies.png')\n",
    "    plt.savefig(output_path_integrated_all, dpi=300, bbox_inches='tight')\n",
    "    print(f'\\n全動画統合(全データ)の箱ひげ図を保存: {output_path_integrated_all}')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. 全動画・Originalが高MAE(MAE>=10)のデータに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    # Originalで高MAEのwindow_indexを特定(動画ごとに管理)\n",
    "    original_integrated_df = all_movies_df[all_movies_df['projection'] == 'original'].copy()\n",
    "    \n",
    "    # 動画名とwindow_indexの組み合わせで高MAEを特定\n",
    "    high_mae_mask = original_integrated_df['bpm_MAE'] >= 10\n",
    "    high_mae_keys = original_integrated_df[high_mae_mask][['movie_name', 'window_index']].values\n",
    "    \n",
    "    print(f'\\n全動画でOriginalが高MAE(>=10)のウィンドウ数: {len(high_mae_keys)}')\n",
    "    \n",
    "    if len(high_mae_keys) > 0:\n",
    "        # 高MAEウィンドウのデータを抽出\n",
    "        high_mae_integrated_df = all_movies_df[\n",
    "            all_movies_df.apply(lambda row: any((row['movie_name'] == k[0]) and (row['window_index'] == k[1]) \n",
    "                                               for k in high_mae_keys), axis=1)\n",
    "        ].copy()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        data_integrated_high_mae = [high_mae_integrated_df[high_mae_integrated_df['projection'] == proj]['bpm_MAE'].dropna() \n",
    "                                   for proj in projections]\n",
    "        \n",
    "        bp2 = ax.boxplot(data_integrated_high_mae, tick_labels=projections, patch_artist=True,\n",
    "                        showmeans=True, meanline=True)\n",
    "        \n",
    "        for patch, color in zip(bp2['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_xlabel('Projection Matrix', fontsize=12)\n",
    "        ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "        ax.set_title(f'Comparison of Projection Matrices - High MAE Windows (Original MAE>=10)\\nAll Movies Combined ({len(high_mae_keys)} windows)', \n",
    "                     fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axhline(y=10, color='red', linestyle='--', alpha=0.5, label='MAE=10 threshold')\n",
    "        \n",
    "        # 統計情報と改善効果を追加\n",
    "        stats_text = []\n",
    "        original_mean = np.mean(data_integrated_high_mae[0])\n",
    "        for proj, data in zip(projections, data_integrated_high_mae):\n",
    "            improvement = ''\n",
    "            if proj != 'original' and len(data_integrated_high_mae[0]) > 0:\n",
    "                current_mean = np.mean(data)\n",
    "                improvement_val = current_mean - original_mean\n",
    "                improvement_rate = ((original_mean - current_mean) / original_mean) * 100 if original_mean > 0 else 0\n",
    "                improvement = f', Δ={improvement_val:.2f} ({improvement_rate:+.1f}%)'\n",
    "            stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}{improvement}')\n",
    "        \n",
    "        ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                fontsize=10)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path_integrated_high = os.path.join(integrated_figure_dir, 'projection_comparison_high_mae_all_movies.png')\n",
    "        plt.savefig(output_path_integrated_high, dpi=300, bbox_inches='tight')\n",
    "        print(f'全動画統合(高MAE)の箱ひげ図を保存: {output_path_integrated_high}')\n",
    "        plt.close()\n",
    "        \n",
    "        # 改善効果の詳細分析\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'全動画統合の改善効果分析:')\n",
    "        print(f'{\"=\"*60}')\n",
    "        for proj, data in zip(projections[1:], data_integrated_high_mae[1:]):\n",
    "            current_mean = np.mean(data)\n",
    "            improvement = original_mean - current_mean\n",
    "            improvement_rate = (improvement / original_mean) * 100 if original_mean > 0 else 0\n",
    "            \n",
    "            # 改善されたウィンドウの割合\n",
    "            original_data = data_integrated_high_mae[0]\n",
    "            improved_count = sum(data.values < original_data.values)\n",
    "            improved_rate = (improved_count / len(data)) * 100 if len(data) > 0 else 0\n",
    "            \n",
    "            print(f'{proj}:')\n",
    "            print(f'  平均MAE: {current_mean:.2f} (Original: {original_mean:.2f})')\n",
    "            print(f'  改善量: {improvement:.2f} bpm')\n",
    "            print(f'  改善率: {improvement_rate:.2f}%')\n",
    "            print(f'  改善されたウィンドウ: {improved_count}/{len(data)} ({improved_rate:.1f}%)')\n",
    "            print()\n",
    "    else:\n",
    "        print('\\n高MAE(>=10)のウィンドウが存在しないため、2つ目の統合図はスキップします。')\n",
    "    \n",
    "    print(f'\\n全動画統合の処理が完了しました。')\n",
    "    print(f'図の保存先: {integrated_figure_dir}')\n",
    "else:\n",
    "    print('\\n統合するデータが見つかりませんでした。')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('すべての処理が完了しました。')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7c4bd",
   "metadata": {},
   "source": [
    "輝度と変えた射影行列のMAEを箱ひげ図にプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 全動画統合の箱ひげ図作成\n",
    "# ============================================================================\n",
    "print('\\n' + '='*60)\n",
    "print('全動画統合の箱ひげ図を作成中...')\n",
    "print('='*60)\n",
    "\n",
    "# 全動画のデータを統合\n",
    "all_movies_df_list = []\n",
    "all_intensity_df_list = []\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    projection_comparison_path = os.path.join(rootDir, SAVE_DIR, f'projection_comparison_{dataName}.csv')\n",
    "    intensity_comparison_path = os.path.join(rootDir, SAVE_DIR, f'window_intensity_{dataName}.csv')\n",
    "    \n",
    "    if os.path.exists(projection_comparison_path):\n",
    "        temp_df = pd.read_csv(projection_comparison_path)\n",
    "        temp_df['movie_name'] = dataName  # 動画名を追加\n",
    "        all_movies_df_list.append(temp_df)\n",
    "        print(f'{dataName}: {len(temp_df)}件のprojectionデータを読み込み')\n",
    "    \n",
    "    if os.path.exists(intensity_comparison_path):\n",
    "        temp_intensity_df = pd.read_csv(intensity_comparison_path)\n",
    "        temp_intensity_df['movie_name'] = dataName\n",
    "        all_intensity_df_list.append(temp_intensity_df)\n",
    "        print(f'{dataName}: {len(temp_intensity_df)}件のintensityデータを読み込み')\n",
    "\n",
    "if len(all_movies_df_list) > 0:\n",
    "    # 全データを結合\n",
    "    all_movies_df = pd.concat(all_movies_df_list, ignore_index=True)\n",
    "    print(f'\\n統合projectionデータ総数: {len(all_movies_df)}件')\n",
    "    print(f'動画数: {len(all_movies_df[\"movie_name\"].unique())}')\n",
    "    print(f'投影パターン: {all_movies_df[\"projection\"].unique()}')\n",
    "    \n",
    "    has_intensity_integrated = False\n",
    "    if len(all_intensity_df_list) > 0:\n",
    "        all_intensity_df = pd.concat(all_intensity_df_list, ignore_index=True)\n",
    "        print(f'統合intensityデータ総数: {len(all_intensity_df)}件')\n",
    "        has_intensity_integrated = True\n",
    "    \n",
    "    # 保存先ディレクトリ(最初の動画のディレクトリを使用、または共通ディレクトリを指定)\n",
    "    integrated_figure_dir = os.path.join(SAVE_DIR)\n",
    "    os.makedirs(integrated_figure_dir, exist_ok=True)\n",
    "    \n",
    "    projections = ['original', 'modified_1', 'modified_2']\n",
    "    if has_intensity_integrated:\n",
    "        projections.append('intensity')\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. 全動画・全データに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    data_integrated_all = []\n",
    "    for proj in projections[:3]:\n",
    "        data_integrated_all.append(all_movies_df[all_movies_df['projection'] == proj]['bpm_MAE'].dropna())\n",
    "    if has_intensity_integrated:\n",
    "        data_integrated_all.append(all_intensity_df['bpm_MAE'].dropna())\n",
    "    \n",
    "    # data_integrated_allをのデータ数確認\n",
    "    print('\\n各投影パターンのデータ数:')\n",
    "    for proj, data in zip(projections, data_integrated_all):\n",
    "        print(f'  {proj}: {len(data)}件')\n",
    "    \n",
    "    df_test = pd.DataFrame({proj: data for proj, data in zip(projections, data_integrated_all)})\n",
    "    print(df_test.head())\n",
    "    \n",
    "    bp1 = ax.boxplot(data_integrated_all, tick_labels=projections, patch_artist=True,\n",
    "                     showmeans=True, meanline=True)\n",
    "    \n",
    "    for patch, color in zip(bp1['boxes'], colors[:len(projections)]):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_xlabel('Projection Matrix / Method', fontsize=12)\n",
    "    ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "    ax.set_title(f'Comparison of Projection Matrices and Intensity - All Movies Combined\\n(Total: {len(all_movies_df[\"movie_name\"].unique())} movies)', \n",
    "                 fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 統計情報を追加\n",
    "    stats_text = []\n",
    "    for proj, data in zip(projections, data_integrated_all):\n",
    "        stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}, std={np.std(data):.2f}')\n",
    "    ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "            fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path_integrated_all = os.path.join(integrated_figure_dir, 'projection_intensity_comparison_all_movies.png')\n",
    "    plt.savefig(output_path_integrated_all, dpi=300, bbox_inches='tight')\n",
    "    print(f'\\n全動画統合(全データ)の箱ひげ図を保存: {output_path_integrated_all}')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. 全動画・Originalが高MAE(MAE>=10)のデータに対する箱ひげ図\n",
    "    # ============================================================================\n",
    "    # Originalで高MAEのwindow_indexを特定(動画ごとに管理)\n",
    "    original_integrated_df = all_movies_df[all_movies_df['projection'] == 'original'].copy()\n",
    "    \n",
    "    # 動画名とwindow_indexの組み合わせで高MAEを特定\n",
    "    high_mae_mask = original_integrated_df['bpm_MAE'] >= 10\n",
    "    high_mae_keys = original_integrated_df[high_mae_mask][['movie_name', 'window_index']].values\n",
    "    \n",
    "    if len(high_mae_keys) > 0:\n",
    "        # 高MAEウィンドウのデータを抽出\n",
    "        high_mae_integrated_df = all_movies_df[\n",
    "            all_movies_df.apply(lambda row: any((row['movie_name'] == k[0]) and (row['window_index'] == k[1]) \n",
    "                                               for k in high_mae_keys), axis=1)\n",
    "        ].copy()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        \n",
    "        data_integrated_high_mae = []\n",
    "        for proj in projections[:3]:\n",
    "            data_integrated_high_mae.append(\n",
    "                high_mae_integrated_df[high_mae_integrated_df['projection'] == proj]['bpm_MAE'].dropna()\n",
    "            )\n",
    "        \n",
    "        if has_intensity_integrated:\n",
    "            # Intensityデータも同じ(movie_name, window_index)の組み合わせでフィルタ\n",
    "            intensity_high_mae_integrated = all_intensity_df[\n",
    "                all_intensity_df.apply(lambda row: any((row['movie_name'] == k[0]) and (row['window_index'] == k[1]) \n",
    "                                                       for k in high_mae_keys), axis=1)\n",
    "            ]['bpm_MAE'].dropna()\n",
    "            data_integrated_high_mae.append(intensity_high_mae_integrated)\n",
    "        \n",
    "        bp2 = ax.boxplot(data_integrated_high_mae, tick_labels=projections, patch_artist=True,\n",
    "                        showmeans=True, meanline=True)\n",
    "        \n",
    "        for patch, color in zip(bp2['boxes'], colors[:len(projections)]):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_xlabel('Projection Matrix / Method', fontsize=12)\n",
    "        ax.set_ylabel('BPM MAE', fontsize=12)\n",
    "        ax.set_title(f'Comparison of Projection Matrices and Intensity - High MAE Windows (Original MAE>=10)\\nAll Movies Combined ({len(high_mae_keys)} windows)', \n",
    "                     fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axhline(y=10, color='red', linestyle='--', alpha=0.5, label='MAE=10 threshold')\n",
    "        \n",
    "        # 統計情報と改善効果を追加\n",
    "        stats_text = []\n",
    "        original_mean = np.mean(data_integrated_high_mae[0])\n",
    "        for proj, data in zip(projections, data_integrated_high_mae):\n",
    "            improvement = ''\n",
    "            if proj != 'original' and len(data_integrated_high_mae[0]) > 0:\n",
    "                current_mean = np.mean(data)\n",
    "                improvement_val = current_mean - original_mean\n",
    "                improvement_rate = ((original_mean - current_mean) / original_mean) * 100 if original_mean > 0 else 0\n",
    "                improvement = f', Δ={improvement_val:.2f} ({improvement_rate:+.1f}%)'\n",
    "            stats_text.append(f'{proj}: n={len(data)}, mean={np.mean(data):.2f}, median={np.median(data):.2f}{improvement}')\n",
    "        \n",
    "        ax.text(0.02, 0.98, '\\n'.join(stats_text), transform=ax.transAxes,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                fontsize=10)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path_integrated_high = os.path.join(integrated_figure_dir, 'projection_intensity_comparison_high_mae_all_movies.png')\n",
    "        plt.savefig(output_path_integrated_high, dpi=300, bbox_inches='tight')\n",
    "        print(f'全動画統合(高MAE)の箱ひげ図を保存: {output_path_integrated_high}')\n",
    "        plt.close()\n",
    "        \n",
    "        # 改善効果の詳細分析\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'全動画統合の改善効果分析:')\n",
    "        print(f'{\"=\"*60}')\n",
    "        for proj, data in zip(projections[1:], data_integrated_high_mae[1:]):\n",
    "            current_mean = np.mean(data)\n",
    "            improvement = original_mean - current_mean\n",
    "            improvement_rate = (improvement / original_mean) * 100 if original_mean > 0 else 0\n",
    "            \n",
    "            # 改善されたウィンドウの割合を計算(同じインデックスで比較可能な場合のみ)\n",
    "            print(f'{proj}:')\n",
    "            print(f'  平均MAE: {current_mean:.2f} (Original: {original_mean:.2f})')\n",
    "            print(f'  改善量: {improvement:.2f} bpm')\n",
    "            print(f'  改善率: {improvement_rate:.2f}%')\n",
    "            print()\n",
    "    else:\n",
    "        print('\\n高MAE(>=10)のウィンドウが存在しないため、2つ目の統合図はスキップします。')\n",
    "    \n",
    "    print(f'\\n全動画統合の処理が完了しました。')\n",
    "    print(f'図の保存先: {integrated_figure_dir}')\n",
    "else:\n",
    "    print('\\n統合するデータが見つかりませんでした。')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('すべての処理が完了しました。')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697d4b0",
   "metadata": {},
   "source": [
    "### POS拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "methodCombinations = [\n",
    "    ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "]\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    print(f'Processing movie: {movie_paths[i]}')\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    window_analysis_path = os.path.join(rootDir, RPPG_ACCURACY_EVAL_DIR, f'window_analysis_{dataName}.csv')\n",
    "    window_analysis_df = pd.read_csv(window_analysis_path)\n",
    "\n",
    "    # 手法がcupy_POSのデータを抽出\n",
    "    high_mae_df = window_analysis_df[window_analysis_df['bvp_method'] == 'cupy_POS'].copy()\n",
    "    print(f'\\n高MAEデータ - {dataName}, 件数: {len(high_mae_df)}')\n",
    "\n",
    "    # 結果保存用のリスト\n",
    "    results_list = []\n",
    "    \n",
    "    window_index = 0\n",
    "    # high_mae_dfの各行を処理\n",
    "    for idx, row in high_mae_df.iterrows():\n",
    "        window_index = row['window_index']\n",
    "        window_size = row['window_size']\n",
    "        stride = row['stride']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        window_start_time = row['window_start_time']\n",
    "        window_end_time = row['window_end_time']\n",
    "        ecg_bpm_in_window_mean = row['ecg_bpm_mean']\n",
    "        bpm_MAE = row['bpm_MAE']\n",
    "\n",
    "        print(f\"\\nウィンドウ {window_index}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # RGB信号を抽出\n",
    "        r_signal_in_window = np.fromstring(row['r_signal_in_window'][1:-1], sep=' ')\n",
    "        g_signal_in_window = np.fromstring(row['g_signal_in_window'][1:-1], sep=' ')\n",
    "        b_signal_in_window = np.fromstring(row['b_signal_in_window'][1:-1], sep=' ')\n",
    "\n",
    "        print(f'  R信号長: {len(r_signal_in_window)}, G信号長: {len(g_signal_in_window)}, B信号長: {len(b_signal_in_window)}')\n",
    "\n",
    "        # rgbからBVPを計算\n",
    "        rgb_signal = np.array([[r_signal_in_window, g_signal_in_window, b_signal_in_window]], dtype=np.float32)\n",
    "        print(f\"\\nRGB信号の形状: {rgb_signal.shape}\")\n",
    "\n",
    "        signal_length = rgb_signal.shape[2]\n",
    "        min_required_length = 50\n",
    "            \n",
    "        filtered_signal = [rgb_signal]\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 【重要】POS法を直接実装(調整可能)\n",
    "        # ============================================================================\n",
    "        import cupy as cp\n",
    "\n",
    "        # CuPy配列に変換\n",
    "        rgb_cupy = cp.asarray(rgb_signal)\n",
    "\n",
    "        # POS法のパラメータ\n",
    "        eps = 10**-9\n",
    "        X = rgb_cupy\n",
    "        fps_cupy = cp.float32(fps)\n",
    "        e, c, f = X.shape  # e = #estimators, c = 3 rgb ch., f = #frames\n",
    "        w = int(1.6 * fps_cupy)  # window length\n",
    "\n",
    "        # 投影行列P(現在のパターンを使用)\n",
    "        P = cp.array([[0, 1, -1], [-2, 1, 1]], dtype=cp.float32)  # ← 修正: cpを使用\n",
    "        Q = cp.stack([P for _ in range(e)], axis=0)  # ← 修正: P_cupyではなくP\n",
    "\n",
    "        # 初期化\n",
    "        H = cp.zeros((e, f))\n",
    "\n",
    "        # 診断情報を保存するリスト（各ウィンドウごとに初期化）← 重要！\n",
    "        M_list = []\n",
    "        window_indices = []\n",
    "\n",
    "        # スライディングウィンドウループ\n",
    "        for n in cp.arange(w, f):\n",
    "            m = n - w + 1\n",
    "            \n",
    "            # 時間的正規化\n",
    "            Cn = X[:, :, m:(n + 1)]\n",
    "            # POSの原理式のNに相当(N・us・I0のN)\n",
    "            M = 1.0 / (cp.mean(Cn, axis=2) + eps)\n",
    "            M_expanded = cp.expand_dims(M, axis=2)\n",
    "            Cn = cp.multiply(M_expanded, Cn)\n",
    "            \n",
    "            # Mの値を保存（形状: (e, c) = (1, 3)）\n",
    "            M_list.append(cp.asnumpy(M))\n",
    "            \n",
    "            # 投影\n",
    "            S = cp.dot(Q, Cn)\n",
    "            S = S[0, :, :, :]\n",
    "            S = cp.swapaxes(S, 0, 1)\n",
    "            \n",
    "            # チューニング\n",
    "            S1 = S[:, 0, :]\n",
    "            S2 = S[:, 1, :]\n",
    "            alpha = cp.std(S1, axis=1) / (eps + cp.std(S2, axis=1))\n",
    "            \n",
    "            alpha_expanded = cp.expand_dims(alpha, axis=1)\n",
    "            alpha_S2 = alpha_expanded * S2\n",
    "            \n",
    "            window_indices.append(int(n))\n",
    "            \n",
    "            Hn = cp.add(S1, alpha_S2)\n",
    "            Hnm = Hn - cp.expand_dims(cp.mean(Hn, axis=1), axis=1)\n",
    "            \n",
    "            # オーバーラップ加算\n",
    "            H[:, m:(n + 1)] = cp.add(H[:, m:(n + 1)], Hnm)\n",
    "\n",
    "        # NumPy配列に戻す\n",
    "        bvp_cupy = H\n",
    "        bvp_numpy = cp.asnumpy(bvp_cupy)\n",
    "\n",
    "        raw_bvp_signal = [bvp_numpy]\n",
    "        bvp_signal = [bvp_numpy.copy()]\n",
    "\n",
    "        # 後処理フィルタリング\n",
    "        bvp_signal = vhr.BVP.apply_filter(\n",
    "            bvp_signal,\n",
    "            vhr.BVP.BPfilter,\n",
    "            params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "        )\n",
    "\n",
    "        bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "\n",
    "        raw_bvp_signal_in_window = raw_bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "        filtered_bvp_signal_in_window = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "\n",
    "        # FFT解析\n",
    "        raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "        filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "        fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "        # MAEの計算\n",
    "        rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "        rppg_freq = fft_result_dic['frequencies']\n",
    "        rppg_amplitude = fft_result_dic['amplitudes']\n",
    "        rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "        bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "        proj_name = \"standard_POS\"  # ← 追加\n",
    "        \n",
    "        print(f\"\\n結果サマリー [{proj_name}]:\")\n",
    "        print(f\"  ECG BPM: {ecg_bpm_in_window_mean:.2f}\")\n",
    "        print(f\"  rPPG BPM: {rppg_bpm:.2f}\")\n",
    "        print(f\"  MAE: {bpm_MAE:.2f}\")\n",
    "        print(f\"  M_listの長さ: {len(M_list)}\")  # ← デバッグ用\n",
    "        \n",
    "        # M_listを文字列に変換（CSV保存用）\n",
    "        # 各Mは形状(1,3)なので、フラット化してスペース区切りに\n",
    "        M_list_str = [' '.join(map(str, M.flatten())) for M in M_list]\n",
    "        M_list_combined = '; '.join(M_list_str)  # セミコロンで各時刻を区切る\n",
    "        \n",
    "        # 結果を辞書形式でリストに追加\n",
    "        result_dict = {\n",
    "            'window_index': window_index,\n",
    "            'projection': proj_name,\n",
    "            'window_size': window_size,\n",
    "            'stride': stride,\n",
    "            'frame_start': frame_start,\n",
    "            'frame_end': frame_end,\n",
    "            'window_start_time': window_start_time,\n",
    "            'window_end_time': window_end_time,\n",
    "            'ecg_bpm': ecg_bpm_in_window_mean,\n",
    "            'rppg_bpm': rppg_bpm,\n",
    "            'bpm_MAE': bpm_MAE,\n",
    "            'M_list': M_list_combined,  # ← 文字列化して保存\n",
    "            'num_sliding_windows': len(M_list),  # ← スライディングウィンドウ数\n",
    "        }\n",
    "        results_list.append(result_dict)\n",
    "    \n",
    "    # 全ウィンドウの処理が終わった後、DataFrameに変換\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # 結果をCSVに保存\n",
    "    output_path = os.path.join(rootDir, SAVE_DIR, f'POS_internalArray_output_{dataName}.csv')\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n結果を保存しました: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27792b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 窓ごとにR,G,BのM_listの変化をプロット\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvhr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
