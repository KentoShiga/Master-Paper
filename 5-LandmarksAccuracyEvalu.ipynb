{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import ConvexHull\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyVHR as vhr\n",
    "from pyVHR.extraction.sig_processing import SignalProcessing\n",
    "from pyVHR.plot.visualize import *\n",
    "from pyVHR.BVP import *\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# 修正: scikit-image 0.18.3用のインポート\n",
    "from skimage.feature import local_binary_pattern\n",
    "# graycomatrixとgraycopropsは古いバージョンでは別の場所にあります\n",
    "try:\n",
    "    from skimage.feature import greycomatrix as graycomatrix, greycoprops as graycoprops\n",
    "except ImportError:\n",
    "    # 別の方法を試す\n",
    "    from skimage.feature import texture\n",
    "    # または関数を使わない場合はコメントアウト\n",
    "    graycomatrix = None\n",
    "    graycoprops = None\n",
    "    print(\"警告: graycomatrix/graycopropsをインポートできませんでした\")\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from scipy.ndimage import laplace\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力とする動画と動画のファイル名を取得\n",
    "root_dir = \"experimentData\\\\\"\n",
    "data_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "movie_paths = []\n",
    "movie_names = []\n",
    "true_value_csv_array = []\n",
    "true_value_rri_csv_array = []\n",
    "print(\"動画ディレクトリ:\", data_dirs)\n",
    "\n",
    "for i in range(len(data_dirs)):\n",
    "    data_dir = data_dirs[i]\n",
    "\n",
    "    # 動画ファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.avi')]\n",
    "    movie_paths.extend(movie_files)\n",
    "\n",
    "    movie_name = os.path.basename(data_dir)\n",
    "    movie_names.append(movie_name)\n",
    "\n",
    "    # ppgファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    true_value_csv_array = [f.replace('.avi', '.csv') for f in movie_paths if f.endswith('.avi')]\n",
    "    true_value_rri_csv_array.append(os.path.join(data_dir, 'RRI_Simple_' + movie_name + '.csv'))\n",
    "\n",
    "\n",
    "f_1_ffi = 0.0399  # LFのはじめ\n",
    "f_2 = 0.151  # LFの終わり、HFのはじめ\n",
    "f_3 = 0.401  # HFの終わり\n",
    "\n",
    "# start_index = 9\n",
    "# end_index = len(movie_paths)\n",
    "\n",
    "# data_dirs = data_dirs[start_index:end_index]\n",
    "# movie_paths = movie_paths[start_index:end_index]\n",
    "# movie_names = movie_names[start_index:end_index]\n",
    "# true_value_csv_array = true_value_csv_array[start_index:end_index]\n",
    "# true_value_rri_csv_array = true_value_rri_csv_array[start_index:end_index]\n",
    "\n",
    "print(f\"data_dirs: {data_dirs}\")\n",
    "print(f\"movie_paths: {movie_paths}\")\n",
    "print(f\"movie_names: {movie_names}\")\n",
    "print(f\"true_value_csv_array: {true_value_csv_array}\")\n",
    "print(f\"true_value_rri_csv_array: {true_value_rri_csv_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR  = \"LandmarksAccuracyEvalResults\"\n",
    "# rPPGに最適なランドマーク番号を定義\n",
    "\n",
    "# 代表的な部分のみ\n",
    "# FOREHEAD_LANDMARKS = [151]  # 額\n",
    "UPPER_LEFT_CHEEK_LANDMARKS = [119]  # 左頬\n",
    "LOWER_LEFT_CHEEK_LANDMARKS = [207]  # 左頬\n",
    "UPPER_RIGHT_CHEEK_LANDMARKS = [347]  # 右頬\n",
    "LOWER_RIGHT_CHEEK_LANDMARKS = [425]  # 右頬\n",
    "NOSE_LANDMARKS = [4]\n",
    "CHIN_LANDMARKS = [200]  # 顎\n",
    "\n",
    "# ALL_RPPG_LANDMARKS = FOREHEAD_LANDMARKS + UPPER_LEFT_CHEEK_LANDMARKS + LOWER_LEFT_CHEEK_LANDMARKS + UPPER_RIGHT_CHEEK_LANDMARKS + LOWER_RIGHT_CHEEK_LANDMARKS + NOSE_LANDMARKS + CHIN_LANDMARKS\n",
    "ALL_RPPG_LANDMARKS = UPPER_LEFT_CHEEK_LANDMARKS + LOWER_LEFT_CHEEK_LANDMARKS + UPPER_RIGHT_CHEEK_LANDMARKS + LOWER_RIGHT_CHEEK_LANDMARKS + NOSE_LANDMARKS + CHIN_LANDMARKS\n",
    "# PATCH_SIZE = 10.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "PATCH_SIZE = 30.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "# PATCH_SIZE = 50.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "\n",
    "LANDMARK_ID_NAME_MAP = {\n",
    "    151: \"Forehead\",\n",
    "    119: \"Upper Left Cheek\",\n",
    "    207: \"Lower Left Cheek\",\n",
    "    347: \"Upper Right Cheek\",\n",
    "    425: \"Lower Right Cheek\",\n",
    "    4: \"Nose\",\n",
    "    200: \"Chin\"\n",
    "}\n",
    "\n",
    "GLOBAL_SAVE_DIR = root_dir\n",
    "print(f\"GLOBAL_SAVE_DIR: {GLOBAL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273c039",
   "metadata": {},
   "source": [
    "ランドマークの座標を記録\n",
    "- {dataName}_landmarks_coordinates.csvを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_idx in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    saveDir = os.path.join(rootDir, SAVE_DIR)\n",
    "    print(f\"ランドマーク抽出結果保存ディレクトリ: {saveDir}\")\n",
    "    os.makedirs(saveDir, exist_ok=True)\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "    \n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    \n",
    "    # 1フレーム目を読み込む\n",
    "    ret, first_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: 最初のフレームを読み込めませんでした: {inputMoviePath}\")\n",
    "        continue\n",
    "    \n",
    "    # === Step 1: ランドマーク抽出用のSignalProcessing初期化 ===\n",
    "    print(\"=== ランドマーク抽出開始 ===\")\n",
    "    sig_processing = SignalProcessing()\n",
    "    sig_processing.set_landmarks(ALL_RPPG_LANDMARKS)\n",
    "    sig_processing.set_square_patches_side(PATCH_SIZE)\n",
    "    \n",
    "    # 可視化を有効化\n",
    "    sig_processing.set_visualize_skin_and_landmarks(\n",
    "        visualize_skin=True,\n",
    "        visualize_landmarks=True,\n",
    "        visualize_landmarks_number=True,\n",
    "        visualize_patch=True\n",
    "    )\n",
    "    \n",
    "    # 肌抽出器を設定(ConvexHullを使用)\n",
    "    sig_processing.set_skin_extractor(vhr.extraction.SkinExtractionConvexHull('CPU'))\n",
    "    \n",
    "    # 1フレームのみ処理\n",
    "    sig_processing.set_total_frames(1)\n",
    "    \n",
    "    # ダミーでextract_patchesを実行してランドマーク検出を行う\n",
    "    try:\n",
    "        _ = sig_processing.extract_patches(inputMoviePath, \"squares\", \"mean\")\n",
    "        \n",
    "        # 可視化画像を取得\n",
    "        visualize_patches = sig_processing.get_visualize_patches()\n",
    "        \n",
    "        if len(visualize_patches) > 0:\n",
    "            # 1フレーム目の可視化画像を保存\n",
    "            output_path = os.path.join(saveDir, f\"{dataName}_landmarks_frame1.png\")\n",
    "            cv2.imwrite(output_path, visualize_patches[0])\n",
    "            print(f\"ランドマーク画像を保存しました: {output_path}\")\n",
    "            \n",
    "            # ランドマークの座標を取得して保存\n",
    "            # MediaPipeを使用してランドマークを検出\n",
    "            import mediapipe as mp\n",
    "            mp_face_mesh = mp.solutions.face_mesh\n",
    "            \n",
    "            with mp_face_mesh.FaceMesh(\n",
    "                static_image_mode=True,\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=True,\n",
    "                min_detection_confidence=0.5) as face_mesh:\n",
    "                \n",
    "                # RGB変換\n",
    "                frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "                results = face_mesh.process(frame_rgb)\n",
    "                \n",
    "                if results.multi_face_landmarks:\n",
    "                    landmarks_data = []\n",
    "                    face_landmarks = results.multi_face_landmarks[0]\n",
    "                    h, w = first_frame.shape[:2]\n",
    "                    \n",
    "                    # 使用したランドマークの座標を取得\n",
    "                    for idx in ALL_RPPG_LANDMARKS:\n",
    "                        landmark = face_landmarks.landmark[idx]\n",
    "                        x = int(landmark.x * w)\n",
    "                        y = int(landmark.y * h)\n",
    "                        landmarks_data.append({\n",
    "                            'landmark_id': idx,\n",
    "                            'x': x,\n",
    "                            'y': y\n",
    "                        })\n",
    "                    \n",
    "                    # CSVファイルに保存\n",
    "                    import pandas as pd\n",
    "                    df = pd.DataFrame(landmarks_data)\n",
    "                    csv_path = os.path.join(saveDir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    print(f\"ランドマーク座標を保存しました: {csv_path}\")\n",
    "                else:\n",
    "                    print(f\"Warning: 顔のランドマークが検出されませんでした: {inputMoviePath}\")\n",
    "        else:\n",
    "            print(f\"Warning: ランドマークが検出されませんでした: {inputMoviePath}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: ランドマーク検出中にエラーが発生しました: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"=== {dataName} の処理完了 ===\\n\")\n",
    "\n",
    "    # ここにランドマークのidと座標を保存するコードを追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424f67",
   "metadata": {},
   "source": [
    "記録された座標を読み込み、各々のRGBを記録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe737fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analysis_df(video_path, roi_coordinates, fps):\n",
    "    \"\"\"\n",
    "    RGB + HSV + L*a*b*特徴量を含む画像品質解析を行う関数\n",
    "    \n",
    "    Args:\n",
    "        video_path: 動画ファイルのパス\n",
    "        roi_coordinates: ROI座標 (left, top, right, bottom)\n",
    "        fps: フレームレート\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 解析結果\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 結果を格納するリスト\n",
    "    results = {\n",
    "        'frame_number': [],\n",
    "        'timestamp': [],\n",
    "        'contrast': [],\n",
    "        'r_mean': [],\n",
    "        'g_mean': [],\n",
    "        'b_mean': [],\n",
    "        'r_std': [],\n",
    "        'g_std': [],\n",
    "        'b_std': [],\n",
    "        's_mean': [],\n",
    "        's_std': [],\n",
    "        'l_mean': [],\n",
    "        'l_std': [],\n",
    "    }\n",
    "    \n",
    "    frame_count = 0\n",
    "    roi_left, roi_top, roi_right, roi_bottom = roi_coordinates\n",
    "    \n",
    "    print(f\"動画解析開始: {video_path}\")\n",
    "    print(f\"ROI座標: ({roi_left}, {roi_top}, {roi_right}, {roi_bottom})\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # ROI領域を切り出し\n",
    "        roi_frame = frame[roi_top:roi_bottom, roi_left:roi_right]\n",
    "        \n",
    "        if roi_frame.size == 0:\n",
    "            continue\n",
    "            \n",
    "        # タイムスタンプ計算\n",
    "        timestamp = frame_count / fps\n",
    "        \n",
    "        # RGB解析\n",
    "        b_channel, g_channel, r_channel = cv2.split(roi_frame)\n",
    "        \n",
    "        r_mean = np.mean(r_channel)\n",
    "        g_mean = np.mean(g_channel)\n",
    "        b_mean = np.mean(b_channel)\n",
    "        \n",
    "        r_std = np.std(r_channel)\n",
    "        g_std = np.std(g_channel)\n",
    "        b_std = np.std(b_channel)\n",
    "        \n",
    "        # コントラスト計算（グレースケール）\n",
    "        gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "        contrast = np.std(gray_roi)\n",
    "        \n",
    "        # HSV解析\n",
    "        hsv_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2HSV)\n",
    "        h_channel, s_channel, v_channel = cv2.split(hsv_roi)\n",
    "        \n",
    "        s_mean = np.mean(s_channel)\n",
    "        s_std = np.std(s_channel)\n",
    "        \n",
    "        # L*a*b*解析\n",
    "        lab_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel_lab = cv2.split(lab_roi)\n",
    "        \n",
    "        l_mean = np.mean(l_channel)\n",
    "        l_std = np.std(l_channel)\n",
    "        \n",
    "        # 結果を保存\n",
    "        results['frame_number'].append(frame_count)\n",
    "        results['timestamp'].append(timestamp)\n",
    "        results['contrast'].append(contrast)\n",
    "        results['r_mean'].append(r_mean)\n",
    "        results['g_mean'].append(g_mean)\n",
    "        results['b_mean'].append(b_mean)\n",
    "        results['r_std'].append(r_std)\n",
    "        results['g_std'].append(g_std)\n",
    "        results['b_std'].append(b_std)\n",
    "        results['s_mean'].append(s_mean)\n",
    "        results['s_std'].append(s_std)\n",
    "        results['l_mean'].append(l_mean)\n",
    "        results['l_std'].append(l_std)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # 進捗表示\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"処理済みフレーム: {frame_count}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # DataFrameに変換\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"解析完了: {len(df)} フレーム処理\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_idx in range(len(movie_paths)):  # ★ 変数名を変更\n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    \n",
    "    print(f'Processing movie: {dataName}')  # ★ デバッグ用\n",
    "    \n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    savedir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    \n",
    "    # ROIの座標を取得\n",
    "    roi_coordinates_path = os.path.join(savedir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "    roi_df = pd.read_csv(roi_coordinates_path)\n",
    "    \n",
    "    # ★★★ 動画ごとにリストとDataFrameを初期化 ★★★\n",
    "    all_segments_data = []\n",
    "    all_segments_df = pd.DataFrame()\n",
    "    \n",
    "    # ROIごとにRGB、HSVを記録\n",
    "    for roi_idx, row in roi_df.iterrows():\n",
    "        landmark_id = int(row['landmark_id'])  # 整数に変換\n",
    "        center_x = int(row['x'])  # 整数に変換\n",
    "        center_y = int(row['y'])  # 整数に変換\n",
    "        \n",
    "        # パッチの座標を計算（中心座標から±PATCH_SIZE/2）\n",
    "        half_patch = PATCH_SIZE // 2\n",
    "        landmark_left = int(max(0, center_x - half_patch))\n",
    "        landmark_top = int(max(0, center_y - half_patch))\n",
    "        landmark_right = int(center_x + half_patch)\n",
    "        landmark_bottom = int(center_y + half_patch)\n",
    "        \n",
    "        roi = (landmark_left, landmark_top, landmark_right, landmark_bottom)\n",
    "        \n",
    "        print(f'  Processing landmark_id: {landmark_id} at ({center_x}, {center_y})')\n",
    "        \n",
    "        landmark_df = make_analysis_df(\n",
    "            video_path=inputMoviePath,\n",
    "            roi_coordinates=roi,\n",
    "            fps=fps\n",
    "        )\n",
    "        landmark_df[\"landmark_id\"] = landmark_id\n",
    "        print(f'  landmark {landmark_id} data shape: {landmark_df.shape}')\n",
    "        \n",
    "        # 動画のデータをリストに追加\n",
    "        all_segments_data.append(landmark_df)\n",
    "    \n",
    "    # 全てのランドマークのデータを統合\n",
    "    all_landmarks_df = pd.concat(all_segments_data, ignore_index=True)\n",
    "    print(f'Total data shape for {dataName}: {all_landmarks_df.shape}')\n",
    "    \n",
    "    # CSVとして保存\n",
    "    output_csv_path = os.path.join(rootDir, SAVE_DIR, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_data.csv\")\n",
    "    all_landmarks_df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Saved: {output_csv_path}')\n",
    "    \n",
    "    # === ROI可視化 ===\n",
    "    # 1フレーム目を読み込み\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    ret, first_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        vis_frame = first_frame.copy()\n",
    "        \n",
    "        # CSVから各ランドマークのROIを描画\n",
    "        for roi_idx, row in roi_df.iterrows():\n",
    "            landmark_id = int(row['landmark_id'])\n",
    "            center_x = int(row['x'])\n",
    "            center_y = int(row['y'])\n",
    "            \n",
    "            # パッチの座標を計算\n",
    "            half_patch = PATCH_SIZE // 2\n",
    "            left = int(max(0, center_x - half_patch))\n",
    "            top = int(max(0, center_y - half_patch))\n",
    "            right = int(center_x + half_patch)\n",
    "            bottom = int(center_y + half_patch)\n",
    "            \n",
    "            # ROIの矩形を描画（緑色）\n",
    "            cv2.rectangle(vis_frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # ランドマークIDを表示\n",
    "            cv2.putText(vis_frame, str(landmark_id), (center_x - 10, center_y - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            # 中心点を描画（赤色）\n",
    "            cv2.circle(vis_frame, (center_x, center_y), 3, (0, 0, 255), -1)\n",
    "        \n",
    "        # 可視化画像を保存\n",
    "        vis_output_path = os.path.join(savedir, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_visualization.png\")\n",
    "        cv2.imwrite(vis_output_path, vis_frame)\n",
    "        print(f'ROI可視化画像を保存: {vis_output_path}\\n')\n",
    "    else:\n",
    "        print(f'Error: フレームの読み込みに失敗しました\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe90449",
   "metadata": {},
   "source": [
    "各窓にRGB信号を格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933183b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZES = [2, 4, 6, 8, 10]\n",
    "STRIDES = [2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_full_string(arr):\n",
    "    \"\"\"NumPy配列を省略なしの文字列に変換\"\"\"\n",
    "    if isinstance(arr, str):\n",
    "        return arr\n",
    "    elif isinstance(arr, (np.ndarray, list)):\n",
    "        # NumPy配列またはリストを完全な文字列に変換\n",
    "        arr_np = np.array(arr)\n",
    "        return np.array2string(arr_np, threshold=np.inf, max_line_width=np.inf, separator=' ')\n",
    "    else:\n",
    "        return str(arr)\n",
    "\n",
    "class StrideSegmentCalculator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_sizes: List[float] = [2, 3, 4, 5],\n",
    "        strides: List[float] = [0.1, 0.5, 1, 1.5, 2],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_sizes : List[float]\n",
    "            窓幅（秒）のリスト\n",
    "        strides : List[float]\n",
    "            移動秒数のリスト\n",
    "        \"\"\"\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "    def calculate_overlap(self, window_size: float, stride: float) -> float:\n",
    "        \"\"\"\n",
    "        窓幅と移動秒数からオーバーラップ率を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            オーバーラップ率（%）\n",
    "        \"\"\"\n",
    "        if stride >= window_size:\n",
    "            return 0\n",
    "        overlap = (window_size - stride) / window_size * 100\n",
    "        return round(overlap, 2)\n",
    "\n",
    "    def calculate_segments(\n",
    "        self, window_size: float, stride: float, total_frames: int, fps: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        フレーム数から解析区間を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple[int, int]]\n",
    "            各区間の(開始フレーム, 終了フレーム)のリスト\n",
    "        \"\"\"\n",
    "        frames_per_window = round(window_size * fps)\n",
    "        frames_per_stride = round(stride * fps)\n",
    "\n",
    "        segments = []\n",
    "        start_frame = 0\n",
    "\n",
    "        while start_frame + frames_per_window <= total_frames:\n",
    "            segments.append((start_frame, start_frame + frames_per_window))\n",
    "            start_frame += frames_per_stride\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def create_analysis_dataframe(self, total_frames: int, fps: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        全ての窓幅と移動秒数の組み合わせに対してDataFrameを生成\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            各条件でのセグメント情報を含むDataFrame\n",
    "            columns: window_size, stride, overlap, segment_number, frame_start, frame_end\n",
    "        \"\"\"\n",
    "        data_dict = {\n",
    "            \"window_size\": [],\n",
    "            \"stride\": [],\n",
    "            \"overlap\": [],\n",
    "            \"segment_number\": [],\n",
    "            \"frame_start\": [],\n",
    "            \"frame_end\": [],\n",
    "        }\n",
    "\n",
    "        for window_size in self.window_sizes:\n",
    "            for stride in self.strides:\n",
    "                overlap = self.calculate_overlap(window_size, stride)\n",
    "                segments = self.calculate_segments(\n",
    "                    window_size, stride, total_frames, fps\n",
    "                )\n",
    "\n",
    "                for i, (start_frame, end_frame) in enumerate(segments):\n",
    "                    data_dict[\"window_size\"].append(window_size)\n",
    "                    data_dict[\"stride\"].append(stride)\n",
    "                    data_dict[\"overlap\"].append(overlap)\n",
    "                    data_dict[\"segment_number\"].append(i)\n",
    "                    data_dict[\"frame_start\"].append(start_frame)\n",
    "                    data_dict[\"frame_end\"].append(end_frame)\n",
    "\n",
    "        return pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "class PulseAnalysisDataStrides:\n",
    "    def __init__(self, window_sizes, strides):\n",
    "        # 窓枠とストライドの値を定義\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "        # accuracyのみを格納するDataFrameを初期化\n",
    "        self.results = pd.DataFrame(\n",
    "            index=pd.Index(self.window_sizes, name=\"window_size\"),\n",
    "            columns=pd.Index(self.strides, name=\"strides\"),\n",
    "        )\n",
    "\n",
    "    def add_accuracy(self, window_size: float, strides: int, accuracy: float):\n",
    "        \"\"\"\n",
    "        精度データを追加する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        strides : int\n",
    "            ストライド（s）\n",
    "        accuracy : float\n",
    "            精度値\n",
    "        \"\"\"\n",
    "        self.results.loc[window_size, strides] = accuracy\n",
    "\n",
    "    def _create_heatmap_dataframe(self):\n",
    "        \"\"\"\n",
    "        ヒートマップ用のDataFrameを作成する内部メソッド\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            ヒートマップ用に整形されたDataFrame\n",
    "        \"\"\"\n",
    "        data = {\"stride\": self.strides}\n",
    "        for window_size in self.window_sizes:\n",
    "            data[window_size] = [\n",
    "                self.results.loc[window_size, stride] for stride in self.strides\n",
    "            ]\n",
    "        df = pd.DataFrame(data).set_index(\"stride\").T\n",
    "        return df\n",
    "\n",
    "    def save_heatmap(\n",
    "        self,\n",
    "        title: str,\n",
    "        save_path: str,\n",
    "        figsize: tuple = (10, 8),\n",
    "        cmap: str = \"YlGnBu\",\n",
    "        colorbar_label: str = \"MAE\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        cmap : str, optional\n",
    "            カラーマップ (default: 'YlGnBu')\n",
    "        colorbar_label : str, optional\n",
    "            カラーバーのラベル (default: 'MAE')\n",
    "        \"\"\"\n",
    "        df = self._create_heatmap_dataframe()\n",
    "\n",
    "        # ヒートマップを作成\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(\n",
    "            df, annot=True, fmt=\".4f\", cmap=cmap, cbar_kws={\"label\": colorbar_label}\n",
    "        )\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.xlabel(\"Stride [s]\")\n",
    "        plt.ylabel(\"Window Size [s]\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def save_heatmap_std(self, title: str, save_path: str, figsize: tuple = (10, 8)):\n",
    "        \"\"\"\n",
    "        標準偏差のヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        \"\"\"\n",
    "        self.save_heatmap(\n",
    "            title,\n",
    "            save_path,\n",
    "            figsize,\n",
    "            cmap=\"Reds\",\n",
    "            colorbar_label=\"Standard Deviation\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "    \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    landmark_data_path = os.path.join(rootDir, SAVE_DIR, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_data.csv\")\n",
    "    landmark_data_df = pd.read_csv(landmark_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in landmark_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = landmark_data_df[landmark_data_df['landmark_id'] == landmark_id]\n",
    "            print(f'    landmark data shape: {landmark_df}')\n",
    "            \n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = (landmark_df['timestamp'] >= window_start_time) & (landmark_df['timestamp'] < window_end_time)\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_mean'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_mean'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_mean'].values\n",
    "\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['s_mean'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['l_mean'].values\n",
    "\n",
    "            # 窓情報を保存\n",
    "            window_info = {\n",
    "                'landmark_id': landmark_id,\n",
    "                'window_index': idx,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'saturation_signal_in_window': array_to_full_string(saturation_signal_in_window),\n",
    "                'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window)\n",
    "            }\n",
    "            all_window_results.append(window_info)\n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8614501",
   "metadata": {},
   "source": [
    "### 窓ごとにBVPとMAEを算出し、保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_BVPsignal(r_signals, g_signals, b_signals,  fps, deviceType, bvpMethod, bvpMethodName, method_params=None):\n",
    "    \"\"\"\n",
    "    RGB信号からBVP信号を抽出する関数\n",
    "    \"\"\"\n",
    "    rgb_signal = np.array([[r_signals, g_signals, b_signals]], dtype=np.float32)\n",
    "    print(f\"\\nRGB信号の形状: {rgb_signal.shape}\")\n",
    "    \n",
    "    signal_length = rgb_signal.shape[2]\n",
    "    min_required_length = 50\n",
    "    \n",
    "    if signal_length < min_required_length:\n",
    "        print(f\"警告: 信号長が短すぎます ({signal_length} < {min_required_length})。処理をスキップします。\")\n",
    "        return None, None\n",
    "    \n",
    "    filtered_signal = [rgb_signal]\n",
    "    \n",
    "    # デフォルトのメソッドパラメータ\n",
    "    if method_params is None:\n",
    "        method_params = {}\n",
    "    \n",
    "    # メソッド別パラメータ設定\n",
    "    if bvpMethodName in [\"cupy_POS\", \"cpu_POS\"]:\n",
    "        method_params['fps'] = fps\n",
    "    elif bvpMethodName in [\"cpu_ICA\", \"cpu_PCA\"]:\n",
    "        method_params['component'] = 'all_comp'\n",
    "    \n",
    "    print(f\"\\nBVP抽出開始 (メソッド: {bvpMethodName})\")\n",
    "    print(f\"パラメータ: {method_params}\")\n",
    "    \n",
    "    # BVP信号抽出\n",
    "    if method_params:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod,\n",
    "            params=method_params\n",
    "        )\n",
    "    else:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod\n",
    "        )\n",
    "    \n",
    "    # 生のBVP信号を保存\n",
    "    raw_bvp_signal = bvp_signal[0].copy() if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    # 後処理フィルタリング\n",
    "    bvp_signal = vhr.BVP.apply_filter(\n",
    "        bvp_signal,\n",
    "        vhr.BVP.BPfilter,\n",
    "        params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "    )\n",
    "    \n",
    "    bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "    \n",
    "    filtered_bvp_signal = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    print(f\"\\nBVP信号抽出完了\")\n",
    "    return raw_bvp_signal, filtered_bvp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_window_fft(values, fps):\n",
    "    \"\"\"\n",
    "    時系列データの最大周波数とスペクトル情報を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        分析対象の時系列データ\n",
    "    fps : int\n",
    "        サンプリング周波数（1秒あたりのフレーム数）\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        以下のキーを含む辞書：\n",
    "        - 'max_freq': 検出された最大周波数\n",
    "        - 'max_amplitude': 最大周波数のときの振幅\n",
    "        - 'frequencies': 周波数配列（正の周波数のみ）\n",
    "        - 'amplitudes': 振幅配列（正の周波数のみ）\n",
    "        - 'power_spectrum': パワースペクトル\n",
    "        - 'dominant_freqs': 上位5つの卓越周波数とその振幅\n",
    "        - 'spectral_centroid': スペクトル重心\n",
    "        - 'spectral_bandwidth': スペクトル帯域幅\n",
    "        - 'total_power': 全体のパワー\n",
    "    \"\"\"\n",
    "    # データをnumpy配列に変換\n",
    "    values = np.array(values)\n",
    "\n",
    "    # ゼロパディングで分解能を向上（窓長の8倍）\n",
    "    n_pad = len(values) * 8\n",
    "\n",
    "    # ハミング窓を適用（オプション：コメントアウトされている）\n",
    "    # window = np.hamming(len(values))\n",
    "    # windowed_data = values * window\n",
    "\n",
    "    # FFTを実行（ゼロパディング適用）\n",
    "    fft_result = np.fft.fft(values, n=n_pad)\n",
    "    fft_freq = np.fft.fftfreq(n_pad, 1 / fps)\n",
    "\n",
    "    # 正の周波数のみを取得\n",
    "    positive_freq_idx = fft_freq > 0\n",
    "    positive_fft = np.abs(fft_result[positive_freq_idx])\n",
    "    positive_freq = fft_freq[positive_freq_idx]\n",
    "    \n",
    "    # パワースペクトルを計算\n",
    "    power_spectrum = positive_fft ** 2\n",
    "\n",
    "    # 最大周波数の検出と補間\n",
    "    max_idx = np.argmax(positive_fft)\n",
    "    max_amplitude = positive_fft[max_idx]\n",
    "    \n",
    "    if 0 < max_idx < len(positive_fft) - 1:\n",
    "        # 3点を使用した放物線補間\n",
    "        alpha = positive_fft[max_idx - 1]\n",
    "        beta = positive_fft[max_idx]\n",
    "        gamma = positive_fft[max_idx + 1]\n",
    "        peak_pos = 0.5 * (alpha - gamma) / (alpha - 2 * beta + gamma)\n",
    "\n",
    "        # 補間された周波数と振幅\n",
    "        freq_resolution = fps / n_pad\n",
    "        max_freq = positive_freq[max_idx] + peak_pos * freq_resolution\n",
    "        \n",
    "        # 補間された振幅（放物線の頂点）\n",
    "        max_amplitude = beta - 0.25 * (alpha - gamma) * peak_pos\n",
    "    else:\n",
    "        max_freq = positive_freq[max_idx]\n",
    "    \n",
    "    # 上位5つの卓越周波数を検出\n",
    "    top_indices = np.argsort(positive_fft)[-5:][::-1]\n",
    "    dominant_freqs = [(positive_freq[idx], positive_fft[idx]) for idx in top_indices]\n",
    "    \n",
    "    # スペクトル特徴量の計算\n",
    "    # スペクトル重心（周波数の重み付き平均）\n",
    "    spectral_centroid = np.sum(positive_freq * positive_fft) / np.sum(positive_fft)\n",
    "    \n",
    "    # スペクトル帯域幅（重心からの重み付き分散）\n",
    "    spectral_bandwidth = np.sqrt(\n",
    "        np.sum(((positive_freq - spectral_centroid) ** 2) * positive_fft) / np.sum(positive_fft)\n",
    "    )\n",
    "    \n",
    "    # 全体のパワー\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    \n",
    "    # 結果を辞書にまとめる\n",
    "    result = {\n",
    "        'max_freq': max_freq,\n",
    "        'max_amplitude': max_amplitude,\n",
    "        'frequencies': positive_freq,\n",
    "        'amplitudes': positive_fft,\n",
    "        'power_spectrum': power_spectrum,\n",
    "        'dominant_freqs': dominant_freqs,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'total_power': total_power,\n",
    "        'freq_resolution': fps / n_pad,  # 周波数分解能\n",
    "        'nyquist_freq': fps / 2  # ナイキスト周波数\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e81a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    window_signals_data_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    window_signals_data_df = pd.read_csv(window_signals_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in window_signals_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = window_signals_data_df[window_signals_data_df['landmark_id'] == landmark_id]\n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = landmark_df['window_index'] == idx\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_signal_in_window'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_signal_in_window'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_signal_in_window'].values\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['saturation_signal_in_window'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['lightness_signal_in_window'].values\n",
    "\n",
    "            # 文字列をNumPy配列に変換\n",
    "            r_signal_in_window = np.fromstring(r_signal_in_window[0].strip('[]'), sep=' ') if len(r_signal_in_window) > 0 else np.array([])\n",
    "            g_signal_in_window = np.fromstring(g_signal_in_window[0].strip('[]'), sep=' ') if len(g_signal_in_window) > 0 else np.array([])\n",
    "            b_signal_in_window = np.fromstring(b_signal_in_window[0].strip('[]'), sep=' ') if len(b_signal_in_window) > 0 else np.array([])\n",
    "            saturation_signal_in_window = np.fromstring(saturation_signal_in_window[0].strip('[]'), sep=' ') if len(saturation_signal_in_window) > 0 else np.array([])\n",
    "            lightness_signal_in_window = np.fromstring(lightness_signal_in_window[0].strip('[]'), sep=' ') if len(lightness_signal_in_window) > 0 else np.array([])\n",
    "\n",
    "            print(f'    RGB信号の長さ: R={len(r_signal_in_window)}, G={len(g_signal_in_window)}, B={len(b_signal_in_window)}')\n",
    "\n",
    "            # BVPメソッドの設定\n",
    "            methodCombinations =  ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "            deviceType = methodCombinations[0]  # 'cuda'\n",
    "            bvpMethod = methodCombinations[1]   # cupy_POS\n",
    "            bvpMethodName = methodCombinations[2]  # \"cupy_POS\"\n",
    "\n",
    "            # rgbからBVPを計算\n",
    "            raw_bvp_signal_in_window, filtered_bvp_signal_in_window = extract_BVPsignal(\n",
    "                r_signal_in_window,\n",
    "                g_signal_in_window,\n",
    "                b_signal_in_window,\n",
    "                fps,\n",
    "                deviceType,\n",
    "                bvpMethod,\n",
    "                bvpMethodName\n",
    "            )\n",
    "            \n",
    "            # BVP信号の抽出に失敗した場合はスキップ\n",
    "            if filtered_bvp_signal_in_window is None:\n",
    "                print(f\"ウィンドウ {idx} をスキップ: BVP信号の抽出に失敗\")\n",
    "                continue\n",
    "            \n",
    "            # FFT解析\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "            filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "            fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "            # MAEの計算\n",
    "            rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "            rppg_freq = fft_result_dic['frequencies']\n",
    "            rppg_amplitude = fft_result_dic['amplitudes']\n",
    "            rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "            bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "            # 窓情報を保存\n",
    "            window_info = {\n",
    "                'landmark_id': landmark_id,\n",
    "                'window_index': idx,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'saturation_signal_in_window': array_to_full_string(saturation_signal_in_window),\n",
    "                'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window),\n",
    "                'raw_bvp_in_window': raw_bvp_signal_in_window,\n",
    "                'filtered_bvp_in_window': filtered_bvp_signal_in_window,\n",
    "                'ecg_bpm_in_window': ecg_bpm_in_window,\n",
    "                'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "                'rppg_bpm': rppg_bpm,\n",
    "                'bpm_MAE': bpm_MAE,\n",
    "                'max_freq': fft_result_dic['max_freq'],\n",
    "                'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "                'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "                'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "                'total_power': fft_result_dic['total_power']\n",
    "            }\n",
    "            all_window_results.append(window_info)\n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'{dataName}_window_analysis_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab914144",
   "metadata": {},
   "source": [
    "### ランドマークごとに輝度信号を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    window_signals_data_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    window_signals_data_df = pd.read_csv(window_signals_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    \n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in window_signals_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = window_signals_data_df[window_signals_data_df['landmark_id'] == landmark_id]\n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = landmark_df['window_index'] == idx\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_signal_in_window'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_signal_in_window'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_signal_in_window'].values\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['saturation_signal_in_window'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['lightness_signal_in_window'].values\n",
    "\n",
    "            # 文字列をNumPy配列に変換\n",
    "            r_signal_in_window = np.fromstring(r_signal_in_window[0].strip('[]'), sep=' ') if len(r_signal_in_window) > 0 else np.array([])\n",
    "            g_signal_in_window = np.fromstring(g_signal_in_window[0].strip('[]'), sep=' ') if len(g_signal_in_window) > 0 else np.array([])\n",
    "            b_signal_in_window = np.fromstring(b_signal_in_window[0].strip('[]'), sep=' ') if len(b_signal_in_window) > 0 else np.array([])\n",
    "            saturation_signal_in_window = np.fromstring(saturation_signal_in_window[0].strip('[]'), sep=' ') if len(saturation_signal_in_window) > 0 else np.array([])\n",
    "            lightness_signal_in_window = np.fromstring(lightness_signal_in_window[0].strip('[]'), sep=' ') if len(lightness_signal_in_window) > 0 else np.array([])\n",
    "\n",
    "            print(f'    RGB信号の長さ: R={len(r_signal_in_window)}, G={len(g_signal_in_window)}, B={len(b_signal_in_window)}')\n",
    "            \n",
    "            # RGB信号が存在しない場合はスキップ\n",
    "            if len(r_signal_in_window) == 0 or len(g_signal_in_window) == 0 or len(b_signal_in_window) == 0:\n",
    "                print(f'    警告: RGB信号が存在しないため、landmark {landmark_id} をスキップします')\n",
    "                continue\n",
    "            \n",
    "            # ============================================================================\n",
    "            # Intensity計算(POS法ベース)\n",
    "            # ============================================================================\n",
    "            try:\n",
    "                # RGB信号をCuPy配列に変換\n",
    "                rgb_signal = np.array([[r_signal_in_window, g_signal_in_window, b_signal_in_window]], dtype=np.float32)\n",
    "                rgb_cupy = cp.asarray(rgb_signal)\n",
    "                \n",
    "                # POS法のパラメータ\n",
    "                eps = 10**-9\n",
    "                X = rgb_cupy\n",
    "                fps_cupy = cp.float32(fps)\n",
    "                e, c, f = X.shape  # e = #estimators, c = 3 rgb ch., f = #frames\n",
    "                w = int(1.6 * fps_cupy)  # window length\n",
    "\n",
    "                # 固定の拍動ベクトル(論文の式30)\n",
    "                u_pbv = cp.array([0.33, 0.77, 0.53], dtype=cp.float32)\n",
    "\n",
    "                # 肌色調ベクトルを計算\n",
    "                r_signal_square = r_signal_in_window ** 2\n",
    "                g_signal_square = g_signal_in_window ** 2\n",
    "                b_signal_square = b_signal_in_window ** 2\n",
    "                norm = np.sqrt(r_signal_square + g_signal_square + b_signal_square)\n",
    "\n",
    "                normalized_r = r_signal_in_window / norm\n",
    "                normalized_g = g_signal_in_window / norm\n",
    "                normalized_b = b_signal_in_window / norm\n",
    "\n",
    "                skin_vector_array = np.array([normalized_r, normalized_g, normalized_b])\n",
    "                skin_vector = cp.mean(cp.asarray(skin_vector_array), axis=1)\n",
    "\n",
    "                # 標準化された肌色ベクトル\n",
    "                u_skin = skin_vector / (cp.linalg.norm(skin_vector) + eps)\n",
    "                \n",
    "                # u_pbvとu_skinに直交するベクトルを求める\n",
    "                v_n = cp.cross(u_skin, u_pbv)\n",
    "                normalize_v_n = v_n / (cp.linalg.norm(v_n) + eps)\n",
    "\n",
    "                # 投影行列P(1x3の行ベクトル)\n",
    "                P = cp.reshape(normalize_v_n, (1, 3))\n",
    "\n",
    "                # 初期化\n",
    "                intensity_signal = cp.zeros((e, f))\n",
    "\n",
    "                # スライディングウィンドウループ\n",
    "                for n in cp.arange(w, f):\n",
    "                    m = n - w + 1\n",
    "                    \n",
    "                    # 時間的正規化\n",
    "                    Cn = X[:, :, m:(n + 1)]\n",
    "                    M = 1.0 / (cp.mean(Cn, axis=2) + eps)\n",
    "                    M_expanded = cp.expand_dims(M, axis=2)\n",
    "                    Cn = cp.multiply(M_expanded, Cn)\n",
    "                    \n",
    "                    # 投影(uskinとupbvに直交する方向に投影してi(t)を抽出)\n",
    "                    for estimator_idx in range(e):\n",
    "                        projected = cp.dot(P, Cn[estimator_idx, :, :]).flatten()\n",
    "                        # ゼロ平均化\n",
    "                        projected = projected - cp.mean(projected)\n",
    "                        # オーバーラップ加算\n",
    "                        intensity_signal[estimator_idx, m:(n + 1)] = cp.add(\n",
    "                            intensity_signal[estimator_idx, m:(n + 1)], \n",
    "                            projected\n",
    "                        )\n",
    "                \n",
    "                # CuPy配列をNumPy配列に変換\n",
    "                bvp_numpy = cp.asnumpy(intensity_signal)\n",
    "                \n",
    "                raw_bvp_signal = [bvp_numpy]\n",
    "                bvp_signal = [bvp_numpy.copy()]\n",
    "\n",
    "                # 後処理フィルタリング\n",
    "                bvp_signal = vhr.BVP.apply_filter(\n",
    "                    bvp_signal,\n",
    "                    vhr.BVP.BPfilter,\n",
    "                    params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "                )\n",
    "                bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "\n",
    "                raw_bvp_signal_in_window = raw_bvp_signal[0] if len(raw_bvp_signal) > 0 else None\n",
    "                filtered_bvp_signal_in_window = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "\n",
    "                # FFT解析\n",
    "                raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "                filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "                fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "                # MAEの計算\n",
    "                rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "                bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "                print(f\"    Intensity結果: ECG BPM={ecg_bpm_in_window_mean:.2f}, rPPG BPM={rppg_bpm:.2f}, MAE={bpm_MAE:.2f}\")\n",
    "\n",
    "                # 結果を保存\n",
    "                window_info = {\n",
    "                    'window_index': idx,\n",
    "                    'landmark_id': landmark_id,\n",
    "                    'window_size': window_size,\n",
    "                    'stride': stride,\n",
    "                    'frame_start': frame_start,\n",
    "                    'frame_end': frame_end,\n",
    "                    'window_start_time': window_start_time,\n",
    "                    'window_end_time': window_end_time,\n",
    "                    'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                    'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                    'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                    'raw_intensity_in_window': array_to_full_string(raw_bvp_signal_in_window) if raw_bvp_signal_in_window is not None else '',\n",
    "                    'filtered_intensity_in_window': array_to_full_string(filtered_bvp_signal_in_window),\n",
    "                    'ecg_bpm_in_window': array_to_full_string(ecg_bpm_in_window),\n",
    "                    'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "                    'rppg_bpm': rppg_bpm,\n",
    "                    'bpm_MAE': bpm_MAE,\n",
    "                    'max_freq': fft_result_dic['max_freq'],\n",
    "                    'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "                    'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "                    'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "                    'total_power': fft_result_dic['total_power']\n",
    "                }\n",
    "                \n",
    "                all_window_results.append(window_info)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'    エラー: landmark {landmark_id}, window {idx} の処理中にエラーが発生しました: {e}')\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'window_intensity_landmark_{dataName}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nIntensity結果をCSVに保存: {results_csv_path}\")\n",
    "    print(f\"保存されたデータ件数: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "holistic_rppg_results_dir = \"rppgAccuracyEvalu\"\n",
    "SPLIT_TIME = 90\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "    \n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "    \n",
    "    # 肌検出RPPG結果の読み込み\n",
    "    hol_POS_results_df = pd.read_csv(os.path.join(rootDir, holistic_rppg_results_dir, f'window_analysis_{dataName}.csv'))\n",
    "    hol_POS_first_half_mask = hol_POS_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    hol_POS_second_half_mask = hol_POS_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    \n",
    "    hol_POS_first_half_df = hol_POS_results_df[hol_POS_first_half_mask].copy()\n",
    "    hol_POS_second_half_df = hol_POS_results_df[hol_POS_second_half_mask].copy()\n",
    "    \n",
    "    # landmarkごとの結果を読み込み\n",
    "    landmark_window_analysis_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_window_analysis_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    landmark_results_df = pd.read_csv(landmark_window_analysis_path)\n",
    "    landmark_first_half_mask = landmark_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    landmark_second_half_mask = landmark_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    landmark_first_half_df = landmark_results_df[landmark_first_half_mask].copy()\n",
    "    landmark_second_half_df = landmark_results_df[landmark_second_half_mask].copy()\n",
    "    \n",
    "    # 輝度信号ごとの結果を読み込み\n",
    "    intensity_window_analysis_path = os.path.join(rootDir, SAVE_DIR, f'window_intensity_landmark_{dataName}.csv')\n",
    "    intensity_results_df = pd.read_csv(intensity_window_analysis_path)\n",
    "    intensity_first_half_mask = intensity_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    intensity_second_half_mask = intensity_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    intensity_first_half_df = intensity_results_df[intensity_first_half_mask].copy()\n",
    "    intensity_second_half_df = intensity_results_df[intensity_second_half_mask].copy()\n",
    "    \n",
    "    # 図の保存先\n",
    "    figure_dir = os.path.join(rootDir, SAVE_DIR, 'heatmaps')\n",
    "    os.makedirs(figure_dir, exist_ok=True)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 前半と後半それぞれでヒートマップを作成\n",
    "    # ============================================================================\n",
    "    for period, (landmark_df, intensity_df, hol_df) in [\n",
    "        ('first_half', (landmark_first_half_df, intensity_first_half_df, hol_POS_first_half_df)),\n",
    "        ('second_half', (landmark_second_half_df, intensity_second_half_df, hol_POS_second_half_df))\n",
    "    ]:\n",
    "        print(f'\\n{period}のヒートマップを作成中...')\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 1. Landmarkベースの手法のヒートマップ\n",
    "        # ============================================================================\n",
    "        if len(landmark_df) > 0:\n",
    "            # landmark_idを名前に変換\n",
    "            landmark_df_copy = landmark_df.copy()\n",
    "            landmark_df_copy['landmark_name'] = landmark_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            # window_sizeとlandmark_nameでグループ化してMAEの平均を計算\n",
    "            pivot_data = landmark_df_copy.groupby(['window_size', 'landmark_name'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table = pivot_data.pivot(index='window_size', columns='landmark_name', values='bpm_MAE')\n",
    "            \n",
    "            # 列の順序を定義(視覚的に分かりやすい順序)\n",
    "            desired_order = [\"Forehead\", \"Upper Left Cheek\", \"Lower Left Cheek\", \n",
    "                           \"Upper Right Cheek\", \"Lower Right Cheek\", \"Nose\", \"Chin\"]\n",
    "            # 実際に存在する列のみを使用\n",
    "            column_order = [col for col in desired_order if col in pivot_table.columns]\n",
    "            pivot_table = pivot_table[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Landmark Region', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Landmark Region and Window Size - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_landmark_{period}_{dataName}.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Landmarkヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 2. Intensityベースの手法のヒートマップ\n",
    "        # ============================================================================\n",
    "        if len(intensity_df) > 0:\n",
    "            # landmark_idを名前に変換\n",
    "            intensity_df_copy = intensity_df.copy()\n",
    "            intensity_df_copy['landmark_name'] = intensity_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            # window_sizeとlandmark_nameでグループ化してMAEの平均を計算\n",
    "            pivot_data_intensity = intensity_df_copy.groupby(['window_size', 'landmark_name'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table_intensity = pivot_data_intensity.pivot(index='window_size', columns='landmark_name', values='bpm_MAE')\n",
    "            \n",
    "            # 列の順序を定義\n",
    "            column_order = [col for col in desired_order if col in pivot_table_intensity.columns]\n",
    "            pivot_table_intensity = pivot_table_intensity[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_table_intensity, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Landmark Region', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Landmark Region and Window Size (Intensity) - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_intensity_{period}_{dataName}.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Intensityヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 3. 肌検出ベースの手法のヒートマップ(BVP手法別)\n",
    "        # ============================================================================\n",
    "        if len(hol_df) > 0:\n",
    "            # window_sizeとbvp_methodでグループ化してMAEの平均を計算\n",
    "            pivot_data_hol = hol_df.groupby(['window_size', 'bvp_method'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table_hol = pivot_data_hol.pivot(index='window_size', columns='bvp_method', values='bpm_MAE')\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            sns.heatmap(pivot_table_hol, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('BVP Method', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs BVP Method and Window Size (Skin Detection) - {dataName} ({period})', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_skindetection_{period}_{dataName}.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Skin Detectionヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 4. 統合ヒートマップ(Landmark + Intensity + Skin Detection)\n",
    "        # ============================================================================\n",
    "        # 各手法の平均MAEを窓長ごとに計算\n",
    "        combined_data = []\n",
    "        \n",
    "        # Landmarkベース(各landmarkの平均)\n",
    "        if len(landmark_df) > 0:\n",
    "            landmark_df_copy = landmark_df.copy()\n",
    "            landmark_df_copy['landmark_name'] = landmark_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            for window_size in landmark_df_copy['window_size'].unique():\n",
    "                window_data = landmark_df_copy[landmark_df_copy['window_size'] == window_size]\n",
    "                for landmark_name in window_data['landmark_name'].unique():\n",
    "                    landmark_mae = window_data[window_data['landmark_name'] == landmark_name]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'LM_{landmark_name}',\n",
    "                        'mae': landmark_mae\n",
    "                    })\n",
    "        \n",
    "        # Intensityベース(各landmarkの平均)\n",
    "        if len(intensity_df) > 0:\n",
    "            intensity_df_copy = intensity_df.copy()\n",
    "            intensity_df_copy['landmark_name'] = intensity_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            for window_size in intensity_df_copy['window_size'].unique():\n",
    "                window_data = intensity_df_copy[intensity_df_copy['window_size'] == window_size]\n",
    "                for landmark_name in window_data['landmark_name'].unique():\n",
    "                    intensity_mae = window_data[window_data['landmark_name'] == landmark_name]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'INT_{landmark_name}',\n",
    "                        'mae': intensity_mae\n",
    "                    })\n",
    "        \n",
    "        # Skin Detectionベース(各BVP手法)\n",
    "        if len(hol_df) > 0:\n",
    "            for window_size in hol_df['window_size'].unique():\n",
    "                window_data = hol_df[hol_df['window_size'] == window_size]\n",
    "                for bvp_method in window_data['bvp_method'].unique():\n",
    "                    hol_mae = window_data[window_data['bvp_method'] == bvp_method]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'SD_{bvp_method}',\n",
    "                        'mae': hol_mae\n",
    "                    })\n",
    "        \n",
    "        if len(combined_data) > 0:\n",
    "            combined_df = pd.DataFrame(combined_data)\n",
    "            pivot_combined = combined_df.pivot(index='window_size', columns='method', values='mae')\n",
    "            \n",
    "            # 列の順序を整理(Landmark -> Intensity -> Skin Detection)\n",
    "            landmark_cols = [col for col in pivot_combined.columns if col.startswith('LM_')]\n",
    "            intensity_cols = [col for col in pivot_combined.columns if col.startswith('INT_')]\n",
    "            skin_cols = [col for col in pivot_combined.columns if col.startswith('SD_')]\n",
    "            \n",
    "            # 各グループ内でソート\n",
    "            landmark_cols = sorted(landmark_cols, key=lambda x: desired_order.index(x.replace('LM_', '')) if x.replace('LM_', '') in desired_order else 999)\n",
    "            intensity_cols = sorted(intensity_cols, key=lambda x: desired_order.index(x.replace('INT_', '')) if x.replace('INT_', '') in desired_order else 999)\n",
    "            skin_cols = sorted(skin_cols)\n",
    "            \n",
    "            column_order = landmark_cols + intensity_cols + skin_cols\n",
    "            pivot_combined = pivot_combined[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(24, 8))\n",
    "            sns.heatmap(pivot_combined, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Method (LM=Landmark, INT=Intensity, SD=Skin Detection)', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Method and Window Size - All Methods Combined - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_combined_{period}_{dataName}.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'統合ヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "\n",
    "print('\\n全てのヒートマップ作成が完了しました。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9a87d",
   "metadata": {},
   "source": [
    "輝度信号を参考にした結果算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33eea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    window_signals_data_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    window_signals_data_df = pd.read_csv(window_signals_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    \n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in window_signals_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = window_signals_data_df[window_signals_data_df['landmark_id'] == landmark_id]\n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = landmark_df['window_index'] == idx\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_signal_in_window'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_signal_in_window'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_signal_in_window'].values\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['saturation_signal_in_window'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['lightness_signal_in_window'].values\n",
    "\n",
    "            # 文字列をNumPy配列に変換\n",
    "            r_signal_in_window = np.fromstring(r_signal_in_window[0].strip('[]'), sep=' ') if len(r_signal_in_window) > 0 else np.array([])\n",
    "            g_signal_in_window = np.fromstring(g_signal_in_window[0].strip('[]'), sep=' ') if len(g_signal_in_window) > 0 else np.array([])\n",
    "            b_signal_in_window = np.fromstring(b_signal_in_window[0].strip('[]'), sep=' ') if len(b_signal_in_window) > 0 else np.array([])\n",
    "            saturation_signal_in_window = np.fromstring(saturation_signal_in_window[0].strip('[]'), sep=' ') if len(saturation_signal_in_window) > 0 else np.array([])\n",
    "            lightness_signal_in_window = np.fromstring(lightness_signal_in_window[0].strip('[]'), sep=' ') if len(lightness_signal_in_window) > 0 else np.array([])\n",
    "\n",
    "            print(f'    RGB信号の長さ: R={len(r_signal_in_window)}, G={len(g_signal_in_window)}, B={len(b_signal_in_window)}')\n",
    "            \n",
    "            # RGB信号が存在しない場合はスキップ\n",
    "            if len(r_signal_in_window) == 0 or len(g_signal_in_window) == 0 or len(b_signal_in_window) == 0:\n",
    "                print(f'    警告: RGB信号が存在しないため、landmark {landmark_id} をスキップします')\n",
    "                continue\n",
    "            \n",
    "            # RGB信号をCuPy配列に変換\n",
    "            rgb_signal = np.array([[r_signal_in_window, g_signal_in_window, b_signal_in_window]], dtype=np.float32)\n",
    "\n",
    "            # CuPy配列に変換\n",
    "            rgb_cupy = cp.asarray(rgb_signal)\n",
    "\n",
    "            # POS法のパラメータ\n",
    "            eps = 10**-9\n",
    "            X = rgb_cupy\n",
    "            fps_cupy = cp.float32(fps)\n",
    "            e, c, f = X.shape  # e = #estimators, c = 3 rgb ch., f = #frames\n",
    "            w = int(1.6 * fps_cupy)  # window length\n",
    "\n",
    "            # 投影行列P(現在のパターンを使用)\n",
    "            P_cupy = cp.asarray(np.array([[0.0, 1.0, -1.0],\n",
    "                                         [-1.0, 1.0, 1.0]], dtype=np.float32))\n",
    "            Q = cp.stack([P_cupy for _ in range(e)], axis=0)\n",
    "\n",
    "            # 初期化\n",
    "            H = cp.zeros((e, f))\n",
    "\n",
    "            # 診断情報を保存するリスト\n",
    "            alpha_list = []\n",
    "            M_list = []\n",
    "            S1_list = []\n",
    "            S2_list = []\n",
    "            alpha_S2_list = []\n",
    "            window_indices = []\n",
    "\n",
    "            # スライディングウィンドウループ\n",
    "            for n in cp.arange(w, f):\n",
    "                m = n - w + 1\n",
    "                \n",
    "                # 時間的正規化\n",
    "                Cn = X[:, :, m:(n + 1)]\n",
    "                M = 1.0 / (cp.mean(Cn, axis=2) + eps)\n",
    "                M_expanded = cp.expand_dims(M, axis=2)\n",
    "                Cn = cp.multiply(M_expanded, Cn)\n",
    "                \n",
    "                # Mの値を保存\n",
    "                M_list.append(cp.asnumpy(M))\n",
    "                \n",
    "                # 投影\n",
    "                S = cp.dot(Q, Cn)\n",
    "                S = S[0, :, :, :]\n",
    "                S = cp.swapaxes(S, 0, 1)\n",
    "                \n",
    "                # チューニング\n",
    "                S1 = S[:, 0, :]\n",
    "                S2 = S[:, 1, :]\n",
    "                alpha = cp.std(S1, axis=1) / (eps + cp.std(S2, axis=1))\n",
    "                \n",
    "                # S1とS2を保存\n",
    "                S1_list.append(cp.asnumpy(S1))\n",
    "                S2_list.append(cp.asnumpy(S2))\n",
    "                \n",
    "                # alphaの値を保存\n",
    "                alpha_list.append(cp.asnumpy(alpha))\n",
    "                \n",
    "                alpha_expanded = cp.expand_dims(alpha, axis=1)\n",
    "                alpha_S2 = alpha_expanded * S2\n",
    "                \n",
    "                # alpha*S2を保存\n",
    "                alpha_S2_list.append(cp.asnumpy(alpha_S2))\n",
    "                \n",
    "                window_indices.append(int(n))\n",
    "                \n",
    "                Hn = cp.add(S1, alpha_S2)\n",
    "                Hnm = Hn - cp.expand_dims(cp.mean(Hn, axis=1), axis=1)\n",
    "                \n",
    "                # オーバーラップ加算\n",
    "                H[:, m:(n + 1)] = cp.add(H[:, m:(n + 1)], Hnm)\n",
    "            \n",
    "                \n",
    "            # CuPy配列をNumPy配列に変換\n",
    "            bvp_cupy = H\n",
    "            bvp_numpy = cp.asnumpy(bvp_cupy)\n",
    "\n",
    "            raw_bvp_signal = [bvp_numpy]\n",
    "            bvp_signal = [bvp_numpy.copy()]\n",
    "\n",
    "            # 後処理フィルタリング\n",
    "            bvp_signal = vhr.BVP.apply_filter(\n",
    "                bvp_signal,\n",
    "                vhr.BVP.BPfilter,\n",
    "                params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "            )\n",
    "            bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal[0] if len(raw_bvp_signal) > 0 else None\n",
    "            filtered_bvp_signal_in_window = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "\n",
    "            # FFT解析\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "            filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "            fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "            # MAEの計算\n",
    "            rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "            bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "            # 結果を保存\n",
    "            window_info = {\n",
    "                'window_index': idx,\n",
    "                'landmark_id': landmark_id,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'raw_bvp_in_window': array_to_full_string(raw_bvp_signal_in_window) if raw_bvp_signal_in_window is not None else '',\n",
    "                'filtered_bvp_in_window': array_to_full_string(filtered_bvp_signal_in_window),\n",
    "                'ecg_bpm_in_window': array_to_full_string(ecg_bpm_in_window),\n",
    "                'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "                'rppg_bpm': rppg_bpm,\n",
    "                'bpm_MAE': bpm_MAE,\n",
    "                'max_freq': fft_result_dic['max_freq'],\n",
    "                'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "                'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "                'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "                'total_power': fft_result_dic['total_power']\n",
    "            }\n",
    "            \n",
    "            all_window_results.append(window_info)\n",
    "\n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'{dataName}_window_analysis_advanced_POS_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nBVP結果をCSVに保存: {results_csv_path}\")\n",
    "    print(f\"保存されたデータ件数: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "holistic_rppg_results_dir = \"rppgAccuracyEvalu\"\n",
    "SPLIT_TIME = 90\n",
    "\n",
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "    \n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "    \n",
    "    # 肌検出RPPG結果の読み込み\n",
    "    hol_POS_results_df = pd.read_csv(os.path.join(rootDir, holistic_rppg_results_dir, f'window_analysis_{dataName}.csv'))\n",
    "    hol_POS_first_half_mask = hol_POS_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    hol_POS_second_half_mask = hol_POS_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    \n",
    "    hol_POS_first_half_df = hol_POS_results_df[hol_POS_first_half_mask].copy()\n",
    "    hol_POS_second_half_df = hol_POS_results_df[hol_POS_second_half_mask].copy()\n",
    "    \n",
    "    # landmarkごとの結果を読み込み\n",
    "    landmark_window_analysis_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_window_analysis_advanced_POS_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    landmark_results_df = pd.read_csv(landmark_window_analysis_path)\n",
    "    landmark_first_half_mask = landmark_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    landmark_second_half_mask = landmark_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    landmark_first_half_df = landmark_results_df[landmark_first_half_mask].copy()\n",
    "    landmark_second_half_df = landmark_results_df[landmark_second_half_mask].copy()\n",
    "    \n",
    "    # 輝度信号ごとの結果を読み込み\n",
    "    intensity_window_analysis_path = os.path.join(rootDir, SAVE_DIR, f'window_intensity_landmark_{dataName}.csv')\n",
    "    intensity_results_df = pd.read_csv(intensity_window_analysis_path)\n",
    "    intensity_first_half_mask = intensity_results_df['window_end_time'] <= SPLIT_TIME\n",
    "    intensity_second_half_mask = intensity_results_df['window_start_time'] >= SPLIT_TIME\n",
    "    intensity_first_half_df = intensity_results_df[intensity_first_half_mask].copy()\n",
    "    intensity_second_half_df = intensity_results_df[intensity_second_half_mask].copy()\n",
    "    \n",
    "    # 図の保存先\n",
    "    figure_dir = os.path.join(rootDir, SAVE_DIR, 'heatmaps')\n",
    "    os.makedirs(figure_dir, exist_ok=True)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 前半と後半それぞれでヒートマップを作成\n",
    "    # ============================================================================\n",
    "    for period, (landmark_df, intensity_df, hol_df) in [\n",
    "        ('first_half', (landmark_first_half_df, intensity_first_half_df, hol_POS_first_half_df)),\n",
    "        ('second_half', (landmark_second_half_df, intensity_second_half_df, hol_POS_second_half_df))\n",
    "    ]:\n",
    "        print(f'\\n{period}のヒートマップを作成中...')\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 1. Landmarkベースの手法のヒートマップ\n",
    "        # ============================================================================\n",
    "        if len(landmark_df) > 0:\n",
    "            # landmark_idを名前に変換\n",
    "            landmark_df_copy = landmark_df.copy()\n",
    "            landmark_df_copy['landmark_name'] = landmark_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            # window_sizeとlandmark_nameでグループ化してMAEの平均を計算\n",
    "            pivot_data = landmark_df_copy.groupby(['window_size', 'landmark_name'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table = pivot_data.pivot(index='window_size', columns='landmark_name', values='bpm_MAE')\n",
    "            \n",
    "            # 列の順序を定義(視覚的に分かりやすい順序)\n",
    "            desired_order = [\"Forehead\", \"Upper Left Cheek\", \"Lower Left Cheek\", \n",
    "                           \"Upper Right Cheek\", \"Lower Right Cheek\", \"Nose\", \"Chin\"]\n",
    "            # 実際に存在する列のみを使用\n",
    "            column_order = [col for col in desired_order if col in pivot_table.columns]\n",
    "            pivot_table = pivot_table[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Landmark Region', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Landmark Region and Window Size - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_landmark_{period}_{dataName}_adaptive.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Landmarkヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 2. Intensityベースの手法のヒートマップ\n",
    "        # ============================================================================\n",
    "        if len(intensity_df) > 0:\n",
    "            # landmark_idを名前に変換\n",
    "            intensity_df_copy = intensity_df.copy()\n",
    "            intensity_df_copy['landmark_name'] = intensity_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            # window_sizeとlandmark_nameでグループ化してMAEの平均を計算\n",
    "            pivot_data_intensity = intensity_df_copy.groupby(['window_size', 'landmark_name'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table_intensity = pivot_data_intensity.pivot(index='window_size', columns='landmark_name', values='bpm_MAE')\n",
    "            \n",
    "            # 列の順序を定義\n",
    "            column_order = [col for col in desired_order if col in pivot_table_intensity.columns]\n",
    "            pivot_table_intensity = pivot_table_intensity[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_table_intensity, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Landmark Region', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Landmark Region and Window Size (Intensity) - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_intensity_{period}_{dataName}_adaptive.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Intensityヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 3. 肌検出ベースの手法のヒートマップ(BVP手法別)\n",
    "        # ============================================================================\n",
    "        if len(hol_df) > 0:\n",
    "            # window_sizeとbvp_methodでグループ化してMAEの平均を計算\n",
    "            pivot_data_hol = hol_df.groupby(['window_size', 'bvp_method'])['bpm_MAE'].mean().reset_index()\n",
    "            pivot_table_hol = pivot_data_hol.pivot(index='window_size', columns='bvp_method', values='bpm_MAE')\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            sns.heatmap(pivot_table_hol, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('BVP Method', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs BVP Method and Window Size (Skin Detection) - {dataName} ({period})', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_skindetection_{period}_{dataName}_adaptive.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Skin Detectionヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 4. 統合ヒートマップ(Landmark + Intensity + Skin Detection)\n",
    "        # ============================================================================\n",
    "        # 各手法の平均MAEを窓長ごとに計算\n",
    "        combined_data = []\n",
    "        \n",
    "        # Landmarkベース(各landmarkの平均)\n",
    "        if len(landmark_df) > 0:\n",
    "            landmark_df_copy = landmark_df.copy()\n",
    "            landmark_df_copy['landmark_name'] = landmark_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            for window_size in landmark_df_copy['window_size'].unique():\n",
    "                window_data = landmark_df_copy[landmark_df_copy['window_size'] == window_size]\n",
    "                for landmark_name in window_data['landmark_name'].unique():\n",
    "                    landmark_mae = window_data[window_data['landmark_name'] == landmark_name]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'LM_{landmark_name}',\n",
    "                        'mae': landmark_mae\n",
    "                    })\n",
    "        \n",
    "        # Intensityベース(各landmarkの平均)\n",
    "        if len(intensity_df) > 0:\n",
    "            intensity_df_copy = intensity_df.copy()\n",
    "            intensity_df_copy['landmark_name'] = intensity_df_copy['landmark_id'].map(LANDMARK_ID_NAME_MAP)\n",
    "            \n",
    "            for window_size in intensity_df_copy['window_size'].unique():\n",
    "                window_data = intensity_df_copy[intensity_df_copy['window_size'] == window_size]\n",
    "                for landmark_name in window_data['landmark_name'].unique():\n",
    "                    intensity_mae = window_data[window_data['landmark_name'] == landmark_name]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'INT_{landmark_name}',\n",
    "                        'mae': intensity_mae\n",
    "                    })\n",
    "        \n",
    "        # Skin Detectionベース(各BVP手法)\n",
    "        if len(hol_df) > 0:\n",
    "            for window_size in hol_df['window_size'].unique():\n",
    "                window_data = hol_df[hol_df['window_size'] == window_size]\n",
    "                for bvp_method in window_data['bvp_method'].unique():\n",
    "                    hol_mae = window_data[window_data['bvp_method'] == bvp_method]['bpm_MAE'].mean()\n",
    "                    combined_data.append({\n",
    "                        'window_size': window_size,\n",
    "                        'method': f'SD_{bvp_method}',\n",
    "                        'mae': hol_mae\n",
    "                    })\n",
    "        \n",
    "        if len(combined_data) > 0:\n",
    "            combined_df = pd.DataFrame(combined_data)\n",
    "            pivot_combined = combined_df.pivot(index='window_size', columns='method', values='mae')\n",
    "            \n",
    "            # 列の順序を整理(Landmark -> Intensity -> Skin Detection)\n",
    "            landmark_cols = [col for col in pivot_combined.columns if col.startswith('LM_')]\n",
    "            intensity_cols = [col for col in pivot_combined.columns if col.startswith('INT_')]\n",
    "            skin_cols = [col for col in pivot_combined.columns if col.startswith('SD_')]\n",
    "            \n",
    "            # 各グループ内でソート\n",
    "            landmark_cols = sorted(landmark_cols, key=lambda x: desired_order.index(x.replace('LM_', '')) if x.replace('LM_', '') in desired_order else 999)\n",
    "            intensity_cols = sorted(intensity_cols, key=lambda x: desired_order.index(x.replace('INT_', '')) if x.replace('INT_', '') in desired_order else 999)\n",
    "            skin_cols = sorted(skin_cols)\n",
    "            \n",
    "            column_order = landmark_cols + intensity_cols + skin_cols\n",
    "            pivot_combined = pivot_combined[column_order]\n",
    "            \n",
    "            # ヒートマップ作成\n",
    "            fig, ax = plt.subplots(figsize=(24, 8))\n",
    "            sns.heatmap(pivot_combined, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                       cbar_kws={'label': 'Mean MAE (BPM)'}, ax=ax)\n",
    "            ax.set_xlabel('Method (LM=Landmark, INT=Intensity, SD=Skin Detection)', fontsize=12)\n",
    "            ax.set_ylabel('Window Size [s]', fontsize=12)\n",
    "            ax.set_title(f'MAE vs Method and Window Size - All Methods Combined - {dataName} ({period})', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(figure_dir, f'heatmap_mae_combined_{period}_{dataName}_adaptive.png')\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'統合ヒートマップを保存: {output_path}')\n",
    "            plt.close()\n",
    "\n",
    "print('\\n全てのヒートマップ作成が完了しました。')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvhr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
