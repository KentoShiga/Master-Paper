{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import ConvexHull\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyVHR as vhr\n",
    "from pyVHR.extraction.sig_processing import SignalProcessing\n",
    "from pyVHR.plot.visualize import *\n",
    "from pyVHR.BVP import *\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# 修正: scikit-image 0.18.3用のインポート\n",
    "from skimage.feature import local_binary_pattern\n",
    "# graycomatrixとgraycopropsは古いバージョンでは別の場所にあります\n",
    "try:\n",
    "    from skimage.feature import greycomatrix as graycomatrix, greycoprops as graycoprops\n",
    "except ImportError:\n",
    "    # 別の方法を試す\n",
    "    from skimage.feature import texture\n",
    "    # または関数を使わない場合はコメントアウト\n",
    "    graycomatrix = None\n",
    "    graycoprops = None\n",
    "    print(\"警告: graycomatrix/graycopropsをインポートできませんでした\")\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from scipy.ndimage import laplace\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力とする動画と動画のファイル名を取得\n",
    "root_dir = \"experimentData\\\\\"\n",
    "data_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "movie_paths = []\n",
    "movie_names = []\n",
    "true_value_csv_array = []\n",
    "true_value_rri_csv_array = []\n",
    "print(\"動画ディレクトリ:\", data_dirs)\n",
    "\n",
    "for i in range(len(data_dirs)):\n",
    "    data_dir = data_dirs[i]\n",
    "\n",
    "    # 動画ファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.avi')]\n",
    "    movie_paths.extend(movie_files)\n",
    "\n",
    "    movie_name = os.path.basename(data_dir)\n",
    "    movie_names.append(movie_name)\n",
    "\n",
    "    # ppgファイルのパスを取得\n",
    "    movie_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    true_value_csv_array = [f.replace('.avi', '.csv') for f in movie_paths if f.endswith('.avi')]\n",
    "    true_value_rri_csv_array.append(os.path.join(data_dir, 'RRI_Simple_' + movie_name + '.csv'))\n",
    "\n",
    "\n",
    "f_1_ffi = 0.0399  # LFのはじめ\n",
    "f_2 = 0.151  # LFの終わり、HFのはじめ\n",
    "f_3 = 0.401  # HFの終わり\n",
    "\n",
    "start_index = 0\n",
    "end_index = len(movie_paths)\n",
    "end_index = 1\n",
    "\n",
    "data_dirs = data_dirs[start_index:end_index]\n",
    "movie_paths = movie_paths[start_index:end_index]\n",
    "movie_names = movie_names[start_index:end_index]\n",
    "true_value_csv_array = true_value_csv_array[start_index:end_index]\n",
    "true_value_rri_csv_array = true_value_rri_csv_array[start_index:end_index]\n",
    "\n",
    "print(f\"data_dirs: {data_dirs}\")\n",
    "print(f\"movie_paths: {movie_paths}\")\n",
    "print(f\"movie_names: {movie_names}\")\n",
    "print(f\"true_value_csv_array: {true_value_csv_array}\")\n",
    "print(f\"true_value_rri_csv_array: {true_value_rri_csv_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR  = \"LandmarksAccuracyEvalResults\"\n",
    "# rPPGに最適なランドマーク番号を定義\n",
    "\n",
    "# 代表的な部分のみ\n",
    "# FOREHEAD_LANDMARKS = [151]  # 額\n",
    "UPPER_LEFT_CHEEK_LANDMARKS = [119]  # 左頬\n",
    "LOWER_LEFT_CHEEK_LANDMARKS = [207]  # 左頬\n",
    "UPPER_RIGHT_CHEEK_LANDMARKS = [347]  # 右頬\n",
    "LOWER_RIGHT_CHEEK_LANDMARKS = [425]  # 右頬\n",
    "NOSE_LANDMARKS = [4]\n",
    "CHIN_LANDMARKS = [200]  # 顎\n",
    "\n",
    "# ALL_RPPG_LANDMARKS = FOREHEAD_LANDMARKS + UPPER_LEFT_CHEEK_LANDMARKS + LOWER_LEFT_CHEEK_LANDMARKS + UPPER_RIGHT_CHEEK_LANDMARKS + LOWER_RIGHT_CHEEK_LANDMARKS + NOSE_LANDMARKS + CHIN_LANDMARKS\n",
    "ALL_RPPG_LANDMARKS = UPPER_LEFT_CHEEK_LANDMARKS + LOWER_LEFT_CHEEK_LANDMARKS + UPPER_RIGHT_CHEEK_LANDMARKS + LOWER_RIGHT_CHEEK_LANDMARKS + NOSE_LANDMARKS + CHIN_LANDMARKS\n",
    "# PATCH_SIZE = 10.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "PATCH_SIZE = 30.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "# PATCH_SIZE = 50.0  # ランドマーク周辺のBoxelの一辺の長さ（ピクセル数）\n",
    "\n",
    "LANDMARK_ID_NAME_MAP = {\n",
    "    151: \"Forehead\",\n",
    "    119: \"Upper Left Cheek\",\n",
    "    207: \"Lower Left Cheek\",\n",
    "    347: \"Upper Right Cheek\",\n",
    "    425: \"Lower Right Cheek\",\n",
    "    4: \"Nose\",\n",
    "    200: \"Chin\"\n",
    "}\n",
    "\n",
    "GLOBAL_SAVE_DIR = root_dir\n",
    "print(f\"GLOBAL_SAVE_DIR: {GLOBAL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273c039",
   "metadata": {},
   "source": [
    "ランドマークの座標を記録\n",
    "- {dataName}_landmarks_coordinates.csvを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_idx in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    saveDir = os.path.join(rootDir, SAVE_DIR)\n",
    "    print(f\"ランドマーク抽出結果保存ディレクトリ: {saveDir}\")\n",
    "    os.makedirs(saveDir, exist_ok=True)\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "    \n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    \n",
    "    # 1フレーム目を読み込む\n",
    "    ret, first_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: 最初のフレームを読み込めませんでした: {inputMoviePath}\")\n",
    "        continue\n",
    "    \n",
    "    # === Step 1: ランドマーク抽出用のSignalProcessing初期化 ===\n",
    "    print(\"=== ランドマーク抽出開始 ===\")\n",
    "    sig_processing = SignalProcessing()\n",
    "    sig_processing.set_landmarks(ALL_RPPG_LANDMARKS)\n",
    "    sig_processing.set_square_patches_side(PATCH_SIZE)\n",
    "    \n",
    "    # 可視化を有効化\n",
    "    sig_processing.set_visualize_skin_and_landmarks(\n",
    "        visualize_skin=True,\n",
    "        visualize_landmarks=True,\n",
    "        visualize_landmarks_number=True,\n",
    "        visualize_patch=True\n",
    "    )\n",
    "    \n",
    "    # 肌抽出器を設定(ConvexHullを使用)\n",
    "    sig_processing.set_skin_extractor(vhr.extraction.SkinExtractionConvexHull('CPU'))\n",
    "    \n",
    "    # 1フレームのみ処理\n",
    "    sig_processing.set_total_frames(1)\n",
    "    \n",
    "    # ダミーでextract_patchesを実行してランドマーク検出を行う\n",
    "    try:\n",
    "        _ = sig_processing.extract_patches(inputMoviePath, \"squares\", \"mean\")\n",
    "        \n",
    "        # 可視化画像を取得\n",
    "        visualize_patches = sig_processing.get_visualize_patches()\n",
    "        \n",
    "        if len(visualize_patches) > 0:\n",
    "            # 1フレーム目の可視化画像を保存\n",
    "            output_path = os.path.join(saveDir, f\"{dataName}_landmarks_frame1.png\")\n",
    "            cv2.imwrite(output_path, visualize_patches[0])\n",
    "            print(f\"ランドマーク画像を保存しました: {output_path}\")\n",
    "            \n",
    "            # ランドマークの座標を取得して保存\n",
    "            # MediaPipeを使用してランドマークを検出\n",
    "            import mediapipe as mp\n",
    "            mp_face_mesh = mp.solutions.face_mesh\n",
    "            \n",
    "            with mp_face_mesh.FaceMesh(\n",
    "                static_image_mode=True,\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=True,\n",
    "                min_detection_confidence=0.5) as face_mesh:\n",
    "                \n",
    "                # RGB変換\n",
    "                frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "                results = face_mesh.process(frame_rgb)\n",
    "                \n",
    "                if results.multi_face_landmarks:\n",
    "                    landmarks_data = []\n",
    "                    face_landmarks = results.multi_face_landmarks[0]\n",
    "                    h, w = first_frame.shape[:2]\n",
    "                    \n",
    "                    # 使用したランドマークの座標を取得\n",
    "                    for idx in ALL_RPPG_LANDMARKS:\n",
    "                        landmark = face_landmarks.landmark[idx]\n",
    "                        x = int(landmark.x * w)\n",
    "                        y = int(landmark.y * h)\n",
    "                        landmarks_data.append({\n",
    "                            'landmark_id': idx,\n",
    "                            'x': x,\n",
    "                            'y': y\n",
    "                        })\n",
    "                    \n",
    "                    # CSVファイルに保存\n",
    "                    import pandas as pd\n",
    "                    df = pd.DataFrame(landmarks_data)\n",
    "                    csv_path = os.path.join(saveDir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    print(f\"ランドマーク座標を保存しました: {csv_path}\")\n",
    "                else:\n",
    "                    print(f\"Warning: 顔のランドマークが検出されませんでした: {inputMoviePath}\")\n",
    "        else:\n",
    "            print(f\"Warning: ランドマークが検出されませんでした: {inputMoviePath}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: ランドマーク検出中にエラーが発生しました: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"=== {dataName} の処理完了 ===\\n\")\n",
    "\n",
    "    # ここにランドマークのidと座標を保存するコードを追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424f67",
   "metadata": {},
   "source": [
    "記録された座標を読み込み、各々のRGBを記録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe737fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analysis_df(video_path, roi_coordinates, fps):\n",
    "    \"\"\"\n",
    "    RGB + HSV + L*a*b*特徴量を含む画像品質解析を行う関数\n",
    "    \n",
    "    Args:\n",
    "        video_path: 動画ファイルのパス\n",
    "        roi_coordinates: ROI座標 (left, top, right, bottom)\n",
    "        fps: フレームレート\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 解析結果\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 結果を格納するリスト\n",
    "    results = {\n",
    "        'frame_number': [],\n",
    "        'timestamp': [],\n",
    "        'contrast': [],\n",
    "        'r_mean': [],\n",
    "        'g_mean': [],\n",
    "        'b_mean': [],\n",
    "        'r_std': [],\n",
    "        'g_std': [],\n",
    "        'b_std': [],\n",
    "        's_mean': [],\n",
    "        's_std': [],\n",
    "        'l_mean': [],\n",
    "        'l_std': [],\n",
    "    }\n",
    "    \n",
    "    frame_count = 0\n",
    "    roi_left, roi_top, roi_right, roi_bottom = roi_coordinates\n",
    "    \n",
    "    print(f\"動画解析開始: {video_path}\")\n",
    "    print(f\"ROI座標: ({roi_left}, {roi_top}, {roi_right}, {roi_bottom})\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # ROI領域を切り出し\n",
    "        roi_frame = frame[roi_top:roi_bottom, roi_left:roi_right]\n",
    "        \n",
    "        if roi_frame.size == 0:\n",
    "            continue\n",
    "            \n",
    "        # タイムスタンプ計算\n",
    "        timestamp = frame_count / fps\n",
    "        \n",
    "        # RGB解析\n",
    "        b_channel, g_channel, r_channel = cv2.split(roi_frame)\n",
    "        \n",
    "        r_mean = np.mean(r_channel)\n",
    "        g_mean = np.mean(g_channel)\n",
    "        b_mean = np.mean(b_channel)\n",
    "        \n",
    "        r_std = np.std(r_channel)\n",
    "        g_std = np.std(g_channel)\n",
    "        b_std = np.std(b_channel)\n",
    "        \n",
    "        # コントラスト計算（グレースケール）\n",
    "        gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "        contrast = np.std(gray_roi)\n",
    "        \n",
    "        # HSV解析\n",
    "        hsv_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2HSV)\n",
    "        h_channel, s_channel, v_channel = cv2.split(hsv_roi)\n",
    "        \n",
    "        s_mean = np.mean(s_channel)\n",
    "        s_std = np.std(s_channel)\n",
    "        \n",
    "        # L*a*b*解析\n",
    "        lab_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel_lab = cv2.split(lab_roi)\n",
    "        \n",
    "        l_mean = np.mean(l_channel)\n",
    "        l_std = np.std(l_channel)\n",
    "        \n",
    "        # 結果を保存\n",
    "        results['frame_number'].append(frame_count)\n",
    "        results['timestamp'].append(timestamp)\n",
    "        results['contrast'].append(contrast)\n",
    "        results['r_mean'].append(r_mean)\n",
    "        results['g_mean'].append(g_mean)\n",
    "        results['b_mean'].append(b_mean)\n",
    "        results['r_std'].append(r_std)\n",
    "        results['g_std'].append(g_std)\n",
    "        results['b_std'].append(b_std)\n",
    "        results['s_mean'].append(s_mean)\n",
    "        results['s_std'].append(s_std)\n",
    "        results['l_mean'].append(l_mean)\n",
    "        results['l_std'].append(l_std)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # 進捗表示\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"処理済みフレーム: {frame_count}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # DataFrameに変換\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"解析完了: {len(df)} フレーム処理\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_idx in range(len(movie_paths)):  # ★ 変数名を変更\n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    \n",
    "    print(f'Processing movie: {dataName}')  # ★ デバッグ用\n",
    "    \n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    savedir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    \n",
    "    # ROIの座標を取得\n",
    "    roi_coordinates_path = os.path.join(savedir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "    roi_df = pd.read_csv(roi_coordinates_path)\n",
    "    \n",
    "    # ★★★ 動画ごとにリストとDataFrameを初期化 ★★★\n",
    "    all_segments_data = []\n",
    "    all_segments_df = pd.DataFrame()\n",
    "    \n",
    "    # ROIごとにRGB、HSVを記録\n",
    "    for roi_idx, row in roi_df.iterrows():\n",
    "        landmark_id = int(row['landmark_id'])  # 整数に変換\n",
    "        center_x = int(row['x'])  # 整数に変換\n",
    "        center_y = int(row['y'])  # 整数に変換\n",
    "        \n",
    "        # パッチの座標を計算（中心座標から±PATCH_SIZE/2）\n",
    "        half_patch = PATCH_SIZE // 2\n",
    "        landmark_left = int(max(0, center_x - half_patch))\n",
    "        landmark_top = int(max(0, center_y - half_patch))\n",
    "        landmark_right = int(center_x + half_patch)\n",
    "        landmark_bottom = int(center_y + half_patch)\n",
    "        \n",
    "        roi = (landmark_left, landmark_top, landmark_right, landmark_bottom)\n",
    "        \n",
    "        print(f'  Processing landmark_id: {landmark_id} at ({center_x}, {center_y})')\n",
    "        \n",
    "        landmark_df = make_analysis_df(\n",
    "            video_path=inputMoviePath,\n",
    "            roi_coordinates=roi,\n",
    "            fps=fps\n",
    "        )\n",
    "        landmark_df[\"landmark_id\"] = landmark_id\n",
    "        print(f'  landmark {landmark_id} data shape: {landmark_df.shape}')\n",
    "        \n",
    "        # 動画のデータをリストに追加\n",
    "        all_segments_data.append(landmark_df)\n",
    "    \n",
    "    # 全てのランドマークのデータを統合\n",
    "    all_landmarks_df = pd.concat(all_segments_data, ignore_index=True)\n",
    "    print(f'Total data shape for {dataName}: {all_landmarks_df.shape}')\n",
    "    \n",
    "    # CSVとして保存\n",
    "    output_csv_path = os.path.join(rootDir, SAVE_DIR, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_data.csv\")\n",
    "    all_landmarks_df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Saved: {output_csv_path}')\n",
    "    \n",
    "    # === ROI可視化 ===\n",
    "    # 1フレーム目を読み込み\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    ret, first_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        vis_frame = first_frame.copy()\n",
    "        \n",
    "        # CSVから各ランドマークのROIを描画\n",
    "        for roi_idx, row in roi_df.iterrows():\n",
    "            landmark_id = int(row['landmark_id'])\n",
    "            center_x = int(row['x'])\n",
    "            center_y = int(row['y'])\n",
    "            \n",
    "            # パッチの座標を計算\n",
    "            half_patch = PATCH_SIZE // 2\n",
    "            left = int(max(0, center_x - half_patch))\n",
    "            top = int(max(0, center_y - half_patch))\n",
    "            right = int(center_x + half_patch)\n",
    "            bottom = int(center_y + half_patch)\n",
    "            \n",
    "            # ROIの矩形を描画（緑色）\n",
    "            cv2.rectangle(vis_frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # ランドマークIDを表示\n",
    "            cv2.putText(vis_frame, str(landmark_id), (center_x - 10, center_y - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            # 中心点を描画（赤色）\n",
    "            cv2.circle(vis_frame, (center_x, center_y), 3, (0, 0, 255), -1)\n",
    "        \n",
    "        # 可視化画像を保存\n",
    "        vis_output_path = os.path.join(savedir, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_visualization.png\")\n",
    "        cv2.imwrite(vis_output_path, vis_frame)\n",
    "        print(f'ROI可視化画像を保存: {vis_output_path}\\n')\n",
    "    else:\n",
    "        print(f'Error: フレームの読み込みに失敗しました\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe90449",
   "metadata": {},
   "source": [
    "各窓にRGB信号を格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933183b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZES = [2, 4, 6, 8, 10]\n",
    "STRIDES = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_full_string(arr):\n",
    "    \"\"\"NumPy配列を省略なしの文字列に変換\"\"\"\n",
    "    if isinstance(arr, str):\n",
    "        return arr\n",
    "    elif isinstance(arr, (np.ndarray, list)):\n",
    "        # NumPy配列またはリストを完全な文字列に変換\n",
    "        arr_np = np.array(arr)\n",
    "        return np.array2string(arr_np, threshold=np.inf, max_line_width=np.inf, separator=' ')\n",
    "    else:\n",
    "        return str(arr)\n",
    "\n",
    "class StrideSegmentCalculator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_sizes: List[float] = [2, 3, 4, 5],\n",
    "        strides: List[float] = [0.1, 0.5, 1, 1.5, 2],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_sizes : List[float]\n",
    "            窓幅（秒）のリスト\n",
    "        strides : List[float]\n",
    "            移動秒数のリスト\n",
    "        \"\"\"\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "    def calculate_overlap(self, window_size: float, stride: float) -> float:\n",
    "        \"\"\"\n",
    "        窓幅と移動秒数からオーバーラップ率を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            オーバーラップ率（%）\n",
    "        \"\"\"\n",
    "        if stride >= window_size:\n",
    "            return 0\n",
    "        overlap = (window_size - stride) / window_size * 100\n",
    "        return round(overlap, 2)\n",
    "\n",
    "    def calculate_segments(\n",
    "        self, window_size: float, stride: float, total_frames: int, fps: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        フレーム数から解析区間を計算\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        stride : float\n",
    "            移動秒数（秒）\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple[int, int]]\n",
    "            各区間の(開始フレーム, 終了フレーム)のリスト\n",
    "        \"\"\"\n",
    "        frames_per_window = round(window_size * fps)\n",
    "        frames_per_stride = round(stride * fps)\n",
    "\n",
    "        segments = []\n",
    "        start_frame = 0\n",
    "\n",
    "        while start_frame + frames_per_window <= total_frames:\n",
    "            segments.append((start_frame, start_frame + frames_per_window))\n",
    "            start_frame += frames_per_stride\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def create_analysis_dataframe(self, total_frames: int, fps: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        全ての窓幅と移動秒数の組み合わせに対してDataFrameを生成\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        total_frames : int\n",
    "            総フレーム数\n",
    "        fps : int\n",
    "            フレームレート\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            各条件でのセグメント情報を含むDataFrame\n",
    "            columns: window_size, stride, overlap, segment_number, frame_start, frame_end\n",
    "        \"\"\"\n",
    "        data_dict = {\n",
    "            \"window_size\": [],\n",
    "            \"stride\": [],\n",
    "            \"overlap\": [],\n",
    "            \"segment_number\": [],\n",
    "            \"frame_start\": [],\n",
    "            \"frame_end\": [],\n",
    "        }\n",
    "\n",
    "        for window_size in self.window_sizes:\n",
    "            for stride in self.strides:\n",
    "                overlap = self.calculate_overlap(window_size, stride)\n",
    "                segments = self.calculate_segments(\n",
    "                    window_size, stride, total_frames, fps\n",
    "                )\n",
    "\n",
    "                for i, (start_frame, end_frame) in enumerate(segments):\n",
    "                    data_dict[\"window_size\"].append(window_size)\n",
    "                    data_dict[\"stride\"].append(stride)\n",
    "                    data_dict[\"overlap\"].append(overlap)\n",
    "                    data_dict[\"segment_number\"].append(i)\n",
    "                    data_dict[\"frame_start\"].append(start_frame)\n",
    "                    data_dict[\"frame_end\"].append(end_frame)\n",
    "\n",
    "        return pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "class PulseAnalysisDataStrides:\n",
    "    def __init__(self, window_sizes, strides):\n",
    "        # 窓枠とストライドの値を定義\n",
    "        self.window_sizes = window_sizes\n",
    "        self.strides = strides\n",
    "\n",
    "        # accuracyのみを格納するDataFrameを初期化\n",
    "        self.results = pd.DataFrame(\n",
    "            index=pd.Index(self.window_sizes, name=\"window_size\"),\n",
    "            columns=pd.Index(self.strides, name=\"strides\"),\n",
    "        )\n",
    "\n",
    "    def add_accuracy(self, window_size: float, strides: int, accuracy: float):\n",
    "        \"\"\"\n",
    "        精度データを追加する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        window_size : float\n",
    "            窓幅（秒）\n",
    "        strides : int\n",
    "            ストライド（s）\n",
    "        accuracy : float\n",
    "            精度値\n",
    "        \"\"\"\n",
    "        self.results.loc[window_size, strides] = accuracy\n",
    "\n",
    "    def _create_heatmap_dataframe(self):\n",
    "        \"\"\"\n",
    "        ヒートマップ用のDataFrameを作成する内部メソッド\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            ヒートマップ用に整形されたDataFrame\n",
    "        \"\"\"\n",
    "        data = {\"stride\": self.strides}\n",
    "        for window_size in self.window_sizes:\n",
    "            data[window_size] = [\n",
    "                self.results.loc[window_size, stride] for stride in self.strides\n",
    "            ]\n",
    "        df = pd.DataFrame(data).set_index(\"stride\").T\n",
    "        return df\n",
    "\n",
    "    def save_heatmap(\n",
    "        self,\n",
    "        title: str,\n",
    "        save_path: str,\n",
    "        figsize: tuple = (10, 8),\n",
    "        cmap: str = \"YlGnBu\",\n",
    "        colorbar_label: str = \"MAE\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        cmap : str, optional\n",
    "            カラーマップ (default: 'YlGnBu')\n",
    "        colorbar_label : str, optional\n",
    "            カラーバーのラベル (default: 'MAE')\n",
    "        \"\"\"\n",
    "        df = self._create_heatmap_dataframe()\n",
    "\n",
    "        # ヒートマップを作成\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(\n",
    "            df, annot=True, fmt=\".4f\", cmap=cmap, cbar_kws={\"label\": colorbar_label}\n",
    "        )\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.xlabel(\"Stride [s]\")\n",
    "        plt.ylabel(\"Window Size [s]\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def save_heatmap_std(self, title: str, save_path: str, figsize: tuple = (10, 8)):\n",
    "        \"\"\"\n",
    "        標準偏差のヒートマップを作成して保存する\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title : str\n",
    "            プロットのタイトル\n",
    "        save_path : str\n",
    "            保存先のパス\n",
    "        figsize : tuple, optional\n",
    "            図のサイズ (default: (10, 8))\n",
    "        \"\"\"\n",
    "        self.save_heatmap(\n",
    "            title,\n",
    "            save_path,\n",
    "            figsize,\n",
    "            cmap=\"Reds\",\n",
    "            colorbar_label=\"Standard Deviation\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "    \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    landmark_data_path = os.path.join(rootDir, SAVE_DIR, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_data.csv\")\n",
    "    landmark_data_df = pd.read_csv(landmark_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in landmark_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = landmark_data_df[landmark_data_df['landmark_id'] == landmark_id]\n",
    "            print(f'    landmark data shape: {landmark_df}')\n",
    "            \n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = (landmark_df['timestamp'] >= window_start_time) & (landmark_df['timestamp'] < window_end_time)\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_mean'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_mean'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_mean'].values\n",
    "\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['s_mean'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['l_mean'].values\n",
    "\n",
    "            # 窓情報を保存\n",
    "            window_info = {\n",
    "                'landmark_id': landmark_id,\n",
    "                'window_index': idx,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'saturation_signal_in_window': array_to_full_string(saturation_signal_in_window),\n",
    "                'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window)\n",
    "            }\n",
    "            all_window_results.append(window_info)\n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8614501",
   "metadata": {},
   "source": [
    "### 窓ごとにBVPとMAEを算出し、保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_BVPsignal(r_signals, g_signals, b_signals,  fps, deviceType, bvpMethod, bvpMethodName, method_params=None):\n",
    "    \"\"\"\n",
    "    RGB信号からBVP信号を抽出する関数\n",
    "    \"\"\"\n",
    "    rgb_signal = np.array([[r_signals, g_signals, b_signals]], dtype=np.float32)\n",
    "    print(f\"\\nRGB信号の形状: {rgb_signal.shape}\")\n",
    "    \n",
    "    signal_length = rgb_signal.shape[2]\n",
    "    min_required_length = 50\n",
    "    \n",
    "    if signal_length < min_required_length:\n",
    "        print(f\"警告: 信号長が短すぎます ({signal_length} < {min_required_length})。処理をスキップします。\")\n",
    "        return None, None\n",
    "    \n",
    "    filtered_signal = [rgb_signal]\n",
    "    \n",
    "    # デフォルトのメソッドパラメータ\n",
    "    if method_params is None:\n",
    "        method_params = {}\n",
    "    \n",
    "    # メソッド別パラメータ設定\n",
    "    if bvpMethodName in [\"cupy_POS\", \"cpu_POS\"]:\n",
    "        method_params['fps'] = fps\n",
    "    elif bvpMethodName in [\"cpu_ICA\", \"cpu_PCA\"]:\n",
    "        method_params['component'] = 'all_comp'\n",
    "    \n",
    "    print(f\"\\nBVP抽出開始 (メソッド: {bvpMethodName})\")\n",
    "    print(f\"パラメータ: {method_params}\")\n",
    "    \n",
    "    # BVP信号抽出\n",
    "    if method_params:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod,\n",
    "            params=method_params\n",
    "        )\n",
    "    else:\n",
    "        bvp_signal = vhr.BVP.RGB_sig_to_BVP(\n",
    "            filtered_signal,\n",
    "            fps,\n",
    "            device_type=deviceType,\n",
    "            method=bvpMethod\n",
    "        )\n",
    "    \n",
    "    # 生のBVP信号を保存\n",
    "    raw_bvp_signal = bvp_signal[0].copy() if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    # 後処理フィルタリング\n",
    "    bvp_signal = vhr.BVP.apply_filter(\n",
    "        bvp_signal,\n",
    "        vhr.BVP.BPfilter,\n",
    "        params={'order': 6, 'minHz': 0.5, 'maxHz': 2.0, 'fps': fps}\n",
    "    )\n",
    "    \n",
    "    bvp_signal = vhr.BVP.apply_filter(bvp_signal, vhr.BVP.zeromean)\n",
    "    \n",
    "    filtered_bvp_signal = bvp_signal[0] if len(bvp_signal) > 0 else None\n",
    "    \n",
    "    print(f\"\\nBVP信号抽出完了\")\n",
    "    return raw_bvp_signal, filtered_bvp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_window_fft(values, fps):\n",
    "    \"\"\"\n",
    "    時系列データの最大周波数とスペクトル情報を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        分析対象の時系列データ\n",
    "    fps : int\n",
    "        サンプリング周波数（1秒あたりのフレーム数）\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        以下のキーを含む辞書：\n",
    "        - 'max_freq': 検出された最大周波数\n",
    "        - 'max_amplitude': 最大周波数のときの振幅\n",
    "        - 'frequencies': 周波数配列（正の周波数のみ）\n",
    "        - 'amplitudes': 振幅配列（正の周波数のみ）\n",
    "        - 'power_spectrum': パワースペクトル\n",
    "        - 'dominant_freqs': 上位5つの卓越周波数とその振幅\n",
    "        - 'spectral_centroid': スペクトル重心\n",
    "        - 'spectral_bandwidth': スペクトル帯域幅\n",
    "        - 'total_power': 全体のパワー\n",
    "    \"\"\"\n",
    "    # データをnumpy配列に変換\n",
    "    values = np.array(values)\n",
    "\n",
    "    # ゼロパディングで分解能を向上（窓長の8倍）\n",
    "    n_pad = len(values) * 8\n",
    "\n",
    "    # ハミング窓を適用（オプション：コメントアウトされている）\n",
    "    # window = np.hamming(len(values))\n",
    "    # windowed_data = values * window\n",
    "\n",
    "    # FFTを実行（ゼロパディング適用）\n",
    "    fft_result = np.fft.fft(values, n=n_pad)\n",
    "    fft_freq = np.fft.fftfreq(n_pad, 1 / fps)\n",
    "\n",
    "    # 正の周波数のみを取得\n",
    "    positive_freq_idx = fft_freq > 0\n",
    "    positive_fft = np.abs(fft_result[positive_freq_idx])\n",
    "    positive_freq = fft_freq[positive_freq_idx]\n",
    "    \n",
    "    # パワースペクトルを計算\n",
    "    power_spectrum = positive_fft ** 2\n",
    "\n",
    "    # 最大周波数の検出と補間\n",
    "    max_idx = np.argmax(positive_fft)\n",
    "    max_amplitude = positive_fft[max_idx]\n",
    "    \n",
    "    if 0 < max_idx < len(positive_fft) - 1:\n",
    "        # 3点を使用した放物線補間\n",
    "        alpha = positive_fft[max_idx - 1]\n",
    "        beta = positive_fft[max_idx]\n",
    "        gamma = positive_fft[max_idx + 1]\n",
    "        peak_pos = 0.5 * (alpha - gamma) / (alpha - 2 * beta + gamma)\n",
    "\n",
    "        # 補間された周波数と振幅\n",
    "        freq_resolution = fps / n_pad\n",
    "        max_freq = positive_freq[max_idx] + peak_pos * freq_resolution\n",
    "        \n",
    "        # 補間された振幅（放物線の頂点）\n",
    "        max_amplitude = beta - 0.25 * (alpha - gamma) * peak_pos\n",
    "    else:\n",
    "        max_freq = positive_freq[max_idx]\n",
    "    \n",
    "    # 上位5つの卓越周波数を検出\n",
    "    top_indices = np.argsort(positive_fft)[-5:][::-1]\n",
    "    dominant_freqs = [(positive_freq[idx], positive_fft[idx]) for idx in top_indices]\n",
    "    \n",
    "    # スペクトル特徴量の計算\n",
    "    # スペクトル重心（周波数の重み付き平均）\n",
    "    spectral_centroid = np.sum(positive_freq * positive_fft) / np.sum(positive_fft)\n",
    "    \n",
    "    # スペクトル帯域幅（重心からの重み付き分散）\n",
    "    spectral_bandwidth = np.sqrt(\n",
    "        np.sum(((positive_freq - spectral_centroid) ** 2) * positive_fft) / np.sum(positive_fft)\n",
    "    )\n",
    "    \n",
    "    # 全体のパワー\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    \n",
    "    # 結果を辞書にまとめる\n",
    "    result = {\n",
    "        'max_freq': max_freq,\n",
    "        'max_amplitude': max_amplitude,\n",
    "        'frequencies': positive_freq,\n",
    "        'amplitudes': positive_fft,\n",
    "        'power_spectrum': power_spectrum,\n",
    "        'dominant_freqs': dominant_freqs,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'total_power': total_power,\n",
    "        'freq_resolution': fps / n_pad,  # 周波数分解能\n",
    "        'nyquist_freq': fps / 2  # ナイキスト周波数\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e81a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[i]\n",
    "    rootDir = data_dirs[i]\n",
    "    dataName = movie_names[i]\n",
    "\n",
    "    print(f'Processing movie: {inputMoviePath}')\n",
    "\n",
    "    # 動画のfpsを取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    samplingRate = fps\n",
    "    cap.release()\n",
    "\n",
    "    save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(save_dir, exist_ok=True)        \n",
    "\n",
    "    # CSVファイルの読み込み\n",
    "    ecg_csv_path = os.path.join(rootDir, dataName + '.csv')\n",
    "    ecg_df = pd.read_csv(ecg_csv_path)\n",
    "\n",
    "    ecg_RRI_csv_path = os.path.join(rootDir, f'RRI_Simple_{movie_names[i]}.csv')\n",
    "    ecg_RRI_df = pd.read_csv(ecg_RRI_csv_path)\n",
    "\n",
    "    # landmarkで共通のecg_bpm_in_window_meanを取得\n",
    "    ecg_bpm_in_window = ecg_RRI_df['BPM']\n",
    "    ecg_bpm_in_window_mean = ecg_RRI_df['BPM'].values.mean()\n",
    "\n",
    "    # ROIデータの読み込み\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    window_signals_data_path = os.path.join(rootDir, SAVE_DIR, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_ROI_window_signals.csv')\n",
    "    window_signals_data_df = pd.read_csv(window_signals_data_path)\n",
    "\n",
    "    stride_segment_calculator = StrideSegmentCalculator(window_sizes=WINDOW_SIZES, strides=STRIDES)\n",
    "    analysis_df = stride_segment_calculator.create_analysis_dataframe(total_frames, fps)\n",
    "\n",
    "    # ランドマークごとに実行\n",
    "    # 結果を格納するリスト\n",
    "    all_window_results = []\n",
    "    for idx, row in analysis_df.iterrows():\n",
    "        window_size = row['window_size']\n",
    "        frame_start = row['frame_start']\n",
    "        frame_end = row['frame_end']\n",
    "        stride = row['stride']\n",
    "\n",
    "        # 窓の時間範囲を計算\n",
    "        window_start_time = frame_start / fps\n",
    "        window_end_time = frame_end / fps\n",
    "\n",
    "        if(window_end_time > total_frames / fps):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nウィンドウ {idx}: 窓サイズ {window_size}s, ストライド {stride}s, フレーム {frame_start}-{frame_end}, 時間 {window_start_time:.2f}-{window_end_time:.2f}s\")\n",
    "\n",
    "        # 該当する窓の時間範囲内の真値RRIデータを抽出\n",
    "        ecg_RRI_mask = (ecg_RRI_df['time'] >= window_start_time) & \\\n",
    "                (ecg_RRI_df['time'] < window_end_time)\n",
    "        ecg_bpm_in_window = ecg_RRI_df[ecg_RRI_mask]['BPM'].values\n",
    "        ecg_bpm_in_window_mean = np.mean(ecg_bpm_in_window) if len(ecg_bpm_in_window) > 0 else np.nan\n",
    "        print(f'    True Value RRI count in window: {len(ecg_bpm_in_window)}, Mean BPM: {ecg_bpm_in_window_mean:.2f}')\n",
    "        \n",
    "        for landmark_id in window_signals_data_df['landmark_id'].unique():\n",
    "            print(f'  Analyzing landmark_id: {landmark_id}')\n",
    "            landmark_df = window_signals_data_df[window_signals_data_df['landmark_id'] == landmark_id]\n",
    "\n",
    "            # 該当する窓の時間範囲内のRGB信号を抽出し、窓内でBVP算出\n",
    "            bvp_mask = landmark_df['window_index'] == idx\n",
    "\n",
    "            r_signal_in_window = landmark_df[bvp_mask]['r_signal_in_window'].values\n",
    "            g_signal_in_window = landmark_df[bvp_mask]['g_signal_in_window'].values\n",
    "            b_signal_in_window = landmark_df[bvp_mask]['b_signal_in_window'].values\n",
    "            saturation_signal_in_window = landmark_df[bvp_mask]['saturation_signal_in_window'].values\n",
    "            lightness_signal_in_window = landmark_df[bvp_mask]['lightness_signal_in_window'].values\n",
    "\n",
    "            # 文字列をNumPy配列に変換\n",
    "            r_signal_in_window = np.fromstring(r_signal_in_window[0].strip('[]'), sep=' ') if len(r_signal_in_window) > 0 else np.array([])\n",
    "            g_signal_in_window = np.fromstring(g_signal_in_window[0].strip('[]'), sep=' ') if len(g_signal_in_window) > 0 else np.array([])\n",
    "            b_signal_in_window = np.fromstring(b_signal_in_window[0].strip('[]'), sep=' ') if len(b_signal_in_window) > 0 else np.array([])\n",
    "            saturation_signal_in_window = np.fromstring(saturation_signal_in_window[0].strip('[]'), sep=' ') if len(saturation_signal_in_window) > 0 else np.array([])\n",
    "            lightness_signal_in_window = np.fromstring(lightness_signal_in_window[0].strip('[]'), sep=' ') if len(lightness_signal_in_window) > 0 else np.array([])\n",
    "\n",
    "            print(f'    RGB信号の長さ: R={len(r_signal_in_window)}, G={len(g_signal_in_window)}, B={len(b_signal_in_window)}')\n",
    "\n",
    "            # BVPメソッドの設定\n",
    "            methodCombinations =  ['cuda', cupy_POS, \"cupy_POS\"]\n",
    "            deviceType = methodCombinations[0]  # 'cuda'\n",
    "            bvpMethod = methodCombinations[1]   # cupy_POS\n",
    "            bvpMethodName = methodCombinations[2]  # \"cupy_POS\"\n",
    "\n",
    "            # rgbからBVPを計算\n",
    "            raw_bvp_signal_in_window, filtered_bvp_signal_in_window = extract_BVPsignal(\n",
    "                r_signal_in_window,\n",
    "                g_signal_in_window,\n",
    "                b_signal_in_window,\n",
    "                fps,\n",
    "                deviceType,\n",
    "                bvpMethod,\n",
    "                bvpMethodName\n",
    "            )\n",
    "            \n",
    "            # BVP信号の抽出に失敗した場合はスキップ\n",
    "            if filtered_bvp_signal_in_window is None:\n",
    "                print(f\"ウィンドウ {idx} をスキップ: BVP信号の抽出に失敗\")\n",
    "                continue\n",
    "            \n",
    "            # FFT解析\n",
    "            raw_bvp_signal_in_window = raw_bvp_signal_in_window.flatten() if raw_bvp_signal_in_window is not None else None\n",
    "            filtered_bvp_signal_in_window = filtered_bvp_signal_in_window.flatten()\n",
    "            fft_result_dic = analyze_window_fft(filtered_bvp_signal_in_window, fps)\n",
    "\n",
    "            # MAEの計算\n",
    "            rppg_bpm = fft_result_dic['max_freq'] * 60\n",
    "            rppg_freq = fft_result_dic['frequencies']\n",
    "            rppg_amplitude = fft_result_dic['amplitudes']\n",
    "            rppg_pwd = fft_result_dic['power_spectrum']\n",
    "\n",
    "            bpm_MAE = np.abs(ecg_bpm_in_window_mean - rppg_bpm) if not np.isnan(ecg_bpm_in_window_mean) else np.nan\n",
    "\n",
    "            # 窓情報を保存\n",
    "            window_info = {\n",
    "                'landmark_id': landmark_id,\n",
    "                'window_index': idx,\n",
    "                'window_size': window_size,\n",
    "                'stride': stride,\n",
    "                'frame_start': frame_start,\n",
    "                'frame_end': frame_end,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'r_signal_in_window': array_to_full_string(r_signal_in_window),\n",
    "                'g_signal_in_window': array_to_full_string(g_signal_in_window),\n",
    "                'b_signal_in_window': array_to_full_string(b_signal_in_window),\n",
    "                'saturation_signal_in_window': array_to_full_string(saturation_signal_in_window),\n",
    "                'lightness_signal_in_window': array_to_full_string(lightness_signal_in_window),\n",
    "                'raw_bvp_in_window': raw_bvp_signal_in_window,\n",
    "                'filtered_bvp_in_window': filtered_bvp_signal_in_window,\n",
    "                'ecg_bpm_in_window': ecg_bpm_in_window,\n",
    "                'ecg_bpm_mean': ecg_bpm_in_window_mean,\n",
    "                'rppg_bpm': rppg_bpm,\n",
    "                'bpm_MAE': bpm_MAE,\n",
    "                'max_freq': fft_result_dic['max_freq'],\n",
    "                'max_amplitude': fft_result_dic['max_amplitude'],\n",
    "                'spectral_centroid': fft_result_dic['spectral_centroid'],\n",
    "                'spectral_bandwidth': fft_result_dic['spectral_bandwidth'],\n",
    "                'total_power': fft_result_dic['total_power']\n",
    "            }\n",
    "            all_window_results.append(window_info)\n",
    "    # 全結果をDataFrameに変換して保存\n",
    "    results_df = pd.DataFrame(all_window_results)\n",
    "    results_save_dir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(results_save_dir, exist_ok=True)\n",
    "    results_csv_path = os.path.join(results_save_dir, f'{dataName}_window_analysis_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nFFT結果をCSVに保存: {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c49da",
   "metadata": {},
   "source": [
    "### 記録した座標を読み込み、指標を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83406faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skin_angle(r_signal, g_signal, b_signal):\n",
    "    \"\"\"\n",
    "    皮膚色角度を計算（標準肌色調ベクトルとの角度）\n",
    "    \n",
    "    Args:\n",
    "        r_signal: (N,) 赤チャンネル信号\n",
    "        g_signal: (N,) 緑チャンネル信号\n",
    "        b_signal: (N,) 青チャンネル信号\n",
    "    \n",
    "    Returns:\n",
    "        angle: float 標準肌色調ベクトル [0.7682, 0.5121, 0.3841] との角度（度）\n",
    "    \"\"\"\n",
    "    eps = 1e-9  # ゼロ除算対策\n",
    "    \n",
    "    # RGB統計量（時間平均）\n",
    "    r_mean = np.mean(r_signal)\n",
    "    g_mean = np.mean(g_signal)\n",
    "    b_mean = np.mean(b_signal)\n",
    "    \n",
    "    # RGB正規化（単位ベクトル化）\n",
    "    norm = np.sqrt(r_mean**2 + g_mean**2 + b_mean**2)\n",
    "    \n",
    "    # ゼロ除算チェック\n",
    "    if norm < eps:\n",
    "        print(\"警告: RGB平均値がほぼゼロです。角度を計算できません。\")\n",
    "        return np.nan\n",
    "    \n",
    "    skin_vector = np.array([r_mean, g_mean, b_mean]) / norm\n",
    "    \n",
    "    # 標準化肌ベクトル [0.7682, 0.5121, 0.3841]との角度計算\n",
    "    reference_vector = np.array([0.7682, 0.5121, 0.3841])\n",
    "    \n",
    "    # コサイン類似度（範囲を[-1, 1]にクリップ）\n",
    "    cosine_similarity = np.dot(skin_vector, reference_vector)\n",
    "    cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)\n",
    "    \n",
    "    # 角度計算（度数法）\n",
    "    angle = np.degrees(np.arccos(cosine_similarity))\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_idx in range(len(movie_paths)):  \n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    \n",
    "    print(f'Processing movie: {dataName}')  \n",
    "    \n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    savedir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    \n",
    "    # ROIの座標を取得\n",
    "    roi_coordinates_path = os.path.join(savedir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "    roi_df = pd.read_csv(roi_coordinates_path)\n",
    "    \n",
    "    # ★★★ 動画ごとにリストとDataFrameを初期化 ★★★\n",
    "    all_segments_data = []\n",
    "    all_segments_df = pd.DataFrame()\n",
    "    \n",
    "    # ROIごとにRGB、HSVを記録\n",
    "    for roi_idx, row in roi_df.iterrows():\n",
    "        landmark_id = int(row['landmark_id'])\n",
    "        center_x = int(row['x'])\n",
    "        center_y = int(row['y'])\n",
    "        \n",
    "        # パッチの座標を計算\n",
    "        half_patch = PATCH_SIZE // 2\n",
    "        landmark_left = int(max(0, center_x - half_patch))\n",
    "        landmark_top = int(max(0, center_y - half_patch))\n",
    "        landmark_right = int(center_x + half_patch)\n",
    "        landmark_bottom = int(center_y + half_patch)\n",
    "        \n",
    "        roi = (landmark_left, landmark_top, landmark_right, landmark_bottom)\n",
    "        \n",
    "        print(f'  Processing landmark_id: {landmark_id} at ({center_x}, {center_y})')\n",
    "        \n",
    "        # ★★★ リストに辞書を追加していく方法に変更 ★★★\n",
    "        landmark_data_list = []\n",
    "        cap = cv2.VideoCapture(inputMoviePath)\n",
    "        frame_number = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            timestamp = frame_number / fps\n",
    "            \n",
    "            # パッチ領域を抽出\n",
    "            patch = frame[landmark_top:landmark_bottom, landmark_left:landmark_right]\n",
    "            \n",
    "            # RGB平均値を計算\n",
    "            r_mean = np.mean(patch[:, :, 2])\n",
    "            g_mean = np.mean(patch[:, :, 1])\n",
    "            b_mean = np.mean(patch[:, :, 0])\n",
    "\n",
    "            # 皮膚色角度を計算\n",
    "            skin_angle = calculate_skin_angle(\n",
    "                np.array([r_mean]),\n",
    "                np.array([g_mean]),\n",
    "                np.array([b_mean])\n",
    "            )\n",
    "            \n",
    "            # データを辞書としてリストに追加\n",
    "            landmark_data_list.append({\n",
    "                'frame_number': frame_number,\n",
    "                'timestamp': timestamp,\n",
    "                'r_mean': r_mean,\n",
    "                'g_mean': g_mean,\n",
    "                'b_mean': b_mean,\n",
    "                'angle': skin_angle,\n",
    "                'landmark_id': landmark_id\n",
    "            })\n",
    "            \n",
    "            frame_number += 1\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # リストからDataFrameを作成\n",
    "        landmark_df = pd.DataFrame(landmark_data_list)\n",
    "        \n",
    "        print(f'  landmark {landmark_id} data shape: {landmark_df.shape}')\n",
    "        \n",
    "        # 動画のデータをリストに追加\n",
    "        all_segments_data.append(landmark_df)\n",
    "    \n",
    "    # 全てのランドマークのデータを統合\n",
    "    all_landmarks_df = pd.concat(all_segments_data, ignore_index=True)\n",
    "    print(f'Total data shape for {dataName}: {all_landmarks_df.shape}')\n",
    "    \n",
    "    # CSVとして保存\n",
    "    output_csv_path = os.path.join(rootDir, SAVE_DIR, f\"{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_angles_data.csv\")\n",
    "    all_landmarks_df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Saved: {output_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d9ba6",
   "metadata": {},
   "source": [
    "### 窓ごとにマスクを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qfgohhbkw8g",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "SPLIT_TIME = 90  # 秒\n",
    "use_feature_names = ['angle']\n",
    "\n",
    "for movie_idx in range(len(movie_paths)):\n",
    "    inputMoviePath = movie_paths[movie_idx]\n",
    "    rootDir = data_dirs[movie_idx]\n",
    "    dataName = movie_names[movie_idx]\n",
    "    \n",
    "    print(f'\\n{\"=\"*80}')\n",
    "    print(f'ランドマークごとのマスク作成開始: {dataName}')\n",
    "    print(f'{\"=\"*80}')\n",
    "    \n",
    "    # 動画情報取得\n",
    "    cap = cv2.VideoCapture(inputMoviePath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # 1フレーム目を読み込み\n",
    "    ret, first_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: 最初のフレームを読み込めませんでした: {inputMoviePath}\")\n",
    "        continue\n",
    "    \n",
    "    savedir = os.path.join(rootDir, SAVE_DIR)\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    \n",
    "    # ランドマーク座標を読み込み\n",
    "    roi_coordinates_path = os.path.join(savedir, f\"{dataName}_landmarks_coordinates.csv\")\n",
    "    if not os.path.exists(roi_coordinates_path):\n",
    "        print(f\"警告: {roi_coordinates_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "    \n",
    "    roi_df = pd.read_csv(roi_coordinates_path)\n",
    "    landmark_ids = roi_df['landmark_id'].unique()\n",
    "    \n",
    "    # window_analysis (MAEを含む)のCSVを読み込み\n",
    "    window_analysis_csv_path = os.path.join(savedir, f'{dataName}_window_analysis_{PATCH_SIZE}x{PATCH_SIZE}.csv')\n",
    "    \n",
    "    if not os.path.exists(window_analysis_csv_path):\n",
    "        print(f\"警告: {window_analysis_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    window_analysis_dataframe = pd.read_csv(window_analysis_csv_path)\n",
    "    \n",
    "    # angles_data CSVを読み込み\n",
    "    angles_csv_path = os.path.join(savedir, f'{dataName}_{PATCH_SIZE}x{PATCH_SIZE}_landmarks_angles_data.csv')\n",
    "    \n",
    "    if not os.path.exists(angles_csv_path):\n",
    "        print(f\"警告: {angles_csv_path} が見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    print(f\"角度データを読み込み中: {angles_csv_path}\")\n",
    "    angles_df = pd.read_csv(angles_csv_path)\n",
    "    \n",
    "    # ランドマークごとに処理\n",
    "    all_landmark_masks = []\n",
    "    all_window_mask_results = []\n",
    "    \n",
    "    for landmark_id in landmark_ids:\n",
    "        print(f'\\n{\"─\"*60}')\n",
    "        print(f'ランドマーク: {landmark_id}')\n",
    "        print(f'{\"─\"*60}')\n",
    "        \n",
    "        # このランドマークのデータを抽出\n",
    "        landmark_data = angles_df[angles_df['landmark_id'] == landmark_id].copy()\n",
    "        \n",
    "        if len(landmark_data) == 0:\n",
    "            print(f\"  警告: {landmark_id} のデータがありません。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        # 前半90秒のデータで閾値を作成\n",
    "        print(f\"  前半{SPLIT_TIME}秒のデータから閾値を計算中...\")\n",
    "        first_half_mask = landmark_data['timestamp'] <= SPLIT_TIME\n",
    "        first_half_data = landmark_data[first_half_mask]\n",
    "        \n",
    "        if len(first_half_data) == 0:\n",
    "            print(f\"  警告: {landmark_id} の前半データがありません。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        # 平均と標準偏差を計算\n",
    "        threshold_value = first_half_data['angle'].mean()\n",
    "        std_value = first_half_data['angle'].std()\n",
    "        lower_threshold = threshold_value - 2 * std_value\n",
    "        upper_threshold = threshold_value + 2 * std_value\n",
    "        \n",
    "        print(f\"  計算された閾値:\")\n",
    "        print(f\"    平均: {threshold_value:.4f}\")\n",
    "        print(f\"    標準偏差: {std_value:.4f}\")\n",
    "        print(f\"    閾値範囲: {lower_threshold:.4f} ~ {upper_threshold:.4f}\")\n",
    "        \n",
    "        # 全フレームに対してマスクを作成\n",
    "        print(\"  全フレームのマスクを作成中...\")\n",
    "        angle_values = landmark_data['angle'].values\n",
    "        \n",
    "        # 閾値内なら1、閾値外なら0\n",
    "        mask = ((angle_values >= lower_threshold) & \n",
    "                (angle_values <= upper_threshold)).astype(int)\n",
    "        \n",
    "        # 統計情報を表示\n",
    "        valid_ratio = mask.sum() / len(mask) * 100\n",
    "        print(f\"    有効フレーム: {mask.sum()}/{len(mask)} ({valid_ratio:.2f}%)\")\n",
    "        \n",
    "        # マスク結果を保存用にDataFrameに追加\n",
    "        mask_dict = {\n",
    "            'frame_number': landmark_data['frame_number'].values,\n",
    "            'timestamp': landmark_data['timestamp'].values,\n",
    "            'landmark_id': landmark_id,\n",
    "            'angle': angle_values,\n",
    "            'angle_mask': mask,\n",
    "            'threshold_mean': threshold_value,\n",
    "            'threshold_std': std_value,\n",
    "            'threshold_lower': lower_threshold,\n",
    "            'threshold_upper': upper_threshold\n",
    "        }\n",
    "        \n",
    "        landmark_mask_df = pd.DataFrame(mask_dict)\n",
    "        all_landmark_masks.append(landmark_mask_df)\n",
    "        \n",
    "        # 窓ごとのマスク適用結果を作成\n",
    "        print(\"  窓ごとのマスク適用結果を作成中...\")\n",
    "        landmark_window_data = window_analysis_dataframe[\n",
    "            window_analysis_dataframe['landmark_id'] == landmark_id\n",
    "        ].copy()\n",
    "        \n",
    "        for window_idx, row in landmark_window_data.iterrows():\n",
    "            window_index = row['window_index']\n",
    "            window_start_time = row['window_start_time']\n",
    "            window_end_time = row['window_end_time']\n",
    "            \n",
    "            # この窓に対応するフレームを抽出\n",
    "            window_frame_mask = ((landmark_data['timestamp'] >= window_start_time) & \n",
    "                                (landmark_data['timestamp'] < window_end_time))\n",
    "            \n",
    "            window_angles = landmark_data.loc[window_frame_mask, 'angle'].values\n",
    "            feature_mask = mask[window_frame_mask]\n",
    "            \n",
    "            if len(feature_mask) > 0:\n",
    "                valid_count = feature_mask.sum()\n",
    "                total_count = len(feature_mask)\n",
    "                valid_ratio = valid_count / total_count\n",
    "                all_valid = int(valid_count == total_count)\n",
    "            else:\n",
    "                valid_count = 0\n",
    "                total_count = 0\n",
    "                valid_ratio = 0.0\n",
    "                all_valid = 0\n",
    "            \n",
    "            window_result = {\n",
    "                'window_index': window_index,\n",
    "                'window_start_time': window_start_time,\n",
    "                'window_end_time': window_end_time,\n",
    "                'landmark_id': landmark_id,\n",
    "                'angle_valid_count': valid_count,\n",
    "                'angle_total_count': total_count,\n",
    "                'angle_valid_ratio': valid_ratio,\n",
    "                'angle_all_valid': all_valid\n",
    "            }\n",
    "            \n",
    "            all_window_mask_results.append(window_result)\n",
    "        \n",
    "        # 統計情報を表示\n",
    "        window_mask_df = pd.DataFrame([r for r in all_window_mask_results \n",
    "                                       if r['landmark_id'] == landmark_id])\n",
    "        \n",
    "        if len(window_mask_df) > 0:\n",
    "            all_valid_windows = window_mask_df['angle_all_valid'].sum()\n",
    "            total_windows = len(window_mask_df)\n",
    "            avg_valid_ratio = window_mask_df['angle_valid_ratio'].mean()\n",
    "            \n",
    "            print(f\"  窓ごとのマスク統計:\")\n",
    "            print(f\"    全フレーム有効な窓: {all_valid_windows}/{total_windows} ({all_valid_windows/total_windows*100:.2f}%)\")\n",
    "            print(f\"    平均有効率: {avg_valid_ratio*100:.2f}%\")\n",
    "    \n",
    "    # 全ランドマークのマスクを保存\n",
    "    if len(all_landmark_masks) > 0:\n",
    "        all_masks_df = pd.concat(all_landmark_masks, ignore_index=True)\n",
    "        mask_save_path = os.path.join(savedir, f'{dataName}_landmarks_angle_mask.csv')\n",
    "        all_masks_df.to_csv(mask_save_path, index=False)\n",
    "        print(f\"\\n全ランドマークのマスクを保存: {mask_save_path}\")\n",
    "    \n",
    "    # 窓ごとのマスク結果を保存\n",
    "    if len(all_window_mask_results) > 0:\n",
    "        window_mask_dataframe = pd.DataFrame(all_window_mask_results)\n",
    "        window_mask_save_path = os.path.join(savedir, f'{dataName}_landmarks_window_mask.csv')\n",
    "        window_mask_dataframe.to_csv(window_mask_save_path, index=False)\n",
    "        print(f\"窓ごとのマスク結果を保存: {window_mask_save_path}\")\n",
    "        \n",
    "        # 全体の統計を表示\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'全ランドマークの窓マスク統計:')\n",
    "        print(f'{\"=\"*60}')\n",
    "        \n",
    "        for landmark_id in landmark_ids:\n",
    "            landmark_windows = window_mask_dataframe[\n",
    "                window_mask_dataframe['landmark_id'] == landmark_id\n",
    "            ]\n",
    "            \n",
    "            if len(landmark_windows) > 0:\n",
    "                all_valid = landmark_windows['angle_all_valid'].sum()\n",
    "                total = len(landmark_windows)\n",
    "                avg_ratio = landmark_windows['angle_valid_ratio'].mean()\n",
    "                \n",
    "                print(f\"{landmark_id}:\")\n",
    "                print(f\"  全フレーム有効な窓: {all_valid}/{total} ({all_valid/total*100:.2f}%)\")\n",
    "                print(f\"  平均有効率: {avg_ratio*100:.2f}%\")\n",
    "\n",
    "print(\"\\n全ての処理が完了しました!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uaj1ctmx5lr",
   "metadata": {},
   "source": [
    "### 窓ごとにマスク適用した信号を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93eunt2rn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvhr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
